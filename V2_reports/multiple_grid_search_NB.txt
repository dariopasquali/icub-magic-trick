drop NaN
normalize whithin subject
Split in Train and Test set, equal for all the models and column set
 Multiple Grid Search 
==============================
columns ['duration', 'react_dur', 'point_dur', 'descr_dur', 'right_mean', 'right_std', 'right_min', 'right_max', 'left_mean', 'left_std', 'left_min', 'left_max', 'react_right_mean', 'react_right_std', 'react_right_min', 'react_right_max', 'react_left_mean', 'react_left_std', 'react_left_min', 'react_left_max', 'point_right_mean', 'point_right_std', 'point_right_min', 'point_right_max', 'point_left_mean', 'point_left_std', 'point_left_min', 'point_left_max', 'descr_right_mean', 'descr_right_std', 'descr_right_min', 'descr_right_max', 'descr_left_mean', 'descr_left_std', 'descr_left_min', 'descr_left_max', 'descr_mean_pupil', 'react_mean_pupil', 'point_mean_pupil']
number of datapoint: 150
Normalize: True
Oversample: True
Oversample Mode: minmax
Drop NaN: True
==============================
==============================
Train Set Datapoints 112
Test Set Datapoints 38
==============================
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
==============================
 knn 
==============================
# =========================== Tuning hyper-parameters for precision

Fitting 4 folds for each of 96 candidates, totalling 384 fits
Best parameters set found on development set:

{'clf__algorithm': 'auto', 'clf__n_neighbors': 3, 'clf__p': 1, 'clf__weights': 'distance'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.88      0.69      0.77        32
           1       0.23      0.50      0.32         6

   micro avg       0.66      0.66      0.66        38
   macro avg       0.56      0.59      0.54        38
weighted avg       0.78      0.66      0.70        38


Accuracy: 0.6578947368421053
Balanced Accuracy: 0.59375
Precision: 0.23076923076923078
Recall: 0.5
F1: 0.3157894736842105
AUROC: 0.59375
Confusion Matrix: [[22 10]
 [ 3  3]]

# =========================== Tuning hyper-parameters for recall

Fitting 4 folds for each of 96 candidates, totalling 384 fits
Best parameters set found on development set:

{'clf__algorithm': 'auto', 'clf__n_neighbors': 9, 'clf__p': 3, 'clf__weights': 'uniform'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.95      0.62      0.75        32
           1       0.29      0.83      0.43         6

   micro avg       0.66      0.66      0.66        38
   macro avg       0.62      0.73      0.59        38
weighted avg       0.85      0.66      0.70        38


Accuracy: 0.6578947368421053
Balanced Accuracy: 0.7291666666666667
Precision: 0.29411764705882354
Recall: 0.8333333333333334
F1: 0.4347826086956522
AUROC: 0.7291666666666667
Confusion Matrix: [[20 12]
 [ 1  5]]

# =========================== Tuning hyper-parameters for f1

Fitting 4 folds for each of 96 candidates, totalling 384 fits
Best parameters set found on development set:

{'clf__algorithm': 'ball_tree', 'clf__n_neighbors': 9, 'clf__p': 1, 'clf__weights': 'distance'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.91      0.66      0.76        32
           1       0.27      0.67      0.38         6

   micro avg       0.66      0.66      0.66        38
   macro avg       0.59      0.66      0.57        38
weighted avg       0.81      0.66      0.70        38


Accuracy: 0.6578947368421053
Balanced Accuracy: 0.6614583333333333
Precision: 0.26666666666666666
Recall: 0.6666666666666666
F1: 0.3809523809523809
AUROC: 0.6614583333333334
Confusion Matrix: [[21 11]
 [ 2  4]]

# =========================== Tuning hyper-parameters for balanced_accuracy

Fitting 4 folds for each of 96 candidates, totalling 384 fits
