drop NaN
normalize whithin subject
Split in Train and Test set, equal for all the models and column set
 Multiple Grid Search 
==============================
columns ['duration', 'react_dur', 'point_dur', 'descr_dur', 'right_mean', 'right_std', 'right_min', 'right_max', 'left_mean', 'left_std', 'left_min', 'left_max', 'react_right_mean', 'react_right_std', 'react_right_min', 'react_right_max', 'react_left_mean', 'react_left_std', 'react_left_min', 'react_left_max', 'point_right_mean', 'point_right_std', 'point_right_min', 'point_right_max', 'point_left_mean', 'point_left_std', 'point_left_min', 'point_left_max', 'descr_right_mean', 'descr_right_std', 'descr_right_min', 'descr_right_max', 'descr_left_mean', 'descr_left_std', 'descr_left_min', 'descr_left_max', 'descr_mean_pupil', 'react_mean_pupil', 'point_mean_pupil']
number of datapoint: 126
Normalize: True
Oversample: True
Oversample Mode: minmax
Drop NaN: True
==============================
==============================
Train Set Datapoints 94
Test Set Datapoints 32
==============================
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
==============================
 naive_bayes 
==============================
# =========================== Tuning hyper-parameters for precision

Fitting 4 folds for each of 5 candidates, totalling 20 fits
Best parameters set found on development set:

{'clf__var_smoothing': 1e-08}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.95      0.77      0.85        26
           1       0.45      0.83      0.59         6

   micro avg       0.78      0.78      0.78        32
   macro avg       0.70      0.80      0.72        32
weighted avg       0.86      0.78      0.80        32


Accuracy: 0.78125
Balanced Accuracy: 0.8012820512820513
Precision: 0.45454545454545453
Recall: 0.8333333333333334
F1: 0.5882352941176471
AUROC: 0.8012820512820513
Confusion Matrix: [[20  6]
 [ 1  5]]

# =========================== Tuning hyper-parameters for recall

Fitting 4 folds for each of 5 candidates, totalling 20 fits
Best parameters set found on development set:

{'clf__var_smoothing': 1e-08}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.96      0.85      0.90        26
           1       0.56      0.83      0.67         6

   micro avg       0.84      0.84      0.84        32
   macro avg       0.76      0.84      0.78        32
weighted avg       0.88      0.84      0.85        32


Accuracy: 0.84375
Balanced Accuracy: 0.8397435897435898
Precision: 0.5555555555555556
Recall: 0.8333333333333334
F1: 0.6666666666666667
AUROC: 0.8397435897435898
Confusion Matrix: [[22  4]
 [ 1  5]]

# =========================== Tuning hyper-parameters for f1

Fitting 4 folds for each of 5 candidates, totalling 20 fits
Best parameters set found on development set:

{'clf__var_smoothing': 5e-08}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.95      0.81      0.88        26
           1       0.50      0.83      0.62         6

   micro avg       0.81      0.81      0.81        32
   macro avg       0.73      0.82      0.75        32
weighted avg       0.87      0.81      0.83        32


Accuracy: 0.8125
Balanced Accuracy: 0.8205128205128205
Precision: 0.5
Recall: 0.8333333333333334
F1: 0.625
AUROC: 0.8205128205128206
Confusion Matrix: [[21  5]
 [ 1  5]]

# =========================== Tuning hyper-parameters for balanced_accuracy

Fitting 4 folds for each of 5 candidates, totalling 20 fits
Best parameters set found on development set:

{'clf__var_smoothing': 5e-08}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.96      0.85      0.90        26
           1       0.56      0.83      0.67         6

   micro avg       0.84      0.84      0.84        32
   macro avg       0.76      0.84      0.78        32
weighted avg       0.88      0.84      0.85        32


Accuracy: 0.84375
Balanced Accuracy: 0.8397435897435898
Precision: 0.5555555555555556
Recall: 0.8333333333333334
F1: 0.6666666666666667
AUROC: 0.8397435897435898
Confusion Matrix: [[22  4]
 [ 1  5]]

# =========================== Tuning hyper-parameters for roc_auc

Fitting 4 folds for each of 5 candidates, totalling 20 fits
Best parameters set found on development set:

{'clf__var_smoothing': 2e-09}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.95      0.81      0.88        26
           1       0.50      0.83      0.62         6

   micro avg       0.81      0.81      0.81        32
   macro avg       0.73      0.82      0.75        32
weighted avg       0.87      0.81      0.83        32


Accuracy: 0.8125
Balanced Accuracy: 0.8205128205128205
Precision: 0.5
Recall: 0.8333333333333334
F1: 0.625
AUROC: 0.8205128205128206
Confusion Matrix: [[21  5]
 [ 1  5]]

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
==============================
 knn 
==============================
# =========================== Tuning hyper-parameters for precision

Fitting 4 folds for each of 96 candidates, totalling 384 fits
Best parameters set found on development set:

{'clf__algorithm': 'ball_tree', 'clf__n_neighbors': 9, 'clf__p': 4, 'clf__weights': 'uniform'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.65      0.79        26
           1       0.40      1.00      0.57         6

   micro avg       0.72      0.72      0.72        32
   macro avg       0.70      0.83      0.68        32
weighted avg       0.89      0.72      0.75        32


Accuracy: 0.71875
Balanced Accuracy: 0.8269230769230769
Precision: 0.4
Recall: 1.0
F1: 0.5714285714285715
AUROC: 0.8269230769230769
Confusion Matrix: [[17  9]
 [ 0  6]]

# =========================== Tuning hyper-parameters for recall

Fitting 4 folds for each of 96 candidates, totalling 384 fits
Best parameters set found on development set:

{'clf__algorithm': 'auto', 'clf__n_neighbors': 9, 'clf__p': 4, 'clf__weights': 'uniform'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.58      0.73        26
           1       0.35      1.00      0.52         6

   micro avg       0.66      0.66      0.66        32
   macro avg       0.68      0.79      0.63        32
weighted avg       0.88      0.66      0.69        32


Accuracy: 0.65625
Balanced Accuracy: 0.7884615384615384
Precision: 0.35294117647058826
Recall: 1.0
F1: 0.5217391304347826
AUROC: 0.7884615384615384
Confusion Matrix: [[15 11]
 [ 0  6]]

# =========================== Tuning hyper-parameters for f1

Fitting 4 folds for each of 96 candidates, totalling 384 fits
Best parameters set found on development set:

{'clf__algorithm': 'ball_tree', 'clf__n_neighbors': 9, 'clf__p': 4, 'clf__weights': 'uniform'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.73      0.84        26
           1       0.46      1.00      0.63         6

   micro avg       0.78      0.78      0.78        32
   macro avg       0.73      0.87      0.74        32
weighted avg       0.90      0.78      0.80        32


Accuracy: 0.78125
Balanced Accuracy: 0.8653846153846154
Precision: 0.46153846153846156
Recall: 1.0
F1: 0.631578947368421
AUROC: 0.8653846153846154
Confusion Matrix: [[19  7]
 [ 0  6]]

# =========================== Tuning hyper-parameters for balanced_accuracy

Fitting 4 folds for each of 96 candidates, totalling 384 fits
Best parameters set found on development set:

{'clf__algorithm': 'kd_tree', 'clf__n_neighbors': 9, 'clf__p': 3, 'clf__weights': 'uniform'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.65      0.79        26
           1       0.40      1.00      0.57         6

   micro avg       0.72      0.72      0.72        32
   macro avg       0.70      0.83      0.68        32
weighted avg       0.89      0.72      0.75        32


Accuracy: 0.71875
Balanced Accuracy: 0.8269230769230769
Precision: 0.4
Recall: 1.0
F1: 0.5714285714285715
AUROC: 0.8269230769230769
Confusion Matrix: [[17  9]
 [ 0  6]]

# =========================== Tuning hyper-parameters for roc_auc

Fitting 4 folds for each of 96 candidates, totalling 384 fits
Best parameters set found on development set:

{'clf__algorithm': 'ball_tree', 'clf__n_neighbors': 5, 'clf__p': 3, 'clf__weights': 'distance'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.73      0.84        26
           1       0.46      1.00      0.63         6

   micro avg       0.78      0.78      0.78        32
   macro avg       0.73      0.87      0.74        32
weighted avg       0.90      0.78      0.80        32


Accuracy: 0.78125
Balanced Accuracy: 0.8653846153846154
Precision: 0.46153846153846156
Recall: 1.0
F1: 0.631578947368421
AUROC: 0.8653846153846154
Confusion Matrix: [[19  7]
 [ 0  6]]

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
==============================
 ada 
==============================
# =========================== Tuning hyper-parameters for precision

Fitting 4 folds for each of 40 candidates, totalling 160 fits
Best parameters set found on development set:

{'clf__algorithm': 'SAMME', 'clf__learning_rate': 0.01, 'clf__n_estimators': 50}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.95      0.81      0.88        26
           1       0.50      0.83      0.62         6

   micro avg       0.81      0.81      0.81        32
   macro avg       0.73      0.82      0.75        32
weighted avg       0.87      0.81      0.83        32


Accuracy: 0.8125
Balanced Accuracy: 0.8205128205128205
Precision: 0.5
Recall: 0.8333333333333334
F1: 0.625
AUROC: 0.8205128205128206
Confusion Matrix: [[21  5]
 [ 1  5]]

# =========================== Tuning hyper-parameters for recall

Fitting 4 folds for each of 40 candidates, totalling 160 fits
Best parameters set found on development set:

{'clf__algorithm': 'SAMME', 'clf__learning_rate': 0.05, 'clf__n_estimators': 10}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.95      0.77      0.85        26
           1       0.45      0.83      0.59         6

   micro avg       0.78      0.78      0.78        32
   macro avg       0.70      0.80      0.72        32
weighted avg       0.86      0.78      0.80        32


Accuracy: 0.78125
Balanced Accuracy: 0.8012820512820513
Precision: 0.45454545454545453
Recall: 0.8333333333333334
F1: 0.5882352941176471
AUROC: 0.8012820512820513
Confusion Matrix: [[20  6]
 [ 1  5]]

# =========================== Tuning hyper-parameters for f1

Fitting 4 folds for each of 40 candidates, totalling 160 fits
Best parameters set found on development set:

{'clf__algorithm': 'SAMME', 'clf__learning_rate': 0.01, 'clf__n_estimators': 50}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.95      0.81      0.88        26
           1       0.50      0.83      0.62         6

   micro avg       0.81      0.81      0.81        32
   macro avg       0.73      0.82      0.75        32
weighted avg       0.87      0.81      0.83        32


Accuracy: 0.8125
Balanced Accuracy: 0.8205128205128205
Precision: 0.5
Recall: 0.8333333333333334
F1: 0.625
AUROC: 0.8205128205128206
Confusion Matrix: [[21  5]
 [ 1  5]]

# =========================== Tuning hyper-parameters for balanced_accuracy

Fitting 4 folds for each of 40 candidates, totalling 160 fits
Best parameters set found on development set:

{'clf__algorithm': 'SAMME', 'clf__learning_rate': 0.01, 'clf__n_estimators': 50}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.95      0.81      0.88        26
           1       0.50      0.83      0.62         6

   micro avg       0.81      0.81      0.81        32
   macro avg       0.73      0.82      0.75        32
weighted avg       0.87      0.81      0.83        32


Accuracy: 0.8125
Balanced Accuracy: 0.8205128205128205
Precision: 0.5
Recall: 0.8333333333333334
F1: 0.625
AUROC: 0.8205128205128206
Confusion Matrix: [[21  5]
 [ 1  5]]

# =========================== Tuning hyper-parameters for roc_auc

Fitting 4 folds for each of 40 candidates, totalling 160 fits
Best parameters set found on development set:

{'clf__algorithm': 'SAMME', 'clf__learning_rate': 0.1, 'clf__n_estimators': 100}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.96      0.88      0.92        26
           1       0.62      0.83      0.71         6

   micro avg       0.88      0.88      0.88        32
   macro avg       0.79      0.86      0.82        32
weighted avg       0.90      0.88      0.88        32


Accuracy: 0.875
Balanced Accuracy: 0.858974358974359
Precision: 0.625
Recall: 0.8333333333333334
F1: 0.7142857142857143
AUROC: 0.858974358974359
Confusion Matrix: [[23  3]
 [ 1  5]]

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
==============================
 svm 
==============================
# =========================== Tuning hyper-parameters for precision

Fitting 4 folds for each of 81 candidates, totalling 324 fits
Best parameters set found on development set:

{'clf__C': 1, 'clf__gamma': 0.1, 'clf__kernel': 'rbf'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.96      0.85      0.90        26
           1       0.56      0.83      0.67         6

   micro avg       0.84      0.84      0.84        32
   macro avg       0.76      0.84      0.78        32
weighted avg       0.88      0.84      0.85        32


Accuracy: 0.84375
Balanced Accuracy: 0.8397435897435898
Precision: 0.5555555555555556
Recall: 0.8333333333333334
F1: 0.6666666666666667
AUROC: 0.8397435897435898
Confusion Matrix: [[22  4]
 [ 1  5]]

# =========================== Tuning hyper-parameters for recall

Fitting 4 folds for each of 81 candidates, totalling 324 fits
Best parameters set found on development set:

{'clf__C': 0.001, 'clf__gamma': 0.0001, 'clf__kernel': 'rbf'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.65      0.79        26
           1       0.40      1.00      0.57         6

   micro avg       0.72      0.72      0.72        32
   macro avg       0.70      0.83      0.68        32
weighted avg       0.89      0.72      0.75        32


Accuracy: 0.71875
Balanced Accuracy: 0.8269230769230769
Precision: 0.4
Recall: 1.0
F1: 0.5714285714285715
AUROC: 0.8269230769230769
Confusion Matrix: [[17  9]
 [ 0  6]]

# =========================== Tuning hyper-parameters for f1

Fitting 4 folds for each of 81 candidates, totalling 324 fits
Best parameters set found on development set:

{'clf__C': 1000, 'clf__gamma': 1e-05, 'clf__kernel': 'sigmoid'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.62      0.76        26
           1       0.38      1.00      0.55         6

   micro avg       0.69      0.69      0.69        32
   macro avg       0.69      0.81      0.65        32
weighted avg       0.88      0.69      0.72        32


Accuracy: 0.6875
Balanced Accuracy: 0.8076923076923077
Precision: 0.375
Recall: 1.0
F1: 0.5454545454545454
AUROC: 0.8076923076923077
Confusion Matrix: [[16 10]
 [ 0  6]]

# =========================== Tuning hyper-parameters for balanced_accuracy

Fitting 4 folds for each of 81 candidates, totalling 324 fits
Best parameters set found on development set:

{'clf__C': 0.1, 'clf__gamma': 1e-05, 'clf__kernel': 'rbf'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.62      0.76        26
           1       0.38      1.00      0.55         6

   micro avg       0.69      0.69      0.69        32
   macro avg       0.69      0.81      0.65        32
weighted avg       0.88      0.69      0.72        32


Accuracy: 0.6875
Balanced Accuracy: 0.8076923076923077
Precision: 0.375
Recall: 1.0
F1: 0.5454545454545454
AUROC: 0.8076923076923077
Confusion Matrix: [[16 10]
 [ 0  6]]

# =========================== Tuning hyper-parameters for roc_auc

Fitting 4 folds for each of 81 candidates, totalling 324 fits
Best parameters set found on development set:

{'clf__C': 1, 'clf__gamma': 0.001, 'clf__kernel': 'rbf'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.58      0.73        26
           1       0.35      1.00      0.52         6

   micro avg       0.66      0.66      0.66        32
   macro avg       0.68      0.79      0.63        32
weighted avg       0.88      0.66      0.69        32


Accuracy: 0.65625
Balanced Accuracy: 0.7884615384615384
Precision: 0.35294117647058826
Recall: 1.0
F1: 0.5217391304347826
AUROC: 0.7884615384615384
Confusion Matrix: [[15 11]
 [ 0  6]]

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
==============================
 decision_tree 
==============================
# =========================== Tuning hyper-parameters for precision

Fitting 4 folds for each of 1200 candidates, totalling 4800 fits
Best parameters set found on development set:

{'clf__criterion': 'entropy', 'clf__max_depth': 4, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 4, 'clf__min_samples_split': 2, 'clf__splitter': 'best'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.85      0.88      0.87        26
           1       0.40      0.33      0.36         6

   micro avg       0.78      0.78      0.78        32
   macro avg       0.63      0.61      0.62        32
weighted avg       0.77      0.78      0.77        32


Accuracy: 0.78125
Balanced Accuracy: 0.6089743589743589
Precision: 0.4
Recall: 0.3333333333333333
F1: 0.3636363636363636
AUROC: 0.6089743589743589
Confusion Matrix: [[23  3]
 [ 4  2]]

# =========================== Tuning hyper-parameters for recall

Fitting 4 folds for each of 1200 candidates, totalling 4800 fits
Best parameters set found on development set:

{'clf__criterion': 'entropy', 'clf__max_depth': 2, 'clf__max_features': 'auto', 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 5, 'clf__splitter': 'best'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.95      0.81      0.88        26
           1       0.50      0.83      0.62         6

   micro avg       0.81      0.81      0.81        32
   macro avg       0.73      0.82      0.75        32
weighted avg       0.87      0.81      0.83        32


Accuracy: 0.8125
Balanced Accuracy: 0.8205128205128205
Precision: 0.5
Recall: 0.8333333333333334
F1: 0.625
AUROC: 0.8205128205128206
Confusion Matrix: [[21  5]
 [ 1  5]]

# =========================== Tuning hyper-parameters for f1

Fitting 4 folds for each of 1200 candidates, totalling 4800 fits
Best parameters set found on development set:

{'clf__criterion': 'entropy', 'clf__max_depth': 2, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 2, 'clf__min_samples_split': 3, 'clf__splitter': 'best'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.65      0.79        26
           1       0.40      1.00      0.57         6

   micro avg       0.72      0.72      0.72        32
   macro avg       0.70      0.83      0.68        32
weighted avg       0.89      0.72      0.75        32


Accuracy: 0.71875
Balanced Accuracy: 0.8269230769230769
Precision: 0.4
Recall: 1.0
F1: 0.5714285714285715
AUROC: 0.8269230769230769
Confusion Matrix: [[17  9]
 [ 0  6]]

# =========================== Tuning hyper-parameters for balanced_accuracy

Fitting 4 folds for each of 1200 candidates, totalling 4800 fits
Best parameters set found on development set:

{'clf__criterion': 'entropy', 'clf__max_depth': 20, 'clf__max_features': 'auto', 'clf__min_samples_leaf': 4, 'clf__min_samples_split': 3, 'clf__splitter': 'best'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.90      0.73      0.81        26
           1       0.36      0.67      0.47         6

   micro avg       0.72      0.72      0.72        32
   macro avg       0.63      0.70      0.64        32
weighted avg       0.80      0.72      0.75        32


Accuracy: 0.71875
Balanced Accuracy: 0.6987179487179487
Precision: 0.36363636363636365
Recall: 0.6666666666666666
F1: 0.4705882352941177
AUROC: 0.6987179487179488
Confusion Matrix: [[19  7]
 [ 2  4]]

# =========================== Tuning hyper-parameters for roc_auc

Fitting 4 folds for each of 1200 candidates, totalling 4800 fits
Best parameters set found on development set:

{'clf__criterion': 'entropy', 'clf__max_depth': 2, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 5, 'clf__min_samples_split': 4, 'clf__splitter': 'random'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.84      0.81      0.82        26
           1       0.29      0.33      0.31         6

   micro avg       0.72      0.72      0.72        32
   macro avg       0.56      0.57      0.57        32
weighted avg       0.74      0.72      0.73        32


Accuracy: 0.71875
Balanced Accuracy: 0.5705128205128205
Precision: 0.2857142857142857
Recall: 0.3333333333333333
F1: 0.30769230769230765
AUROC: 0.5705128205128205
Confusion Matrix: [[21  5]
 [ 4  2]]

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
==============================
 random_forest 
==============================
# =========================== Tuning hyper-parameters for precision

Fitting 4 folds for each of 540 candidates, totalling 2160 fits
Best parameters set found on development set:

{'clf__bootstrap': True, 'clf__max_depth': 8, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 3, 'clf__min_samples_split': 2, 'clf__n_estimators': 10}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.96      0.88      0.92        26
           1       0.62      0.83      0.71         6

   micro avg       0.88      0.88      0.88        32
   macro avg       0.79      0.86      0.82        32
weighted avg       0.90      0.88      0.88        32


Accuracy: 0.875
Balanced Accuracy: 0.858974358974359
Precision: 0.625
Recall: 0.8333333333333334
F1: 0.7142857142857143
AUROC: 0.858974358974359
Confusion Matrix: [[23  3]
 [ 1  5]]

# =========================== Tuning hyper-parameters for recall

Fitting 4 folds for each of 540 candidates, totalling 2160 fits
Best parameters set found on development set:

{'clf__bootstrap': True, 'clf__max_depth': 8, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 5, 'clf__min_samples_split': 2, 'clf__n_estimators': 10}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.85      0.92        26
           1       0.60      1.00      0.75         6

   micro avg       0.88      0.88      0.88        32
   macro avg       0.80      0.92      0.83        32
weighted avg       0.93      0.88      0.89        32


Accuracy: 0.875
Balanced Accuracy: 0.9230769230769231
Precision: 0.6
Recall: 1.0
F1: 0.7499999999999999
AUROC: 0.9230769230769231
Confusion Matrix: [[22  4]
 [ 0  6]]

# =========================== Tuning hyper-parameters for f1

Fitting 4 folds for each of 540 candidates, totalling 2160 fits
Best parameters set found on development set:

{'clf__bootstrap': False, 'clf__max_depth': 2, 'clf__max_features': 'auto', 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 2, 'clf__n_estimators': 10}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.95      0.81      0.88        26
           1       0.50      0.83      0.62         6

   micro avg       0.81      0.81      0.81        32
   macro avg       0.73      0.82      0.75        32
weighted avg       0.87      0.81      0.83        32


Accuracy: 0.8125
Balanced Accuracy: 0.8205128205128205
Precision: 0.5
Recall: 0.8333333333333334
F1: 0.625
AUROC: 0.8205128205128206
Confusion Matrix: [[21  5]
 [ 1  5]]

# =========================== Tuning hyper-parameters for balanced_accuracy

Fitting 4 folds for each of 540 candidates, totalling 2160 fits
Best parameters set found on development set:

{'clf__bootstrap': True, 'clf__max_depth': 2, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 2, 'clf__n_estimators': 10}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.85      0.92        26
           1       0.60      1.00      0.75         6

   micro avg       0.88      0.88      0.88        32
   macro avg       0.80      0.92      0.83        32
weighted avg       0.93      0.88      0.89        32


Accuracy: 0.875
Balanced Accuracy: 0.9230769230769231
Precision: 0.6
Recall: 1.0
F1: 0.7499999999999999
AUROC: 0.9230769230769231
Confusion Matrix: [[22  4]
 [ 0  6]]

# =========================== Tuning hyper-parameters for roc_auc

Fitting 4 folds for each of 540 candidates, totalling 2160 fits
Best parameters set found on development set:

{'clf__bootstrap': False, 'clf__max_depth': 2, 'clf__max_features': 'auto', 'clf__min_samples_leaf': 3, 'clf__min_samples_split': 2, 'clf__n_estimators': 10}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.85      0.92        26
           1       0.60      1.00      0.75         6

   micro avg       0.88      0.88      0.88        32
   macro avg       0.80      0.92      0.83        32
weighted avg       0.93      0.88      0.89        32


Accuracy: 0.875
Balanced Accuracy: 0.9230769230769231
Precision: 0.6
Recall: 1.0
F1: 0.7499999999999999
AUROC: 0.9230769230769231
Confusion Matrix: [[22  4]
 [ 0  6]]

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
==============================
 mlp 
==============================
# =========================== Tuning hyper-parameters for precision

Fitting 4 folds for each of 36 candidates, totalling 144 fits
Best parameters set found on development set:

{'clf__activation': 'relu', 'clf__alpha': 0.005, 'clf__hidden_layer_sizes': (100,), 'clf__solver': 'adam'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.96      0.88      0.92        26
           1       0.62      0.83      0.71         6

   micro avg       0.88      0.88      0.88        32
   macro avg       0.79      0.86      0.82        32
weighted avg       0.90      0.88      0.88        32


Accuracy: 0.875
Balanced Accuracy: 0.858974358974359
Precision: 0.625
Recall: 0.8333333333333334
F1: 0.7142857142857143
AUROC: 0.858974358974359
Confusion Matrix: [[23  3]
 [ 1  5]]

# =========================== Tuning hyper-parameters for recall

Fitting 4 folds for each of 36 candidates, totalling 144 fits
Best parameters set found on development set:

{'clf__activation': 'tanh', 'clf__alpha': 0.0001, 'clf__hidden_layer_sizes': (300,), 'clf__solver': 'sgd'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.95      0.77      0.85        26
           1       0.45      0.83      0.59         6

   micro avg       0.78      0.78      0.78        32
   macro avg       0.70      0.80      0.72        32
weighted avg       0.86      0.78      0.80        32


Accuracy: 0.78125
Balanced Accuracy: 0.8012820512820513
Precision: 0.45454545454545453
Recall: 0.8333333333333334
F1: 0.5882352941176471
AUROC: 0.8012820512820513
Confusion Matrix: [[20  6]
 [ 1  5]]

# =========================== Tuning hyper-parameters for f1

Fitting 4 folds for each of 36 candidates, totalling 144 fits
Best parameters set found on development set:

{'clf__activation': 'relu', 'clf__alpha': 0.05, 'clf__hidden_layer_sizes': (32, 8, 32), 'clf__solver': 'sgd'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.92      0.96        26
           1       0.75      1.00      0.86         6

   micro avg       0.94      0.94      0.94        32
   macro avg       0.88      0.96      0.91        32
weighted avg       0.95      0.94      0.94        32


Accuracy: 0.9375
Balanced Accuracy: 0.9615384615384616
Precision: 0.75
Recall: 1.0
F1: 0.8571428571428571
AUROC: 0.9615384615384616
Confusion Matrix: [[24  2]
 [ 0  6]]

# =========================== Tuning hyper-parameters for balanced_accuracy

Fitting 4 folds for each of 36 candidates, totalling 144 fits
Best parameters set found on development set:

{'clf__activation': 'tanh', 'clf__alpha': 0.0001, 'clf__hidden_layer_sizes': (32, 8, 32), 'clf__solver': 'sgd'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.92      0.85      0.88        26
           1       0.50      0.67      0.57         6

   micro avg       0.81      0.81      0.81        32
   macro avg       0.71      0.76      0.73        32
weighted avg       0.84      0.81      0.82        32


Accuracy: 0.8125
Balanced Accuracy: 0.7564102564102564
Precision: 0.5
Recall: 0.6666666666666666
F1: 0.5714285714285715
AUROC: 0.7564102564102564
Confusion Matrix: [[22  4]
 [ 2  4]]

# =========================== Tuning hyper-parameters for roc_auc

Fitting 4 folds for each of 36 candidates, totalling 144 fits
Best parameters set found on development set:

{'clf__activation': 'relu', 'clf__alpha': 0.005, 'clf__hidden_layer_sizes': (32, 8, 32), 'clf__solver': 'sgd'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.85      0.92        26
           1       0.60      1.00      0.75         6

   micro avg       0.88      0.88      0.88        32
   macro avg       0.80      0.92      0.83        32
weighted avg       0.93      0.88      0.89        32


Accuracy: 0.875
Balanced Accuracy: 0.9230769230769231
Precision: 0.6
Recall: 1.0
F1: 0.7499999999999999
AUROC: 0.9230769230769231
Confusion Matrix: [[22  4]
 [ 0  6]]

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
 Multiple Grid Search 
==============================
columns ['descr_right_mean', 'descr_left_mean', 'react_right_mean', 'react_left_mean']
number of datapoint: 126
Normalize: True
Oversample: True
Oversample Mode: minmax
Drop NaN: True
==============================
==============================
Train Set Datapoints 94
Test Set Datapoints 32
==============================
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
==============================
 naive_bayes 
==============================
# =========================== Tuning hyper-parameters for precision

Fitting 4 folds for each of 5 candidates, totalling 20 fits
Best parameters set found on development set:

{'clf__var_smoothing': 1e-08}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.96      0.85      0.90        26
           1       0.56      0.83      0.67         6

   micro avg       0.84      0.84      0.84        32
   macro avg       0.76      0.84      0.78        32
weighted avg       0.88      0.84      0.85        32


Accuracy: 0.84375
Balanced Accuracy: 0.8397435897435898
Precision: 0.5555555555555556
Recall: 0.8333333333333334
F1: 0.6666666666666667
AUROC: 0.8397435897435898
Confusion Matrix: [[22  4]
 [ 1  5]]

# =========================== Tuning hyper-parameters for recall

Fitting 4 folds for each of 5 candidates, totalling 20 fits
Best parameters set found on development set:

{'clf__var_smoothing': 2e-09}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.95      0.81      0.88        26
           1       0.50      0.83      0.62         6

   micro avg       0.81      0.81      0.81        32
   macro avg       0.73      0.82      0.75        32
weighted avg       0.87      0.81      0.83        32


Accuracy: 0.8125
Balanced Accuracy: 0.8205128205128205
Precision: 0.5
Recall: 0.8333333333333334
F1: 0.625
AUROC: 0.8205128205128206
Confusion Matrix: [[21  5]
 [ 1  5]]

# =========================== Tuning hyper-parameters for f1

Fitting 4 folds for each of 5 candidates, totalling 20 fits
Best parameters set found on development set:

{'clf__var_smoothing': 1e-09}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.96      0.85      0.90        26
           1       0.56      0.83      0.67         6

   micro avg       0.84      0.84      0.84        32
   macro avg       0.76      0.84      0.78        32
weighted avg       0.88      0.84      0.85        32


Accuracy: 0.84375
Balanced Accuracy: 0.8397435897435898
Precision: 0.5555555555555556
Recall: 0.8333333333333334
F1: 0.6666666666666667
AUROC: 0.8397435897435898
Confusion Matrix: [[22  4]
 [ 1  5]]

# =========================== Tuning hyper-parameters for balanced_accuracy

Fitting 4 folds for each of 5 candidates, totalling 20 fits
Best parameters set found on development set:

{'clf__var_smoothing': 5e-08}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.95      0.81      0.88        26
           1       0.50      0.83      0.62         6

   micro avg       0.81      0.81      0.81        32
   macro avg       0.73      0.82      0.75        32
weighted avg       0.87      0.81      0.83        32


Accuracy: 0.8125
Balanced Accuracy: 0.8205128205128205
Precision: 0.5
Recall: 0.8333333333333334
F1: 0.625
AUROC: 0.8205128205128206
Confusion Matrix: [[21  5]
 [ 1  5]]

# =========================== Tuning hyper-parameters for roc_auc

Fitting 4 folds for each of 5 candidates, totalling 20 fits
Best parameters set found on development set:

{'clf__var_smoothing': 1e-08}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.95      0.81      0.88        26
           1       0.50      0.83      0.62         6

   micro avg       0.81      0.81      0.81        32
   macro avg       0.73      0.82      0.75        32
weighted avg       0.87      0.81      0.83        32


Accuracy: 0.8125
Balanced Accuracy: 0.8205128205128205
Precision: 0.5
Recall: 0.8333333333333334
F1: 0.625
AUROC: 0.8205128205128206
Confusion Matrix: [[21  5]
 [ 1  5]]

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
==============================
 knn 
==============================
# =========================== Tuning hyper-parameters for precision

Fitting 4 folds for each of 96 candidates, totalling 384 fits
Best parameters set found on development set:

{'clf__algorithm': 'kd_tree', 'clf__n_neighbors': 3, 'clf__p': 4, 'clf__weights': 'distance'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.85      0.92        26
           1       0.60      1.00      0.75         6

   micro avg       0.88      0.88      0.88        32
   macro avg       0.80      0.92      0.83        32
weighted avg       0.93      0.88      0.89        32


Accuracy: 0.875
Balanced Accuracy: 0.9230769230769231
Precision: 0.6
Recall: 1.0
F1: 0.7499999999999999
AUROC: 0.9230769230769231
Confusion Matrix: [[22  4]
 [ 0  6]]

# =========================== Tuning hyper-parameters for recall

Fitting 4 folds for each of 96 candidates, totalling 384 fits
Best parameters set found on development set:

{'clf__algorithm': 'auto', 'clf__n_neighbors': 9, 'clf__p': 1, 'clf__weights': 'distance'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.81      0.89        26
           1       0.55      1.00      0.71         6

   micro avg       0.84      0.84      0.84        32
   macro avg       0.77      0.90      0.80        32
weighted avg       0.91      0.84      0.86        32


Accuracy: 0.84375
Balanced Accuracy: 0.9038461538461539
Precision: 0.5454545454545454
Recall: 1.0
F1: 0.7058823529411764
AUROC: 0.9038461538461539
Confusion Matrix: [[21  5]
 [ 0  6]]

# =========================== Tuning hyper-parameters for f1

Fitting 4 folds for each of 96 candidates, totalling 384 fits
Best parameters set found on development set:

{'clf__algorithm': 'ball_tree', 'clf__n_neighbors': 7, 'clf__p': 4, 'clf__weights': 'distance'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.88      0.94        26
           1       0.67      1.00      0.80         6

   micro avg       0.91      0.91      0.91        32
   macro avg       0.83      0.94      0.87        32
weighted avg       0.94      0.91      0.91        32


Accuracy: 0.90625
Balanced Accuracy: 0.9423076923076923
Precision: 0.6666666666666666
Recall: 1.0
F1: 0.8
AUROC: 0.9423076923076923
Confusion Matrix: [[23  3]
 [ 0  6]]

# =========================== Tuning hyper-parameters for balanced_accuracy

Fitting 4 folds for each of 96 candidates, totalling 384 fits
Best parameters set found on development set:

{'clf__algorithm': 'kd_tree', 'clf__n_neighbors': 5, 'clf__p': 3, 'clf__weights': 'distance'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.85      0.92        26
           1       0.60      1.00      0.75         6

   micro avg       0.88      0.88      0.88        32
   macro avg       0.80      0.92      0.83        32
weighted avg       0.93      0.88      0.89        32


Accuracy: 0.875
Balanced Accuracy: 0.9230769230769231
Precision: 0.6
Recall: 1.0
F1: 0.7499999999999999
AUROC: 0.9230769230769231
Confusion Matrix: [[22  4]
 [ 0  6]]

# =========================== Tuning hyper-parameters for roc_auc

Fitting 4 folds for each of 96 candidates, totalling 384 fits
Best parameters set found on development set:

{'clf__algorithm': 'auto', 'clf__n_neighbors': 9, 'clf__p': 4, 'clf__weights': 'distance'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.92      0.96        26
           1       0.75      1.00      0.86         6

   micro avg       0.94      0.94      0.94        32
   macro avg       0.88      0.96      0.91        32
weighted avg       0.95      0.94      0.94        32


Accuracy: 0.9375
Balanced Accuracy: 0.9615384615384616
Precision: 0.75
Recall: 1.0
F1: 0.8571428571428571
AUROC: 0.9615384615384616
Confusion Matrix: [[24  2]
 [ 0  6]]

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
==============================
 ada 
==============================
# =========================== Tuning hyper-parameters for precision

Fitting 4 folds for each of 40 candidates, totalling 160 fits
Best parameters set found on development set:

{'clf__algorithm': 'SAMME', 'clf__learning_rate': 0.1, 'clf__n_estimators': 10}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.95      0.77      0.85        26
           1       0.45      0.83      0.59         6

   micro avg       0.78      0.78      0.78        32
   macro avg       0.70      0.80      0.72        32
weighted avg       0.86      0.78      0.80        32


Accuracy: 0.78125
Balanced Accuracy: 0.8012820512820513
Precision: 0.45454545454545453
Recall: 0.8333333333333334
F1: 0.5882352941176471
AUROC: 0.8012820512820513
Confusion Matrix: [[20  6]
 [ 1  5]]

# =========================== Tuning hyper-parameters for recall

Fitting 4 folds for each of 40 candidates, totalling 160 fits
Best parameters set found on development set:

{'clf__algorithm': 'SAMME', 'clf__learning_rate': 0.01, 'clf__n_estimators': 10}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.95      0.81      0.88        26
           1       0.50      0.83      0.62         6

   micro avg       0.81      0.81      0.81        32
   macro avg       0.73      0.82      0.75        32
weighted avg       0.87      0.81      0.83        32


Accuracy: 0.8125
Balanced Accuracy: 0.8205128205128205
Precision: 0.5
Recall: 0.8333333333333334
F1: 0.625
AUROC: 0.8205128205128206
Confusion Matrix: [[21  5]
 [ 1  5]]

# =========================== Tuning hyper-parameters for f1

Fitting 4 folds for each of 40 candidates, totalling 160 fits
Best parameters set found on development set:

{'clf__algorithm': 'SAMME.R', 'clf__learning_rate': 0.01, 'clf__n_estimators': 10}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.95      0.81      0.88        26
           1       0.50      0.83      0.62         6

   micro avg       0.81      0.81      0.81        32
   macro avg       0.73      0.82      0.75        32
weighted avg       0.87      0.81      0.83        32


Accuracy: 0.8125
Balanced Accuracy: 0.8205128205128205
Precision: 0.5
Recall: 0.8333333333333334
F1: 0.625
AUROC: 0.8205128205128206
Confusion Matrix: [[21  5]
 [ 1  5]]

# =========================== Tuning hyper-parameters for balanced_accuracy

Fitting 4 folds for each of 40 candidates, totalling 160 fits
Best parameters set found on development set:

{'clf__algorithm': 'SAMME', 'clf__learning_rate': 0.01, 'clf__n_estimators': 50}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.95      0.81      0.88        26
           1       0.50      0.83      0.62         6

   micro avg       0.81      0.81      0.81        32
   macro avg       0.73      0.82      0.75        32
weighted avg       0.87      0.81      0.83        32


Accuracy: 0.8125
Balanced Accuracy: 0.8205128205128205
Precision: 0.5
Recall: 0.8333333333333334
F1: 0.625
AUROC: 0.8205128205128206
Confusion Matrix: [[21  5]
 [ 1  5]]

# =========================== Tuning hyper-parameters for roc_auc

Fitting 4 folds for each of 40 candidates, totalling 160 fits
Best parameters set found on development set:

{'clf__algorithm': 'SAMME', 'clf__learning_rate': 0.01, 'clf__n_estimators': 10}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.95      0.81      0.88        26
           1       0.50      0.83      0.62         6

   micro avg       0.81      0.81      0.81        32
   macro avg       0.73      0.82      0.75        32
weighted avg       0.87      0.81      0.83        32


Accuracy: 0.8125
Balanced Accuracy: 0.8205128205128205
Precision: 0.5
Recall: 0.8333333333333334
F1: 0.625
AUROC: 0.8205128205128206
Confusion Matrix: [[21  5]
 [ 1  5]]

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
==============================
 svm 
==============================
# =========================== Tuning hyper-parameters for precision

Fitting 4 folds for each of 81 candidates, totalling 324 fits
Best parameters set found on development set:

{'clf__C': 100, 'clf__gamma': 0.1, 'clf__kernel': 'rbf'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.96      0.85      0.90        26
           1       0.56      0.83      0.67         6

   micro avg       0.84      0.84      0.84        32
   macro avg       0.76      0.84      0.78        32
weighted avg       0.88      0.84      0.85        32


Accuracy: 0.84375
Balanced Accuracy: 0.8397435897435898
Precision: 0.5555555555555556
Recall: 0.8333333333333334
F1: 0.6666666666666667
AUROC: 0.8397435897435898
Confusion Matrix: [[22  4]
 [ 1  5]]

# =========================== Tuning hyper-parameters for recall

Fitting 4 folds for each of 81 candidates, totalling 324 fits
Best parameters set found on development set:

{'clf__C': 0.001, 'clf__gamma': 0.001, 'clf__kernel': 'rbf'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.50      0.67        26
           1       0.32      1.00      0.48         6

   micro avg       0.59      0.59      0.59        32
   macro avg       0.66      0.75      0.57        32
weighted avg       0.87      0.59      0.63        32


Accuracy: 0.59375
Balanced Accuracy: 0.75
Precision: 0.3157894736842105
Recall: 1.0
F1: 0.4799999999999999
AUROC: 0.75
Confusion Matrix: [[13 13]
 [ 0  6]]

# =========================== Tuning hyper-parameters for f1

Fitting 4 folds for each of 81 candidates, totalling 324 fits
Best parameters set found on development set:

{'clf__C': 10, 'clf__gamma': 0.1, 'clf__kernel': 'rbf'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.69      0.82        26
           1       0.43      1.00      0.60         6

   micro avg       0.75      0.75      0.75        32
   macro avg       0.71      0.85      0.71        32
weighted avg       0.89      0.75      0.78        32


Accuracy: 0.75
Balanced Accuracy: 0.8461538461538461
Precision: 0.42857142857142855
Recall: 1.0
F1: 0.6
AUROC: 0.8461538461538461
Confusion Matrix: [[18  8]
 [ 0  6]]

# =========================== Tuning hyper-parameters for balanced_accuracy

Fitting 4 folds for each of 81 candidates, totalling 324 fits
Best parameters set found on development set:

{'clf__C': 10, 'clf__gamma': 0.1, 'clf__kernel': 'rbf'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.77      0.87        26
           1       0.50      1.00      0.67         6

   micro avg       0.81      0.81      0.81        32
   macro avg       0.75      0.88      0.77        32
weighted avg       0.91      0.81      0.83        32


Accuracy: 0.8125
Balanced Accuracy: 0.8846153846153846
Precision: 0.5
Recall: 1.0
F1: 0.6666666666666666
AUROC: 0.8846153846153846
Confusion Matrix: [[20  6]
 [ 0  6]]

# =========================== Tuning hyper-parameters for roc_auc

Fitting 4 folds for each of 81 candidates, totalling 324 fits
Best parameters set found on development set:

{'clf__C': 50, 'clf__gamma': 0.001, 'clf__kernel': 'sigmoid'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.77      0.87        26
           1       0.50      1.00      0.67         6

   micro avg       0.81      0.81      0.81        32
   macro avg       0.75      0.88      0.77        32
weighted avg       0.91      0.81      0.83        32


Accuracy: 0.8125
Balanced Accuracy: 0.8846153846153846
Precision: 0.5
Recall: 1.0
F1: 0.6666666666666666
AUROC: 0.8846153846153846
Confusion Matrix: [[20  6]
 [ 0  6]]

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
==============================
 decision_tree 
==============================
# =========================== Tuning hyper-parameters for precision

Fitting 4 folds for each of 1200 candidates, totalling 4800 fits
Best parameters set found on development set:

{'clf__criterion': 'gini', 'clf__max_depth': 10, 'clf__max_features': 'auto', 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 6, 'clf__splitter': 'random'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.95      0.81      0.88        26
           1       0.50      0.83      0.62         6

   micro avg       0.81      0.81      0.81        32
   macro avg       0.73      0.82      0.75        32
weighted avg       0.87      0.81      0.83        32


Accuracy: 0.8125
Balanced Accuracy: 0.8205128205128205
Precision: 0.5
Recall: 0.8333333333333334
F1: 0.625
AUROC: 0.8205128205128206
Confusion Matrix: [[21  5]
 [ 1  5]]

# =========================== Tuning hyper-parameters for recall

Fitting 4 folds for each of 1200 candidates, totalling 4800 fits
Best parameters set found on development set:

{'clf__criterion': 'entropy', 'clf__max_depth': 2, 'clf__max_features': 'auto', 'clf__min_samples_leaf': 4, 'clf__min_samples_split': 6, 'clf__splitter': 'random'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.73      0.84        26
           1       0.46      1.00      0.63         6

   micro avg       0.78      0.78      0.78        32
   macro avg       0.73      0.87      0.74        32
weighted avg       0.90      0.78      0.80        32


Accuracy: 0.78125
Balanced Accuracy: 0.8653846153846154
Precision: 0.46153846153846156
Recall: 1.0
F1: 0.631578947368421
AUROC: 0.8653846153846154
Confusion Matrix: [[19  7]
 [ 0  6]]

# =========================== Tuning hyper-parameters for f1

Fitting 4 folds for each of 1200 candidates, totalling 4800 fits
Best parameters set found on development set:

{'clf__criterion': 'entropy', 'clf__max_depth': 2, 'clf__max_features': 'auto', 'clf__min_samples_leaf': 4, 'clf__min_samples_split': 2, 'clf__splitter': 'best'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.95      0.81      0.88        26
           1       0.50      0.83      0.62         6

   micro avg       0.81      0.81      0.81        32
   macro avg       0.73      0.82      0.75        32
weighted avg       0.87      0.81      0.83        32


Accuracy: 0.8125
Balanced Accuracy: 0.8205128205128205
Precision: 0.5
Recall: 0.8333333333333334
F1: 0.625
AUROC: 0.8205128205128206
Confusion Matrix: [[21  5]
 [ 1  5]]

# =========================== Tuning hyper-parameters for balanced_accuracy

Fitting 4 folds for each of 1200 candidates, totalling 4800 fits
Best parameters set found on development set:

{'clf__criterion': 'entropy', 'clf__max_depth': 2, 'clf__max_features': 'auto', 'clf__min_samples_leaf': 5, 'clf__min_samples_split': 2, 'clf__splitter': 'best'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.88      0.88      0.88        26
           1       0.50      0.50      0.50         6

   micro avg       0.81      0.81      0.81        32
   macro avg       0.69      0.69      0.69        32
weighted avg       0.81      0.81      0.81        32


Accuracy: 0.8125
Balanced Accuracy: 0.6923076923076923
Precision: 0.5
Recall: 0.5
F1: 0.5
AUROC: 0.6923076923076923
Confusion Matrix: [[23  3]
 [ 3  3]]

# =========================== Tuning hyper-parameters for roc_auc

Fitting 4 folds for each of 1200 candidates, totalling 4800 fits
Best parameters set found on development set:

{'clf__criterion': 'entropy', 'clf__max_depth': 8, 'clf__max_features': 'auto', 'clf__min_samples_leaf': 4, 'clf__min_samples_split': 3, 'clf__splitter': 'random'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.88      0.94        26
           1       0.67      1.00      0.80         6

   micro avg       0.91      0.91      0.91        32
   macro avg       0.83      0.94      0.87        32
weighted avg       0.94      0.91      0.91        32


Accuracy: 0.90625
Balanced Accuracy: 0.9423076923076923
Precision: 0.6666666666666666
Recall: 1.0
F1: 0.8
AUROC: 0.9423076923076923
Confusion Matrix: [[23  3]
 [ 0  6]]

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
==============================
 random_forest 
==============================
# =========================== Tuning hyper-parameters for precision

Fitting 4 folds for each of 540 candidates, totalling 2160 fits
Best parameters set found on development set:

{'clf__bootstrap': True, 'clf__max_depth': 2, 'clf__max_features': 'auto', 'clf__min_samples_leaf': 3, 'clf__min_samples_split': 4, 'clf__n_estimators': 80}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.95      0.81      0.88        26
           1       0.50      0.83      0.62         6

   micro avg       0.81      0.81      0.81        32
   macro avg       0.73      0.82      0.75        32
weighted avg       0.87      0.81      0.83        32


Accuracy: 0.8125
Balanced Accuracy: 0.8205128205128205
Precision: 0.5
Recall: 0.8333333333333334
F1: 0.625
AUROC: 0.8205128205128206
Confusion Matrix: [[21  5]
 [ 1  5]]

# =========================== Tuning hyper-parameters for recall

Fitting 4 folds for each of 540 candidates, totalling 2160 fits
Best parameters set found on development set:

{'clf__bootstrap': True, 'clf__max_depth': 2, 'clf__max_features': 'auto', 'clf__min_samples_leaf': 3, 'clf__min_samples_split': 2, 'clf__n_estimators': 80}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.95      0.81      0.88        26
           1       0.50      0.83      0.62         6

   micro avg       0.81      0.81      0.81        32
   macro avg       0.73      0.82      0.75        32
weighted avg       0.87      0.81      0.83        32


Accuracy: 0.8125
Balanced Accuracy: 0.8205128205128205
Precision: 0.5
Recall: 0.8333333333333334
F1: 0.625
AUROC: 0.8205128205128206
Confusion Matrix: [[21  5]
 [ 1  5]]

# =========================== Tuning hyper-parameters for f1

Fitting 4 folds for each of 540 candidates, totalling 2160 fits
Best parameters set found on development set:

{'clf__bootstrap': True, 'clf__max_depth': 2, 'clf__max_features': 'auto', 'clf__min_samples_leaf': 5, 'clf__min_samples_split': 2, 'clf__n_estimators': 80}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.95      0.81      0.88        26
           1       0.50      0.83      0.62         6

   micro avg       0.81      0.81      0.81        32
   macro avg       0.73      0.82      0.75        32
weighted avg       0.87      0.81      0.83        32


Accuracy: 0.8125
Balanced Accuracy: 0.8205128205128205
Precision: 0.5
Recall: 0.8333333333333334
F1: 0.625
AUROC: 0.8205128205128206
Confusion Matrix: [[21  5]
 [ 1  5]]

# =========================== Tuning hyper-parameters for balanced_accuracy

Fitting 4 folds for each of 540 candidates, totalling 2160 fits
Best parameters set found on development set:

{'clf__bootstrap': True, 'clf__max_depth': 2, 'clf__max_features': 'auto', 'clf__min_samples_leaf': 5, 'clf__min_samples_split': 4, 'clf__n_estimators': 80}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.95      0.81      0.88        26
           1       0.50      0.83      0.62         6

   micro avg       0.81      0.81      0.81        32
   macro avg       0.73      0.82      0.75        32
weighted avg       0.87      0.81      0.83        32


Accuracy: 0.8125
Balanced Accuracy: 0.8205128205128205
Precision: 0.5
Recall: 0.8333333333333334
F1: 0.625
AUROC: 0.8205128205128206
Confusion Matrix: [[21  5]
 [ 1  5]]

# =========================== Tuning hyper-parameters for roc_auc

Fitting 4 folds for each of 540 candidates, totalling 2160 fits
Best parameters set found on development set:

{'clf__bootstrap': True, 'clf__max_depth': 2, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 3, 'clf__min_samples_split': 4, 'clf__n_estimators': 10}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.95      0.69      0.80        26
           1       0.38      0.83      0.53         6

   micro avg       0.72      0.72      0.72        32
   macro avg       0.67      0.76      0.66        32
weighted avg       0.84      0.72      0.75        32


Accuracy: 0.71875
Balanced Accuracy: 0.7628205128205128
Precision: 0.38461538461538464
Recall: 0.8333333333333334
F1: 0.5263157894736842
AUROC: 0.7628205128205129
Confusion Matrix: [[18  8]
 [ 1  5]]

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
==============================
 mlp 
==============================
# =========================== Tuning hyper-parameters for precision

Fitting 4 folds for each of 36 candidates, totalling 144 fits
Best parameters set found on development set:

{'clf__activation': 'tanh', 'clf__alpha': 0.0001, 'clf__hidden_layer_sizes': (300,), 'clf__solver': 'sgd'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.81      0.89        26
           1       0.55      1.00      0.71         6

   micro avg       0.84      0.84      0.84        32
   macro avg       0.77      0.90      0.80        32
weighted avg       0.91      0.84      0.86        32


Accuracy: 0.84375
Balanced Accuracy: 0.9038461538461539
Precision: 0.5454545454545454
Recall: 1.0
F1: 0.7058823529411764
AUROC: 0.9038461538461539
Confusion Matrix: [[21  5]
 [ 0  6]]

# =========================== Tuning hyper-parameters for recall

Fitting 4 folds for each of 36 candidates, totalling 144 fits
Best parameters set found on development set:

{'clf__activation': 'tanh', 'clf__alpha': 0.005, 'clf__hidden_layer_sizes': (100,), 'clf__solver': 'sgd'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.77      0.87        26
           1       0.50      1.00      0.67         6

   micro avg       0.81      0.81      0.81        32
   macro avg       0.75      0.88      0.77        32
weighted avg       0.91      0.81      0.83        32


Accuracy: 0.8125
Balanced Accuracy: 0.8846153846153846
Precision: 0.5
Recall: 1.0
F1: 0.6666666666666666
AUROC: 0.8846153846153846
Confusion Matrix: [[20  6]
 [ 0  6]]

# =========================== Tuning hyper-parameters for f1

Fitting 4 folds for each of 36 candidates, totalling 144 fits
Best parameters set found on development set:

{'clf__activation': 'tanh', 'clf__alpha': 0.0001, 'clf__hidden_layer_sizes': (300,), 'clf__solver': 'sgd'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.77      0.87        26
           1       0.50      1.00      0.67         6

   micro avg       0.81      0.81      0.81        32
   macro avg       0.75      0.88      0.77        32
weighted avg       0.91      0.81      0.83        32


Accuracy: 0.8125
Balanced Accuracy: 0.8846153846153846
Precision: 0.5
Recall: 1.0
F1: 0.6666666666666666
AUROC: 0.8846153846153846
Confusion Matrix: [[20  6]
 [ 0  6]]

# =========================== Tuning hyper-parameters for balanced_accuracy

Fitting 4 folds for each of 36 candidates, totalling 144 fits
Best parameters set found on development set:

{'clf__activation': 'tanh', 'clf__alpha': 0.0001, 'clf__hidden_layer_sizes': (32, 8, 32), 'clf__solver': 'sgd'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.81      0.89        26
           1       0.55      1.00      0.71         6

   micro avg       0.84      0.84      0.84        32
   macro avg       0.77      0.90      0.80        32
weighted avg       0.91      0.84      0.86        32


Accuracy: 0.84375
Balanced Accuracy: 0.9038461538461539
Precision: 0.5454545454545454
Recall: 1.0
F1: 0.7058823529411764
AUROC: 0.9038461538461539
Confusion Matrix: [[21  5]
 [ 0  6]]

# =========================== Tuning hyper-parameters for roc_auc

Fitting 4 folds for each of 36 candidates, totalling 144 fits
Best parameters set found on development set:

{'clf__activation': 'tanh', 'clf__alpha': 0.0001, 'clf__hidden_layer_sizes': (100,), 'clf__solver': 'sgd'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.96      0.85      0.90        26
           1       0.56      0.83      0.67         6

   micro avg       0.84      0.84      0.84        32
   macro avg       0.76      0.84      0.78        32
weighted avg       0.88      0.84      0.85        32


Accuracy: 0.84375
Balanced Accuracy: 0.8397435897435898
Precision: 0.5555555555555556
Recall: 0.8333333333333334
F1: 0.6666666666666667
AUROC: 0.8397435897435898
Confusion Matrix: [[22  4]
 [ 1  5]]

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
 Multiple Grid Search 
==============================
columns ['left_max', 'left_std', 'right_mean', 'left_mean', 'react_right_mean', 'react_left_mean', 'react_mean_pupil', 'descr_left_mean', 'descr_left_max', 'descr_mean_pupil', 'descr_right_max', 'descr_right_mean', 'descr_mean_pupil']
number of datapoint: 126
Normalize: True
Oversample: True
Oversample Mode: minmax
Drop NaN: True
==============================
==============================
Train Set Datapoints 94
Test Set Datapoints 32
==============================
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
==============================
 naive_bayes 
==============================
# =========================== Tuning hyper-parameters for precision

Fitting 4 folds for each of 5 candidates, totalling 20 fits
Best parameters set found on development set:

{'clf__var_smoothing': 1e-08}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.95      0.81      0.88        26
           1       0.50      0.83      0.62         6

   micro avg       0.81      0.81      0.81        32
   macro avg       0.73      0.82      0.75        32
weighted avg       0.87      0.81      0.83        32


Accuracy: 0.8125
Balanced Accuracy: 0.8205128205128205
Precision: 0.5
Recall: 0.8333333333333334
F1: 0.625
AUROC: 0.8205128205128206
Confusion Matrix: [[21  5]
 [ 1  5]]

# =========================== Tuning hyper-parameters for recall

Fitting 4 folds for each of 5 candidates, totalling 20 fits
Best parameters set found on development set:

{'clf__var_smoothing': 1e-09}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.95      0.81      0.88        26
           1       0.50      0.83      0.62         6

   micro avg       0.81      0.81      0.81        32
   macro avg       0.73      0.82      0.75        32
weighted avg       0.87      0.81      0.83        32


Accuracy: 0.8125
Balanced Accuracy: 0.8205128205128205
Precision: 0.5
Recall: 0.8333333333333334
F1: 0.625
AUROC: 0.8205128205128206
Confusion Matrix: [[21  5]
 [ 1  5]]

# =========================== Tuning hyper-parameters for f1

Fitting 4 folds for each of 5 candidates, totalling 20 fits
Best parameters set found on development set:

{'clf__var_smoothing': 2e-09}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.95      0.81      0.88        26
           1       0.50      0.83      0.62         6

   micro avg       0.81      0.81      0.81        32
   macro avg       0.73      0.82      0.75        32
weighted avg       0.87      0.81      0.83        32


Accuracy: 0.8125
Balanced Accuracy: 0.8205128205128205
Precision: 0.5
Recall: 0.8333333333333334
F1: 0.625
AUROC: 0.8205128205128206
Confusion Matrix: [[21  5]
 [ 1  5]]

# =========================== Tuning hyper-parameters for balanced_accuracy

Fitting 4 folds for each of 5 candidates, totalling 20 fits
Best parameters set found on development set:

{'clf__var_smoothing': 1e-08}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.95      0.81      0.88        26
           1       0.50      0.83      0.62         6

   micro avg       0.81      0.81      0.81        32
   macro avg       0.73      0.82      0.75        32
weighted avg       0.87      0.81      0.83        32


Accuracy: 0.8125
Balanced Accuracy: 0.8205128205128205
Precision: 0.5
Recall: 0.8333333333333334
F1: 0.625
AUROC: 0.8205128205128206
Confusion Matrix: [[21  5]
 [ 1  5]]

# =========================== Tuning hyper-parameters for roc_auc

Fitting 4 folds for each of 5 candidates, totalling 20 fits
Best parameters set found on development set:

{'clf__var_smoothing': 1e-08}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.81      0.89        26
           1       0.55      1.00      0.71         6

   micro avg       0.84      0.84      0.84        32
   macro avg       0.77      0.90      0.80        32
weighted avg       0.91      0.84      0.86        32


Accuracy: 0.84375
Balanced Accuracy: 0.9038461538461539
Precision: 0.5454545454545454
Recall: 1.0
F1: 0.7058823529411764
AUROC: 0.9038461538461539
Confusion Matrix: [[21  5]
 [ 0  6]]

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
==============================
 knn 
==============================
# =========================== Tuning hyper-parameters for precision

Fitting 4 folds for each of 96 candidates, totalling 384 fits
Best parameters set found on development set:

{'clf__algorithm': 'auto', 'clf__n_neighbors': 5, 'clf__p': 4, 'clf__weights': 'uniform'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.86      0.73      0.79        26
           1       0.30      0.50      0.37         6

   micro avg       0.69      0.69      0.69        32
   macro avg       0.58      0.62      0.58        32
weighted avg       0.76      0.69      0.71        32


Accuracy: 0.6875
Balanced Accuracy: 0.6153846153846154
Precision: 0.3
Recall: 0.5
F1: 0.37499999999999994
AUROC: 0.6153846153846154
Confusion Matrix: [[19  7]
 [ 3  3]]

# =========================== Tuning hyper-parameters for recall

Fitting 4 folds for each of 96 candidates, totalling 384 fits
Best parameters set found on development set:

{'clf__algorithm': 'auto', 'clf__n_neighbors': 9, 'clf__p': 1, 'clf__weights': 'uniform'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.73      0.84        26
           1       0.46      1.00      0.63         6

   micro avg       0.78      0.78      0.78        32
   macro avg       0.73      0.87      0.74        32
weighted avg       0.90      0.78      0.80        32


Accuracy: 0.78125
Balanced Accuracy: 0.8653846153846154
Precision: 0.46153846153846156
Recall: 1.0
F1: 0.631578947368421
AUROC: 0.8653846153846154
Confusion Matrix: [[19  7]
 [ 0  6]]

# =========================== Tuning hyper-parameters for f1

Fitting 4 folds for each of 96 candidates, totalling 384 fits
Best parameters set found on development set:

{'clf__algorithm': 'auto', 'clf__n_neighbors': 5, 'clf__p': 4, 'clf__weights': 'distance'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.91      0.77      0.83        26
           1       0.40      0.67      0.50         6

   micro avg       0.75      0.75      0.75        32
   macro avg       0.65      0.72      0.67        32
weighted avg       0.81      0.75      0.77        32


Accuracy: 0.75
Balanced Accuracy: 0.717948717948718
Precision: 0.4
Recall: 0.6666666666666666
F1: 0.5
AUROC: 0.7179487179487178
Confusion Matrix: [[20  6]
 [ 2  4]]

# =========================== Tuning hyper-parameters for balanced_accuracy

Fitting 4 folds for each of 96 candidates, totalling 384 fits
Best parameters set found on development set:

{'clf__algorithm': 'ball_tree', 'clf__n_neighbors': 9, 'clf__p': 1, 'clf__weights': 'uniform'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.69      0.82        26
           1       0.43      1.00      0.60         6

   micro avg       0.75      0.75      0.75        32
   macro avg       0.71      0.85      0.71        32
weighted avg       0.89      0.75      0.78        32


Accuracy: 0.75
Balanced Accuracy: 0.8461538461538461
Precision: 0.42857142857142855
Recall: 1.0
F1: 0.6
AUROC: 0.8461538461538461
Confusion Matrix: [[18  8]
 [ 0  6]]

# =========================== Tuning hyper-parameters for roc_auc

Fitting 4 folds for each of 96 candidates, totalling 384 fits
Best parameters set found on development set:

{'clf__algorithm': 'ball_tree', 'clf__n_neighbors': 7, 'clf__p': 2, 'clf__weights': 'distance'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.95      0.77      0.85        26
           1       0.45      0.83      0.59         6

   micro avg       0.78      0.78      0.78        32
   macro avg       0.70      0.80      0.72        32
weighted avg       0.86      0.78      0.80        32


Accuracy: 0.78125
Balanced Accuracy: 0.8012820512820513
Precision: 0.45454545454545453
Recall: 0.8333333333333334
F1: 0.5882352941176471
AUROC: 0.8012820512820513
Confusion Matrix: [[20  6]
 [ 1  5]]

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
==============================
 ada 
==============================
# =========================== Tuning hyper-parameters for precision

Fitting 4 folds for each of 40 candidates, totalling 160 fits
Best parameters set found on development set:

{'clf__algorithm': 'SAMME.R', 'clf__learning_rate': 0.01, 'clf__n_estimators': 10}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.95      0.77      0.85        26
           1       0.45      0.83      0.59         6

   micro avg       0.78      0.78      0.78        32
   macro avg       0.70      0.80      0.72        32
weighted avg       0.86      0.78      0.80        32


Accuracy: 0.78125
Balanced Accuracy: 0.8012820512820513
Precision: 0.45454545454545453
Recall: 0.8333333333333334
F1: 0.5882352941176471
AUROC: 0.8012820512820513
Confusion Matrix: [[20  6]
 [ 1  5]]

# =========================== Tuning hyper-parameters for recall

Fitting 4 folds for each of 40 candidates, totalling 160 fits
Best parameters set found on development set:

{'clf__algorithm': 'SAMME', 'clf__learning_rate': 0.01, 'clf__n_estimators': 10}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.95      0.81      0.88        26
           1       0.50      0.83      0.62         6

   micro avg       0.81      0.81      0.81        32
   macro avg       0.73      0.82      0.75        32
weighted avg       0.87      0.81      0.83        32


Accuracy: 0.8125
Balanced Accuracy: 0.8205128205128205
Precision: 0.5
Recall: 0.8333333333333334
F1: 0.625
AUROC: 0.8205128205128206
Confusion Matrix: [[21  5]
 [ 1  5]]

# =========================== Tuning hyper-parameters for f1

Fitting 4 folds for each of 40 candidates, totalling 160 fits
Best parameters set found on development set:

{'clf__algorithm': 'SAMME', 'clf__learning_rate': 0.01, 'clf__n_estimators': 10}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.95      0.81      0.88        26
           1       0.50      0.83      0.62         6

   micro avg       0.81      0.81      0.81        32
   macro avg       0.73      0.82      0.75        32
weighted avg       0.87      0.81      0.83        32


Accuracy: 0.8125
Balanced Accuracy: 0.8205128205128205
Precision: 0.5
Recall: 0.8333333333333334
F1: 0.625
AUROC: 0.8205128205128206
Confusion Matrix: [[21  5]
 [ 1  5]]

# =========================== Tuning hyper-parameters for balanced_accuracy

Fitting 4 folds for each of 40 candidates, totalling 160 fits
Best parameters set found on development set:

{'clf__algorithm': 'SAMME', 'clf__learning_rate': 0.05, 'clf__n_estimators': 10}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.95      0.77      0.85        26
           1       0.45      0.83      0.59         6

   micro avg       0.78      0.78      0.78        32
   macro avg       0.70      0.80      0.72        32
weighted avg       0.86      0.78      0.80        32


Accuracy: 0.78125
Balanced Accuracy: 0.8012820512820513
Precision: 0.45454545454545453
Recall: 0.8333333333333334
F1: 0.5882352941176471
AUROC: 0.8012820512820513
Confusion Matrix: [[20  6]
 [ 1  5]]

# =========================== Tuning hyper-parameters for roc_auc

Fitting 4 folds for each of 40 candidates, totalling 160 fits
Best parameters set found on development set:

{'clf__algorithm': 'SAMME', 'clf__learning_rate': 0.3, 'clf__n_estimators': 10}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.96      0.85      0.90        26
           1       0.56      0.83      0.67         6

   micro avg       0.84      0.84      0.84        32
   macro avg       0.76      0.84      0.78        32
weighted avg       0.88      0.84      0.85        32


Accuracy: 0.84375
Balanced Accuracy: 0.8397435897435898
Precision: 0.5555555555555556
Recall: 0.8333333333333334
F1: 0.6666666666666667
AUROC: 0.8397435897435898
Confusion Matrix: [[22  4]
 [ 1  5]]

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
==============================
 svm 
==============================
# =========================== Tuning hyper-parameters for precision

Fitting 4 folds for each of 81 candidates, totalling 324 fits
Best parameters set found on development set:

{'clf__C': 1000, 'clf__gamma': 0.1, 'clf__kernel': 'rbf'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.82      0.88      0.85        26
           1       0.25      0.17      0.20         6

   micro avg       0.75      0.75      0.75        32
   macro avg       0.54      0.53      0.53        32
weighted avg       0.71      0.75      0.73        32


Accuracy: 0.75
Balanced Accuracy: 0.5256410256410257
Precision: 0.25
Recall: 0.16666666666666666
F1: 0.2
AUROC: 0.5256410256410257
Confusion Matrix: [[23  3]
 [ 5  1]]

# =========================== Tuning hyper-parameters for recall

Fitting 4 folds for each of 81 candidates, totalling 324 fits
Best parameters set found on development set:

{'clf__C': 0.001, 'clf__gamma': 0.001, 'clf__kernel': 'rbf'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.46      0.63        26
           1       0.30      1.00      0.46         6

   micro avg       0.56      0.56      0.56        32
   macro avg       0.65      0.73      0.55        32
weighted avg       0.87      0.56      0.60        32


Accuracy: 0.5625
Balanced Accuracy: 0.7307692307692308
Precision: 0.3
Recall: 1.0
F1: 0.4615384615384615
AUROC: 0.7307692307692308
Confusion Matrix: [[12 14]
 [ 0  6]]

# =========================== Tuning hyper-parameters for f1

Fitting 4 folds for each of 81 candidates, totalling 324 fits
Best parameters set found on development set:

{'clf__C': 25, 'clf__gamma': 0.01, 'clf__kernel': 'sigmoid'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.73      0.84        26
           1       0.46      1.00      0.63         6

   micro avg       0.78      0.78      0.78        32
   macro avg       0.73      0.87      0.74        32
weighted avg       0.90      0.78      0.80        32


Accuracy: 0.78125
Balanced Accuracy: 0.8653846153846154
Precision: 0.46153846153846156
Recall: 1.0
F1: 0.631578947368421
AUROC: 0.8653846153846154
Confusion Matrix: [[19  7]
 [ 0  6]]

# =========================== Tuning hyper-parameters for balanced_accuracy

Fitting 4 folds for each of 81 candidates, totalling 324 fits
Best parameters set found on development set:

{'clf__C': 10, 'clf__gamma': 0.001, 'clf__kernel': 'rbf'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.73      0.84        26
           1       0.46      1.00      0.63         6

   micro avg       0.78      0.78      0.78        32
   macro avg       0.73      0.87      0.74        32
weighted avg       0.90      0.78      0.80        32


Accuracy: 0.78125
Balanced Accuracy: 0.8653846153846154
Precision: 0.46153846153846156
Recall: 1.0
F1: 0.631578947368421
AUROC: 0.8653846153846154
Confusion Matrix: [[19  7]
 [ 0  6]]

# =========================== Tuning hyper-parameters for roc_auc

Fitting 4 folds for each of 81 candidates, totalling 324 fits
Best parameters set found on development set:

{'clf__C': 100, 'clf__gamma': 0.1, 'clf__kernel': 'rbf'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.86      0.96      0.91        26
           1       0.67      0.33      0.44         6

   micro avg       0.84      0.84      0.84        32
   macro avg       0.76      0.65      0.68        32
weighted avg       0.83      0.84      0.82        32


Accuracy: 0.84375
Balanced Accuracy: 0.6474358974358975
Precision: 0.6666666666666666
Recall: 0.3333333333333333
F1: 0.4444444444444444
AUROC: 0.6474358974358974
Confusion Matrix: [[25  1]
 [ 4  2]]

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
==============================
 decision_tree 
==============================
# =========================== Tuning hyper-parameters for precision

Fitting 4 folds for each of 1200 candidates, totalling 4800 fits
Best parameters set found on development set:

{'clf__criterion': 'gini', 'clf__max_depth': 6, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 5, 'clf__min_samples_split': 3, 'clf__splitter': 'best'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.88      0.85      0.86        26
           1       0.43      0.50      0.46         6

   micro avg       0.78      0.78      0.78        32
   macro avg       0.65      0.67      0.66        32
weighted avg       0.80      0.78      0.79        32


Accuracy: 0.78125
Balanced Accuracy: 0.6730769230769231
Precision: 0.42857142857142855
Recall: 0.5
F1: 0.4615384615384615
AUROC: 0.673076923076923
Confusion Matrix: [[22  4]
 [ 3  3]]

# =========================== Tuning hyper-parameters for recall

Fitting 4 folds for each of 1200 candidates, totalling 4800 fits
Best parameters set found on development set:

{'clf__criterion': 'entropy', 'clf__max_depth': 2, 'clf__max_features': 'auto', 'clf__min_samples_leaf': 5, 'clf__min_samples_split': 5, 'clf__splitter': 'random'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.96      0.96      0.96        26
           1       0.83      0.83      0.83         6

   micro avg       0.94      0.94      0.94        32
   macro avg       0.90      0.90      0.90        32
weighted avg       0.94      0.94      0.94        32


Accuracy: 0.9375
Balanced Accuracy: 0.8974358974358975
Precision: 0.8333333333333334
Recall: 0.8333333333333334
F1: 0.8333333333333334
AUROC: 0.8974358974358976
Confusion Matrix: [[25  1]
 [ 1  5]]

# =========================== Tuning hyper-parameters for f1

Fitting 4 folds for each of 1200 candidates, totalling 4800 fits
Best parameters set found on development set:

{'clf__criterion': 'gini', 'clf__max_depth': 2, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 3, 'clf__min_samples_split': 5, 'clf__splitter': 'best'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.95      0.77      0.85        26
           1       0.45      0.83      0.59         6

   micro avg       0.78      0.78      0.78        32
   macro avg       0.70      0.80      0.72        32
weighted avg       0.86      0.78      0.80        32


Accuracy: 0.78125
Balanced Accuracy: 0.8012820512820513
Precision: 0.45454545454545453
Recall: 0.8333333333333334
F1: 0.5882352941176471
AUROC: 0.8012820512820513
Confusion Matrix: [[20  6]
 [ 1  5]]

# =========================== Tuning hyper-parameters for balanced_accuracy

Fitting 4 folds for each of 1200 candidates, totalling 4800 fits
Best parameters set found on development set:

{'clf__criterion': 'gini', 'clf__max_depth': 8, 'clf__max_features': 'auto', 'clf__min_samples_leaf': 5, 'clf__min_samples_split': 4, 'clf__splitter': 'random'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.81      0.89        26
           1       0.55      1.00      0.71         6

   micro avg       0.84      0.84      0.84        32
   macro avg       0.77      0.90      0.80        32
weighted avg       0.91      0.84      0.86        32


Accuracy: 0.84375
Balanced Accuracy: 0.9038461538461539
Precision: 0.5454545454545454
Recall: 1.0
F1: 0.7058823529411764
AUROC: 0.9038461538461539
Confusion Matrix: [[21  5]
 [ 0  6]]

# =========================== Tuning hyper-parameters for roc_auc

Fitting 4 folds for each of 1200 candidates, totalling 4800 fits
Best parameters set found on development set:

{'clf__criterion': 'gini', 'clf__max_depth': 6, 'clf__max_features': 'auto', 'clf__min_samples_leaf': 4, 'clf__min_samples_split': 2, 'clf__splitter': 'best'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.88      0.88      0.88        26
           1       0.50      0.50      0.50         6

   micro avg       0.81      0.81      0.81        32
   macro avg       0.69      0.69      0.69        32
weighted avg       0.81      0.81      0.81        32


Accuracy: 0.8125
Balanced Accuracy: 0.6923076923076923
Precision: 0.5
Recall: 0.5
F1: 0.5
AUROC: 0.6923076923076923
Confusion Matrix: [[23  3]
 [ 3  3]]

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
==============================
 random_forest 
==============================
# =========================== Tuning hyper-parameters for precision

Fitting 4 folds for each of 540 candidates, totalling 2160 fits
Best parameters set found on development set:

{'clf__bootstrap': False, 'clf__max_depth': 10, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 3, 'clf__min_samples_split': 6, 'clf__n_estimators': 10}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.92      0.88      0.90        26
           1       0.57      0.67      0.62         6

   micro avg       0.84      0.84      0.84        32
   macro avg       0.75      0.78      0.76        32
weighted avg       0.85      0.84      0.85        32


Accuracy: 0.84375
Balanced Accuracy: 0.7756410256410255
Precision: 0.5714285714285714
Recall: 0.6666666666666666
F1: 0.6153846153846153
AUROC: 0.7756410256410255
Confusion Matrix: [[23  3]
 [ 2  4]]

# =========================== Tuning hyper-parameters for recall

Fitting 4 folds for each of 540 candidates, totalling 2160 fits
Best parameters set found on development set:

{'clf__bootstrap': True, 'clf__max_depth': 2, 'clf__max_features': 'auto', 'clf__min_samples_leaf': 5, 'clf__min_samples_split': 2, 'clf__n_estimators': 10}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.77      0.87        26
           1       0.50      1.00      0.67         6

   micro avg       0.81      0.81      0.81        32
   macro avg       0.75      0.88      0.77        32
weighted avg       0.91      0.81      0.83        32


Accuracy: 0.8125
Balanced Accuracy: 0.8846153846153846
Precision: 0.5
Recall: 1.0
F1: 0.6666666666666666
AUROC: 0.8846153846153846
Confusion Matrix: [[20  6]
 [ 0  6]]

# =========================== Tuning hyper-parameters for f1

Fitting 4 folds for each of 540 candidates, totalling 2160 fits
Best parameters set found on development set:

{'clf__bootstrap': True, 'clf__max_depth': 10, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 5, 'clf__min_samples_split': 4, 'clf__n_estimators': 100}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.96      0.85      0.90        26
           1       0.56      0.83      0.67         6

   micro avg       0.84      0.84      0.84        32
   macro avg       0.76      0.84      0.78        32
weighted avg       0.88      0.84      0.85        32


Accuracy: 0.84375
Balanced Accuracy: 0.8397435897435898
Precision: 0.5555555555555556
Recall: 0.8333333333333334
F1: 0.6666666666666667
AUROC: 0.8397435897435898
Confusion Matrix: [[22  4]
 [ 1  5]]

# =========================== Tuning hyper-parameters for balanced_accuracy

Fitting 4 folds for each of 540 candidates, totalling 2160 fits
Best parameters set found on development set:

{'clf__bootstrap': True, 'clf__max_depth': 10, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 5, 'clf__min_samples_split': 2, 'clf__n_estimators': 100}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.81      0.89        26
           1       0.55      1.00      0.71         6

   micro avg       0.84      0.84      0.84        32
   macro avg       0.77      0.90      0.80        32
weighted avg       0.91      0.84      0.86        32


Accuracy: 0.84375
Balanced Accuracy: 0.9038461538461539
Precision: 0.5454545454545454
Recall: 1.0
F1: 0.7058823529411764
AUROC: 0.9038461538461539
Confusion Matrix: [[21  5]
 [ 0  6]]

# =========================== Tuning hyper-parameters for roc_auc

Fitting 4 folds for each of 540 candidates, totalling 2160 fits
Best parameters set found on development set:

{'clf__bootstrap': False, 'clf__max_depth': 10, 'clf__max_features': 'auto', 'clf__min_samples_leaf': 3, 'clf__min_samples_split': 6, 'clf__n_estimators': 10}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.95      0.81      0.88        26
           1       0.50      0.83      0.62         6

   micro avg       0.81      0.81      0.81        32
   macro avg       0.73      0.82      0.75        32
weighted avg       0.87      0.81      0.83        32


Accuracy: 0.8125
Balanced Accuracy: 0.8205128205128205
Precision: 0.5
Recall: 0.8333333333333334
F1: 0.625
AUROC: 0.8205128205128206
Confusion Matrix: [[21  5]
 [ 1  5]]

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
==============================
 mlp 
==============================
# =========================== Tuning hyper-parameters for precision

Fitting 4 folds for each of 36 candidates, totalling 144 fits
Best parameters set found on development set:

{'clf__activation': 'relu', 'clf__alpha': 0.05, 'clf__hidden_layer_sizes': (32, 8, 32), 'clf__solver': 'adam'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.89      0.92      0.91        26
           1       0.60      0.50      0.55         6

   micro avg       0.84      0.84      0.84        32
   macro avg       0.74      0.71      0.73        32
weighted avg       0.83      0.84      0.84        32


Accuracy: 0.84375
Balanced Accuracy: 0.7115384615384616
Precision: 0.6
Recall: 0.5
F1: 0.5454545454545454
AUROC: 0.7115384615384616
Confusion Matrix: [[24  2]
 [ 3  3]]

# =========================== Tuning hyper-parameters for recall

Fitting 4 folds for each of 36 candidates, totalling 144 fits
Best parameters set found on development set:

{'clf__activation': 'relu', 'clf__alpha': 0.005, 'clf__hidden_layer_sizes': (300,), 'clf__solver': 'sgd'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.85      0.92        26
           1       0.60      1.00      0.75         6

   micro avg       0.88      0.88      0.88        32
   macro avg       0.80      0.92      0.83        32
weighted avg       0.93      0.88      0.89        32


Accuracy: 0.875
Balanced Accuracy: 0.9230769230769231
Precision: 0.6
Recall: 1.0
F1: 0.7499999999999999
AUROC: 0.9230769230769231
Confusion Matrix: [[22  4]
 [ 0  6]]

# =========================== Tuning hyper-parameters for f1

Fitting 4 folds for each of 36 candidates, totalling 144 fits
Best parameters set found on development set:

{'clf__activation': 'relu', 'clf__alpha': 0.005, 'clf__hidden_layer_sizes': (100,), 'clf__solver': 'sgd'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.85      0.92        26
           1       0.60      1.00      0.75         6

   micro avg       0.88      0.88      0.88        32
   macro avg       0.80      0.92      0.83        32
weighted avg       0.93      0.88      0.89        32


Accuracy: 0.875
Balanced Accuracy: 0.9230769230769231
Precision: 0.6
Recall: 1.0
F1: 0.7499999999999999
AUROC: 0.9230769230769231
Confusion Matrix: [[22  4]
 [ 0  6]]

# =========================== Tuning hyper-parameters for balanced_accuracy

Fitting 4 folds for each of 36 candidates, totalling 144 fits
Best parameters set found on development set:

{'clf__activation': 'tanh', 'clf__alpha': 0.0001, 'clf__hidden_layer_sizes': (100,), 'clf__solver': 'adam'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.92      0.85      0.88        26
           1       0.50      0.67      0.57         6

   micro avg       0.81      0.81      0.81        32
   macro avg       0.71      0.76      0.73        32
weighted avg       0.84      0.81      0.82        32


Accuracy: 0.8125
Balanced Accuracy: 0.7564102564102564
Precision: 0.5
Recall: 0.6666666666666666
F1: 0.5714285714285715
AUROC: 0.7564102564102564
Confusion Matrix: [[22  4]
 [ 2  4]]

# =========================== Tuning hyper-parameters for roc_auc

Fitting 4 folds for each of 36 candidates, totalling 144 fits
Best parameters set found on development set:

{'clf__activation': 'relu', 'clf__alpha': 0.005, 'clf__hidden_layer_sizes': (32, 8, 32), 'clf__solver': 'sgd'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.95      0.81      0.88        26
           1       0.50      0.83      0.62         6

   micro avg       0.81      0.81      0.81        32
   macro avg       0.73      0.82      0.75        32
weighted avg       0.87      0.81      0.83        32


Accuracy: 0.8125
Balanced Accuracy: 0.8205128205128205
Precision: 0.5
Recall: 0.8333333333333334
F1: 0.625
AUROC: 0.8205128205128206
Confusion Matrix: [[21  5]
 [ 1  5]]

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
 Multiple Grid Search 
==============================
columns ['left_max', 'descr_left_max', 'react_right_mean', 'react_mean_pupil', 'descr_right_max', 'react_left_mean', 'right_mean', 'left_mean', 'descr_right_mean', 'descr_left_mean', 'descr_mean_pupil']
number of datapoint: 126
Normalize: True
Oversample: True
Oversample Mode: minmax
Drop NaN: True
==============================
==============================
Train Set Datapoints 94
Test Set Datapoints 32
==============================
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
==============================
 naive_bayes 
==============================
# =========================== Tuning hyper-parameters for precision

Fitting 4 folds for each of 5 candidates, totalling 20 fits
Best parameters set found on development set:

{'clf__var_smoothing': 2e-09}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.95      0.81      0.88        26
           1       0.50      0.83      0.62         6

   micro avg       0.81      0.81      0.81        32
   macro avg       0.73      0.82      0.75        32
weighted avg       0.87      0.81      0.83        32


Accuracy: 0.8125
Balanced Accuracy: 0.8205128205128205
Precision: 0.5
Recall: 0.8333333333333334
F1: 0.625
AUROC: 0.8205128205128206
Confusion Matrix: [[21  5]
 [ 1  5]]

# =========================== Tuning hyper-parameters for recall

Fitting 4 folds for each of 5 candidates, totalling 20 fits
Best parameters set found on development set:

{'clf__var_smoothing': 1e-09}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.95      0.77      0.85        26
           1       0.45      0.83      0.59         6

   micro avg       0.78      0.78      0.78        32
   macro avg       0.70      0.80      0.72        32
weighted avg       0.86      0.78      0.80        32


Accuracy: 0.78125
Balanced Accuracy: 0.8012820512820513
Precision: 0.45454545454545453
Recall: 0.8333333333333334
F1: 0.5882352941176471
AUROC: 0.8012820512820513
Confusion Matrix: [[20  6]
 [ 1  5]]

# =========================== Tuning hyper-parameters for f1

Fitting 4 folds for each of 5 candidates, totalling 20 fits
Best parameters set found on development set:

{'clf__var_smoothing': 2e-09}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.95      0.81      0.88        26
           1       0.50      0.83      0.62         6

   micro avg       0.81      0.81      0.81        32
   macro avg       0.73      0.82      0.75        32
weighted avg       0.87      0.81      0.83        32


Accuracy: 0.8125
Balanced Accuracy: 0.8205128205128205
Precision: 0.5
Recall: 0.8333333333333334
F1: 0.625
AUROC: 0.8205128205128206
Confusion Matrix: [[21  5]
 [ 1  5]]

# =========================== Tuning hyper-parameters for balanced_accuracy

Fitting 4 folds for each of 5 candidates, totalling 20 fits
Best parameters set found on development set:

{'clf__var_smoothing': 1e-09}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.95      0.81      0.88        26
           1       0.50      0.83      0.62         6

   micro avg       0.81      0.81      0.81        32
   macro avg       0.73      0.82      0.75        32
weighted avg       0.87      0.81      0.83        32


Accuracy: 0.8125
Balanced Accuracy: 0.8205128205128205
Precision: 0.5
Recall: 0.8333333333333334
F1: 0.625
AUROC: 0.8205128205128206
Confusion Matrix: [[21  5]
 [ 1  5]]

# =========================== Tuning hyper-parameters for roc_auc

Fitting 4 folds for each of 5 candidates, totalling 20 fits
Best parameters set found on development set:

{'clf__var_smoothing': 1e-09}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.95      0.77      0.85        26
           1       0.45      0.83      0.59         6

   micro avg       0.78      0.78      0.78        32
   macro avg       0.70      0.80      0.72        32
weighted avg       0.86      0.78      0.80        32


Accuracy: 0.78125
Balanced Accuracy: 0.8012820512820513
Precision: 0.45454545454545453
Recall: 0.8333333333333334
F1: 0.5882352941176471
AUROC: 0.8012820512820513
Confusion Matrix: [[20  6]
 [ 1  5]]

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
==============================
 knn 
==============================
# =========================== Tuning hyper-parameters for precision

Fitting 4 folds for each of 96 candidates, totalling 384 fits
Best parameters set found on development set:

{'clf__algorithm': 'auto', 'clf__n_neighbors': 9, 'clf__p': 1, 'clf__weights': 'uniform'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.77      0.87        26
           1       0.50      1.00      0.67         6

   micro avg       0.81      0.81      0.81        32
   macro avg       0.75      0.88      0.77        32
weighted avg       0.91      0.81      0.83        32


Accuracy: 0.8125
Balanced Accuracy: 0.8846153846153846
Precision: 0.5
Recall: 1.0
F1: 0.6666666666666666
AUROC: 0.8846153846153846
Confusion Matrix: [[20  6]
 [ 0  6]]

# =========================== Tuning hyper-parameters for recall

Fitting 4 folds for each of 96 candidates, totalling 384 fits
Best parameters set found on development set:

{'clf__algorithm': 'auto', 'clf__n_neighbors': 7, 'clf__p': 1, 'clf__weights': 'uniform'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.69      0.82        26
           1       0.43      1.00      0.60         6

   micro avg       0.75      0.75      0.75        32
   macro avg       0.71      0.85      0.71        32
weighted avg       0.89      0.75      0.78        32


Accuracy: 0.75
Balanced Accuracy: 0.8461538461538461
Precision: 0.42857142857142855
Recall: 1.0
F1: 0.6
AUROC: 0.8461538461538461
Confusion Matrix: [[18  8]
 [ 0  6]]

# =========================== Tuning hyper-parameters for f1

Fitting 4 folds for each of 96 candidates, totalling 384 fits
Best parameters set found on development set:

{'clf__algorithm': 'ball_tree', 'clf__n_neighbors': 7, 'clf__p': 1, 'clf__weights': 'uniform'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.69      0.82        26
           1       0.43      1.00      0.60         6

   micro avg       0.75      0.75      0.75        32
   macro avg       0.71      0.85      0.71        32
weighted avg       0.89      0.75      0.78        32


Accuracy: 0.75
Balanced Accuracy: 0.8461538461538461
Precision: 0.42857142857142855
Recall: 1.0
F1: 0.6
AUROC: 0.8461538461538461
Confusion Matrix: [[18  8]
 [ 0  6]]

# =========================== Tuning hyper-parameters for balanced_accuracy

Fitting 4 folds for each of 96 candidates, totalling 384 fits
Best parameters set found on development set:

{'clf__algorithm': 'kd_tree', 'clf__n_neighbors': 7, 'clf__p': 1, 'clf__weights': 'uniform'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.73      0.84        26
           1       0.46      1.00      0.63         6

   micro avg       0.78      0.78      0.78        32
   macro avg       0.73      0.87      0.74        32
weighted avg       0.90      0.78      0.80        32


Accuracy: 0.78125
Balanced Accuracy: 0.8653846153846154
Precision: 0.46153846153846156
Recall: 1.0
F1: 0.631578947368421
AUROC: 0.8653846153846154
Confusion Matrix: [[19  7]
 [ 0  6]]

# =========================== Tuning hyper-parameters for roc_auc

Fitting 4 folds for each of 96 candidates, totalling 384 fits
Best parameters set found on development set:

{'clf__algorithm': 'auto', 'clf__n_neighbors': 9, 'clf__p': 1, 'clf__weights': 'uniform'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.65      0.79        26
           1       0.40      1.00      0.57         6

   micro avg       0.72      0.72      0.72        32
   macro avg       0.70      0.83      0.68        32
weighted avg       0.89      0.72      0.75        32


Accuracy: 0.71875
Balanced Accuracy: 0.8269230769230769
Precision: 0.4
Recall: 1.0
F1: 0.5714285714285715
AUROC: 0.8269230769230769
Confusion Matrix: [[17  9]
 [ 0  6]]

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
==============================
 ada 
==============================
# =========================== Tuning hyper-parameters for precision

Fitting 4 folds for each of 40 candidates, totalling 160 fits
Best parameters set found on development set:

{'clf__algorithm': 'SAMME', 'clf__learning_rate': 0.1, 'clf__n_estimators': 10}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.95      0.81      0.88        26
           1       0.50      0.83      0.62         6

   micro avg       0.81      0.81      0.81        32
   macro avg       0.73      0.82      0.75        32
weighted avg       0.87      0.81      0.83        32


Accuracy: 0.8125
Balanced Accuracy: 0.8205128205128205
Precision: 0.5
Recall: 0.8333333333333334
F1: 0.625
AUROC: 0.8205128205128206
Confusion Matrix: [[21  5]
 [ 1  5]]

# =========================== Tuning hyper-parameters for recall

Fitting 4 folds for each of 40 candidates, totalling 160 fits
Best parameters set found on development set:

{'clf__algorithm': 'SAMME', 'clf__learning_rate': 0.05, 'clf__n_estimators': 10}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.95      0.81      0.88        26
           1       0.50      0.83      0.62         6

   micro avg       0.81      0.81      0.81        32
   macro avg       0.73      0.82      0.75        32
weighted avg       0.87      0.81      0.83        32


Accuracy: 0.8125
Balanced Accuracy: 0.8205128205128205
Precision: 0.5
Recall: 0.8333333333333334
F1: 0.625
AUROC: 0.8205128205128206
Confusion Matrix: [[21  5]
 [ 1  5]]

# =========================== Tuning hyper-parameters for f1

Fitting 4 folds for each of 40 candidates, totalling 160 fits
Best parameters set found on development set:

{'clf__algorithm': 'SAMME', 'clf__learning_rate': 0.05, 'clf__n_estimators': 10}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.95      0.81      0.88        26
           1       0.50      0.83      0.62         6

   micro avg       0.81      0.81      0.81        32
   macro avg       0.73      0.82      0.75        32
weighted avg       0.87      0.81      0.83        32


Accuracy: 0.8125
Balanced Accuracy: 0.8205128205128205
Precision: 0.5
Recall: 0.8333333333333334
F1: 0.625
AUROC: 0.8205128205128206
Confusion Matrix: [[21  5]
 [ 1  5]]

# =========================== Tuning hyper-parameters for balanced_accuracy

Fitting 4 folds for each of 40 candidates, totalling 160 fits
Best parameters set found on development set:

{'clf__algorithm': 'SAMME', 'clf__learning_rate': 0.1, 'clf__n_estimators': 10}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.95      0.77      0.85        26
           1       0.45      0.83      0.59         6

   micro avg       0.78      0.78      0.78        32
   macro avg       0.70      0.80      0.72        32
weighted avg       0.86      0.78      0.80        32


Accuracy: 0.78125
Balanced Accuracy: 0.8012820512820513
Precision: 0.45454545454545453
Recall: 0.8333333333333334
F1: 0.5882352941176471
AUROC: 0.8012820512820513
Confusion Matrix: [[20  6]
 [ 1  5]]

# =========================== Tuning hyper-parameters for roc_auc

Fitting 4 folds for each of 40 candidates, totalling 160 fits
Best parameters set found on development set:

{'clf__algorithm': 'SAMME', 'clf__learning_rate': 0.1, 'clf__n_estimators': 10}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.95      0.77      0.85        26
           1       0.45      0.83      0.59         6

   micro avg       0.78      0.78      0.78        32
   macro avg       0.70      0.80      0.72        32
weighted avg       0.86      0.78      0.80        32


Accuracy: 0.78125
Balanced Accuracy: 0.8012820512820513
Precision: 0.45454545454545453
Recall: 0.8333333333333334
F1: 0.5882352941176471
AUROC: 0.8012820512820513
Confusion Matrix: [[20  6]
 [ 1  5]]

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
==============================
 svm 
==============================
# =========================== Tuning hyper-parameters for precision

Fitting 4 folds for each of 81 candidates, totalling 324 fits
Best parameters set found on development set:

{'clf__C': 1, 'clf__gamma': 1, 'clf__kernel': 'rbf'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.96      0.85      0.90        26
           1       0.56      0.83      0.67         6

   micro avg       0.84      0.84      0.84        32
   macro avg       0.76      0.84      0.78        32
weighted avg       0.88      0.84      0.85        32


Accuracy: 0.84375
Balanced Accuracy: 0.8397435897435898
Precision: 0.5555555555555556
Recall: 0.8333333333333334
F1: 0.6666666666666667
AUROC: 0.8397435897435898
Confusion Matrix: [[22  4]
 [ 1  5]]

# =========================== Tuning hyper-parameters for recall

Fitting 4 folds for each of 81 candidates, totalling 324 fits
Best parameters set found on development set:

{'clf__C': 0.001, 'clf__gamma': 0.001, 'clf__kernel': 'rbf'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.42      0.59        26
           1       0.29      1.00      0.44         6

   micro avg       0.53      0.53      0.53        32
   macro avg       0.64      0.71      0.52        32
weighted avg       0.87      0.53      0.57        32


Accuracy: 0.53125
Balanced Accuracy: 0.7115384615384616
Precision: 0.2857142857142857
Recall: 1.0
F1: 0.4444444444444445
AUROC: 0.7115384615384616
Confusion Matrix: [[11 15]
 [ 0  6]]

# =========================== Tuning hyper-parameters for f1

Fitting 4 folds for each of 81 candidates, totalling 324 fits
Best parameters set found on development set:

{'clf__C': 1000, 'clf__gamma': 0.0001, 'clf__kernel': 'rbf'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.69      0.82        26
           1       0.43      1.00      0.60         6

   micro avg       0.75      0.75      0.75        32
   macro avg       0.71      0.85      0.71        32
weighted avg       0.89      0.75      0.78        32


Accuracy: 0.75
Balanced Accuracy: 0.8461538461538461
Precision: 0.42857142857142855
Recall: 1.0
F1: 0.6
AUROC: 0.8461538461538461
Confusion Matrix: [[18  8]
 [ 0  6]]

# =========================== Tuning hyper-parameters for balanced_accuracy

Fitting 4 folds for each of 81 candidates, totalling 324 fits
Best parameters set found on development set:

{'clf__C': 100, 'clf__gamma': 0.001, 'clf__kernel': 'rbf'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.73      0.84        26
           1       0.46      1.00      0.63         6

   micro avg       0.78      0.78      0.78        32
   macro avg       0.73      0.87      0.74        32
weighted avg       0.90      0.78      0.80        32


Accuracy: 0.78125
Balanced Accuracy: 0.8653846153846154
Precision: 0.46153846153846156
Recall: 1.0
F1: 0.631578947368421
AUROC: 0.8653846153846154
Confusion Matrix: [[19  7]
 [ 0  6]]

# =========================== Tuning hyper-parameters for roc_auc

Fitting 4 folds for each of 81 candidates, totalling 324 fits
Best parameters set found on development set:

{'clf__C': 100, 'clf__gamma': 0.01, 'clf__kernel': 'rbf'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.77      0.87        26
           1       0.50      1.00      0.67         6

   micro avg       0.81      0.81      0.81        32
   macro avg       0.75      0.88      0.77        32
weighted avg       0.91      0.81      0.83        32


Accuracy: 0.8125
Balanced Accuracy: 0.8846153846153846
Precision: 0.5
Recall: 1.0
F1: 0.6666666666666666
AUROC: 0.8846153846153846
Confusion Matrix: [[20  6]
 [ 0  6]]

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
==============================
 decision_tree 
==============================
# =========================== Tuning hyper-parameters for precision

Fitting 4 folds for each of 1200 candidates, totalling 4800 fits
Best parameters set found on development set:

{'clf__criterion': 'entropy', 'clf__max_depth': 10, 'clf__max_features': 'auto', 'clf__min_samples_leaf': 2, 'clf__min_samples_split': 5, 'clf__splitter': 'random'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.95      0.73      0.83        26
           1       0.42      0.83      0.56         6

   micro avg       0.75      0.75      0.75        32
   macro avg       0.68      0.78      0.69        32
weighted avg       0.85      0.75      0.78        32


Accuracy: 0.75
Balanced Accuracy: 0.782051282051282
Precision: 0.4166666666666667
Recall: 0.8333333333333334
F1: 0.5555555555555556
AUROC: 0.7820512820512822
Confusion Matrix: [[19  7]
 [ 1  5]]

# =========================== Tuning hyper-parameters for recall

Fitting 4 folds for each of 1200 candidates, totalling 4800 fits
Best parameters set found on development set:

{'clf__criterion': 'gini', 'clf__max_depth': 4, 'clf__max_features': 'auto', 'clf__min_samples_leaf': 3, 'clf__min_samples_split': 2, 'clf__splitter': 'random'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.62      0.76        26
           1       0.38      1.00      0.55         6

   micro avg       0.69      0.69      0.69        32
   macro avg       0.69      0.81      0.65        32
weighted avg       0.88      0.69      0.72        32


Accuracy: 0.6875
Balanced Accuracy: 0.8076923076923077
Precision: 0.375
Recall: 1.0
F1: 0.5454545454545454
AUROC: 0.8076923076923077
Confusion Matrix: [[16 10]
 [ 0  6]]

# =========================== Tuning hyper-parameters for f1

Fitting 4 folds for each of 1200 candidates, totalling 4800 fits
Best parameters set found on development set:

{'clf__criterion': 'gini', 'clf__max_depth': 2, 'clf__max_features': 'auto', 'clf__min_samples_leaf': 2, 'clf__min_samples_split': 4, 'clf__splitter': 'best'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.95      0.81      0.88        26
           1       0.50      0.83      0.62         6

   micro avg       0.81      0.81      0.81        32
   macro avg       0.73      0.82      0.75        32
weighted avg       0.87      0.81      0.83        32


Accuracy: 0.8125
Balanced Accuracy: 0.8205128205128205
Precision: 0.5
Recall: 0.8333333333333334
F1: 0.625
AUROC: 0.8205128205128206
Confusion Matrix: [[21  5]
 [ 1  5]]

# =========================== Tuning hyper-parameters for balanced_accuracy

Fitting 4 folds for each of 1200 candidates, totalling 4800 fits
Best parameters set found on development set:

{'clf__criterion': 'gini', 'clf__max_depth': 4, 'clf__max_features': 'auto', 'clf__min_samples_leaf': 3, 'clf__min_samples_split': 2, 'clf__splitter': 'random'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.95      0.73      0.83        26
           1       0.42      0.83      0.56         6

   micro avg       0.75      0.75      0.75        32
   macro avg       0.68      0.78      0.69        32
weighted avg       0.85      0.75      0.78        32


Accuracy: 0.75
Balanced Accuracy: 0.782051282051282
Precision: 0.4166666666666667
Recall: 0.8333333333333334
F1: 0.5555555555555556
AUROC: 0.7820512820512822
Confusion Matrix: [[19  7]
 [ 1  5]]

# =========================== Tuning hyper-parameters for roc_auc

Fitting 4 folds for each of 1200 candidates, totalling 4800 fits
Best parameters set found on development set:

{'clf__criterion': 'gini', 'clf__max_depth': 2, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 2, 'clf__min_samples_split': 2, 'clf__splitter': 'best'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.73      0.84        26
           1       0.46      1.00      0.63         6

   micro avg       0.78      0.78      0.78        32
   macro avg       0.73      0.87      0.74        32
weighted avg       0.90      0.78      0.80        32


Accuracy: 0.78125
Balanced Accuracy: 0.8653846153846154
Precision: 0.46153846153846156
Recall: 1.0
F1: 0.631578947368421
AUROC: 0.8653846153846154
Confusion Matrix: [[19  7]
 [ 0  6]]

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
==============================
 random_forest 
==============================
# =========================== Tuning hyper-parameters for precision

Fitting 4 folds for each of 540 candidates, totalling 2160 fits
Best parameters set found on development set:

{'clf__bootstrap': True, 'clf__max_depth': 10, 'clf__max_features': 'auto', 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 6, 'clf__n_estimators': 10}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.91      0.81      0.86        26
           1       0.44      0.67      0.53         6

   micro avg       0.78      0.78      0.78        32
   macro avg       0.68      0.74      0.70        32
weighted avg       0.83      0.78      0.80        32


Accuracy: 0.78125
Balanced Accuracy: 0.7371794871794872
Precision: 0.4444444444444444
Recall: 0.6666666666666666
F1: 0.5333333333333333
AUROC: 0.7371794871794871
Confusion Matrix: [[21  5]
 [ 2  4]]

# =========================== Tuning hyper-parameters for recall

Fitting 4 folds for each of 540 candidates, totalling 2160 fits
Best parameters set found on development set:

{'clf__bootstrap': True, 'clf__max_depth': 8, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 5, 'clf__min_samples_split': 2, 'clf__n_estimators': 80}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.77      0.87        26
           1       0.50      1.00      0.67         6

   micro avg       0.81      0.81      0.81        32
   macro avg       0.75      0.88      0.77        32
weighted avg       0.91      0.81      0.83        32


Accuracy: 0.8125
Balanced Accuracy: 0.8846153846153846
Precision: 0.5
Recall: 1.0
F1: 0.6666666666666666
AUROC: 0.8846153846153846
Confusion Matrix: [[20  6]
 [ 0  6]]

# =========================== Tuning hyper-parameters for f1

Fitting 4 folds for each of 540 candidates, totalling 2160 fits
Best parameters set found on development set:

{'clf__bootstrap': False, 'clf__max_depth': 2, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 5, 'clf__min_samples_split': 6, 'clf__n_estimators': 10}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.77      0.87        26
           1       0.50      1.00      0.67         6

   micro avg       0.81      0.81      0.81        32
   macro avg       0.75      0.88      0.77        32
weighted avg       0.91      0.81      0.83        32


Accuracy: 0.8125
Balanced Accuracy: 0.8846153846153846
Precision: 0.5
Recall: 1.0
F1: 0.6666666666666666
AUROC: 0.8846153846153846
Confusion Matrix: [[20  6]
 [ 0  6]]

# =========================== Tuning hyper-parameters for balanced_accuracy

Fitting 4 folds for each of 540 candidates, totalling 2160 fits
Best parameters set found on development set:

{'clf__bootstrap': False, 'clf__max_depth': 10, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 5, 'clf__min_samples_split': 4, 'clf__n_estimators': 100}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.81      0.89        26
           1       0.55      1.00      0.71         6

   micro avg       0.84      0.84      0.84        32
   macro avg       0.77      0.90      0.80        32
weighted avg       0.91      0.84      0.86        32


Accuracy: 0.84375
Balanced Accuracy: 0.9038461538461539
Precision: 0.5454545454545454
Recall: 1.0
F1: 0.7058823529411764
AUROC: 0.9038461538461539
Confusion Matrix: [[21  5]
 [ 0  6]]

# =========================== Tuning hyper-parameters for roc_auc

Fitting 4 folds for each of 540 candidates, totalling 2160 fits
Best parameters set found on development set:

{'clf__bootstrap': False, 'clf__max_depth': 2, 'clf__max_features': 'auto', 'clf__min_samples_leaf': 3, 'clf__min_samples_split': 2, 'clf__n_estimators': 10}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.95      0.81      0.88        26
           1       0.50      0.83      0.62         6

   micro avg       0.81      0.81      0.81        32
   macro avg       0.73      0.82      0.75        32
weighted avg       0.87      0.81      0.83        32


Accuracy: 0.8125
Balanced Accuracy: 0.8205128205128205
Precision: 0.5
Recall: 0.8333333333333334
F1: 0.625
AUROC: 0.8205128205128206
Confusion Matrix: [[21  5]
 [ 1  5]]

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
==============================
 mlp 
==============================
# =========================== Tuning hyper-parameters for precision

Fitting 4 folds for each of 36 candidates, totalling 144 fits
Best parameters set found on development set:

{'clf__activation': 'relu', 'clf__alpha': 0.005, 'clf__hidden_layer_sizes': (32, 8, 32), 'clf__solver': 'adam'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.88      0.81      0.84        26
           1       0.38      0.50      0.43         6

   micro avg       0.75      0.75      0.75        32
   macro avg       0.62      0.65      0.63        32
weighted avg       0.78      0.75      0.76        32


Accuracy: 0.75
Balanced Accuracy: 0.6538461538461539
Precision: 0.375
Recall: 0.5
F1: 0.42857142857142855
AUROC: 0.653846153846154
Confusion Matrix: [[21  5]
 [ 3  3]]

# =========================== Tuning hyper-parameters for recall

Fitting 4 folds for each of 36 candidates, totalling 144 fits
Best parameters set found on development set:

{'clf__activation': 'tanh', 'clf__alpha': 0.05, 'clf__hidden_layer_sizes': (100,), 'clf__solver': 'sgd'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.77      0.87        26
           1       0.50      1.00      0.67         6

   micro avg       0.81      0.81      0.81        32
   macro avg       0.75      0.88      0.77        32
weighted avg       0.91      0.81      0.83        32


Accuracy: 0.8125
Balanced Accuracy: 0.8846153846153846
Precision: 0.5
Recall: 1.0
F1: 0.6666666666666666
AUROC: 0.8846153846153846
Confusion Matrix: [[20  6]
 [ 0  6]]

# =========================== Tuning hyper-parameters for f1

Fitting 4 folds for each of 36 candidates, totalling 144 fits
Best parameters set found on development set:

{'clf__activation': 'tanh', 'clf__alpha': 0.05, 'clf__hidden_layer_sizes': (100,), 'clf__solver': 'sgd'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.81      0.89        26
           1       0.55      1.00      0.71         6

   micro avg       0.84      0.84      0.84        32
   macro avg       0.77      0.90      0.80        32
weighted avg       0.91      0.84      0.86        32


Accuracy: 0.84375
Balanced Accuracy: 0.9038461538461539
Precision: 0.5454545454545454
Recall: 1.0
F1: 0.7058823529411764
AUROC: 0.9038461538461539
Confusion Matrix: [[21  5]
 [ 0  6]]

# =========================== Tuning hyper-parameters for balanced_accuracy

Fitting 4 folds for each of 36 candidates, totalling 144 fits
Best parameters set found on development set:

{'clf__activation': 'tanh', 'clf__alpha': 0.0001, 'clf__hidden_layer_sizes': (300,), 'clf__solver': 'sgd'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.96      0.85      0.90        26
           1       0.56      0.83      0.67         6

   micro avg       0.84      0.84      0.84        32
   macro avg       0.76      0.84      0.78        32
weighted avg       0.88      0.84      0.85        32


Accuracy: 0.84375
Balanced Accuracy: 0.8397435897435898
Precision: 0.5555555555555556
Recall: 0.8333333333333334
F1: 0.6666666666666667
AUROC: 0.8397435897435898
Confusion Matrix: [[22  4]
 [ 1  5]]

# =========================== Tuning hyper-parameters for roc_auc

Fitting 4 folds for each of 36 candidates, totalling 144 fits
Best parameters set found on development set:

{'clf__activation': 'tanh', 'clf__alpha': 0.0001, 'clf__hidden_layer_sizes': (100,), 'clf__solver': 'sgd'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.95      0.81      0.88        26
           1       0.50      0.83      0.62         6

   micro avg       0.81      0.81      0.81        32
   macro avg       0.73      0.82      0.75        32
weighted avg       0.87      0.81      0.83        32


Accuracy: 0.8125
Balanced Accuracy: 0.8205128205128205
Precision: 0.5
Recall: 0.8333333333333334
F1: 0.625
AUROC: 0.8205128205128206
Confusion Matrix: [[21  5]
 [ 1  5]]

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
 Multiple Grid Search 
==============================
columns ['descr_left_max', 'react_left_max', 'descr_right_max', 'react_left_std', 'right_max', 'left_std', 'react_right_mean', 'react_mean_pupil', 'react_left_mean', 'right_mean', 'left_mean', 'descr_left_mean', 'descr_right_mean', 'descr_mean_pupil']
number of datapoint: 126
Normalize: True
Oversample: True
Oversample Mode: minmax
Drop NaN: True
==============================
==============================
Train Set Datapoints 94
Test Set Datapoints 32
==============================
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
==============================
 naive_bayes 
==============================
# =========================== Tuning hyper-parameters for precision

Fitting 4 folds for each of 5 candidates, totalling 20 fits
Best parameters set found on development set:

{'clf__var_smoothing': 2e-08}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.96      0.85      0.90        26
           1       0.56      0.83      0.67         6

   micro avg       0.84      0.84      0.84        32
   macro avg       0.76      0.84      0.78        32
weighted avg       0.88      0.84      0.85        32


Accuracy: 0.84375
Balanced Accuracy: 0.8397435897435898
Precision: 0.5555555555555556
Recall: 0.8333333333333334
F1: 0.6666666666666667
AUROC: 0.8397435897435898
Confusion Matrix: [[22  4]
 [ 1  5]]

# =========================== Tuning hyper-parameters for recall

Fitting 4 folds for each of 5 candidates, totalling 20 fits
Best parameters set found on development set:

{'clf__var_smoothing': 2e-09}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.96      0.85      0.90        26
           1       0.56      0.83      0.67         6

   micro avg       0.84      0.84      0.84        32
   macro avg       0.76      0.84      0.78        32
weighted avg       0.88      0.84      0.85        32


Accuracy: 0.84375
Balanced Accuracy: 0.8397435897435898
Precision: 0.5555555555555556
Recall: 0.8333333333333334
F1: 0.6666666666666667
AUROC: 0.8397435897435898
Confusion Matrix: [[22  4]
 [ 1  5]]

# =========================== Tuning hyper-parameters for f1

Fitting 4 folds for each of 5 candidates, totalling 20 fits
Best parameters set found on development set:

{'clf__var_smoothing': 1e-08}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.96      0.85      0.90        26
           1       0.56      0.83      0.67         6

   micro avg       0.84      0.84      0.84        32
   macro avg       0.76      0.84      0.78        32
weighted avg       0.88      0.84      0.85        32


Accuracy: 0.84375
Balanced Accuracy: 0.8397435897435898
Precision: 0.5555555555555556
Recall: 0.8333333333333334
F1: 0.6666666666666667
AUROC: 0.8397435897435898
Confusion Matrix: [[22  4]
 [ 1  5]]

# =========================== Tuning hyper-parameters for balanced_accuracy

Fitting 4 folds for each of 5 candidates, totalling 20 fits
Best parameters set found on development set:

{'clf__var_smoothing': 1e-09}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.96      0.85      0.90        26
           1       0.56      0.83      0.67         6

   micro avg       0.84      0.84      0.84        32
   macro avg       0.76      0.84      0.78        32
weighted avg       0.88      0.84      0.85        32


Accuracy: 0.84375
Balanced Accuracy: 0.8397435897435898
Precision: 0.5555555555555556
Recall: 0.8333333333333334
F1: 0.6666666666666667
AUROC: 0.8397435897435898
Confusion Matrix: [[22  4]
 [ 1  5]]

# =========================== Tuning hyper-parameters for roc_auc

Fitting 4 folds for each of 5 candidates, totalling 20 fits
Best parameters set found on development set:

{'clf__var_smoothing': 2e-09}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.96      0.85      0.90        26
           1       0.56      0.83      0.67         6

   micro avg       0.84      0.84      0.84        32
   macro avg       0.76      0.84      0.78        32
weighted avg       0.88      0.84      0.85        32


Accuracy: 0.84375
Balanced Accuracy: 0.8397435897435898
Precision: 0.5555555555555556
Recall: 0.8333333333333334
F1: 0.6666666666666667
AUROC: 0.8397435897435898
Confusion Matrix: [[22  4]
 [ 1  5]]

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
==============================
 knn 
==============================
# =========================== Tuning hyper-parameters for precision

Fitting 4 folds for each of 96 candidates, totalling 384 fits
Best parameters set found on development set:

{'clf__algorithm': 'auto', 'clf__n_neighbors': 7, 'clf__p': 1, 'clf__weights': 'uniform'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.77      0.87        26
           1       0.50      1.00      0.67         6

   micro avg       0.81      0.81      0.81        32
   macro avg       0.75      0.88      0.77        32
weighted avg       0.91      0.81      0.83        32


Accuracy: 0.8125
Balanced Accuracy: 0.8846153846153846
Precision: 0.5
Recall: 1.0
F1: 0.6666666666666666
AUROC: 0.8846153846153846
Confusion Matrix: [[20  6]
 [ 0  6]]

# =========================== Tuning hyper-parameters for recall

Fitting 4 folds for each of 96 candidates, totalling 384 fits
Best parameters set found on development set:

{'clf__algorithm': 'auto', 'clf__n_neighbors': 7, 'clf__p': 1, 'clf__weights': 'distance'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.77      0.87        26
           1       0.50      1.00      0.67         6

   micro avg       0.81      0.81      0.81        32
   macro avg       0.75      0.88      0.77        32
weighted avg       0.91      0.81      0.83        32


Accuracy: 0.8125
Balanced Accuracy: 0.8846153846153846
Precision: 0.5
Recall: 1.0
F1: 0.6666666666666666
AUROC: 0.8846153846153846
Confusion Matrix: [[20  6]
 [ 0  6]]

# =========================== Tuning hyper-parameters for f1

Fitting 4 folds for each of 96 candidates, totalling 384 fits
Best parameters set found on development set:

{'clf__algorithm': 'auto', 'clf__n_neighbors': 7, 'clf__p': 1, 'clf__weights': 'uniform'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.77      0.87        26
           1       0.50      1.00      0.67         6

   micro avg       0.81      0.81      0.81        32
   macro avg       0.75      0.88      0.77        32
weighted avg       0.91      0.81      0.83        32


Accuracy: 0.8125
Balanced Accuracy: 0.8846153846153846
Precision: 0.5
Recall: 1.0
F1: 0.6666666666666666
AUROC: 0.8846153846153846
Confusion Matrix: [[20  6]
 [ 0  6]]

# =========================== Tuning hyper-parameters for balanced_accuracy

Fitting 4 folds for each of 96 candidates, totalling 384 fits
Best parameters set found on development set:

{'clf__algorithm': 'kd_tree', 'clf__n_neighbors': 7, 'clf__p': 1, 'clf__weights': 'distance'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.69      0.82        26
           1       0.43      1.00      0.60         6

   micro avg       0.75      0.75      0.75        32
   macro avg       0.71      0.85      0.71        32
weighted avg       0.89      0.75      0.78        32


Accuracy: 0.75
Balanced Accuracy: 0.8461538461538461
Precision: 0.42857142857142855
Recall: 1.0
F1: 0.6
AUROC: 0.8461538461538461
Confusion Matrix: [[18  8]
 [ 0  6]]

# =========================== Tuning hyper-parameters for roc_auc

Fitting 4 folds for each of 96 candidates, totalling 384 fits
Best parameters set found on development set:

{'clf__algorithm': 'auto', 'clf__n_neighbors': 9, 'clf__p': 1, 'clf__weights': 'uniform'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.69      0.82        26
           1       0.43      1.00      0.60         6

   micro avg       0.75      0.75      0.75        32
   macro avg       0.71      0.85      0.71        32
weighted avg       0.89      0.75      0.78        32


Accuracy: 0.75
Balanced Accuracy: 0.8461538461538461
Precision: 0.42857142857142855
Recall: 1.0
F1: 0.6
AUROC: 0.8461538461538461
Confusion Matrix: [[18  8]
 [ 0  6]]

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
==============================
 ada 
==============================
# =========================== Tuning hyper-parameters for precision

Fitting 4 folds for each of 40 candidates, totalling 160 fits
Best parameters set found on development set:

{'clf__algorithm': 'SAMME.R', 'clf__learning_rate': 0.01, 'clf__n_estimators': 10}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.95      0.81      0.88        26
           1       0.50      0.83      0.62         6

   micro avg       0.81      0.81      0.81        32
   macro avg       0.73      0.82      0.75        32
weighted avg       0.87      0.81      0.83        32


Accuracy: 0.8125
Balanced Accuracy: 0.8205128205128205
Precision: 0.5
Recall: 0.8333333333333334
F1: 0.625
AUROC: 0.8205128205128206
Confusion Matrix: [[21  5]
 [ 1  5]]

# =========================== Tuning hyper-parameters for recall

Fitting 4 folds for each of 40 candidates, totalling 160 fits
Best parameters set found on development set:

{'clf__algorithm': 'SAMME', 'clf__learning_rate': 0.01, 'clf__n_estimators': 10}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.95      0.81      0.88        26
           1       0.50      0.83      0.62         6

   micro avg       0.81      0.81      0.81        32
   macro avg       0.73      0.82      0.75        32
weighted avg       0.87      0.81      0.83        32


Accuracy: 0.8125
Balanced Accuracy: 0.8205128205128205
Precision: 0.5
Recall: 0.8333333333333334
F1: 0.625
AUROC: 0.8205128205128206
Confusion Matrix: [[21  5]
 [ 1  5]]

# =========================== Tuning hyper-parameters for f1

Fitting 4 folds for each of 40 candidates, totalling 160 fits
Best parameters set found on development set:

{'clf__algorithm': 'SAMME', 'clf__learning_rate': 0.01, 'clf__n_estimators': 50}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.95      0.81      0.88        26
           1       0.50      0.83      0.62         6

   micro avg       0.81      0.81      0.81        32
   macro avg       0.73      0.82      0.75        32
weighted avg       0.87      0.81      0.83        32


Accuracy: 0.8125
Balanced Accuracy: 0.8205128205128205
Precision: 0.5
Recall: 0.8333333333333334
F1: 0.625
AUROC: 0.8205128205128206
Confusion Matrix: [[21  5]
 [ 1  5]]

# =========================== Tuning hyper-parameters for balanced_accuracy

Fitting 4 folds for each of 40 candidates, totalling 160 fits
Best parameters set found on development set:

{'clf__algorithm': 'SAMME', 'clf__learning_rate': 0.01, 'clf__n_estimators': 10}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.95      0.77      0.85        26
           1       0.45      0.83      0.59         6

   micro avg       0.78      0.78      0.78        32
   macro avg       0.70      0.80      0.72        32
weighted avg       0.86      0.78      0.80        32


Accuracy: 0.78125
Balanced Accuracy: 0.8012820512820513
Precision: 0.45454545454545453
Recall: 0.8333333333333334
F1: 0.5882352941176471
AUROC: 0.8012820512820513
Confusion Matrix: [[20  6]
 [ 1  5]]

# =========================== Tuning hyper-parameters for roc_auc

Fitting 4 folds for each of 40 candidates, totalling 160 fits
Best parameters set found on development set:

{'clf__algorithm': 'SAMME.R', 'clf__learning_rate': 0.01, 'clf__n_estimators': 10}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.95      0.81      0.88        26
           1       0.50      0.83      0.62         6

   micro avg       0.81      0.81      0.81        32
   macro avg       0.73      0.82      0.75        32
weighted avg       0.87      0.81      0.83        32


Accuracy: 0.8125
Balanced Accuracy: 0.8205128205128205
Precision: 0.5
Recall: 0.8333333333333334
F1: 0.625
AUROC: 0.8205128205128206
Confusion Matrix: [[21  5]
 [ 1  5]]

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
==============================
 svm 
==============================
# =========================== Tuning hyper-parameters for precision

Fitting 4 folds for each of 81 candidates, totalling 324 fits
Best parameters set found on development set:

{'clf__C': 1000, 'clf__gamma': 1, 'clf__kernel': 'rbf'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.88      0.85      0.86        26
           1       0.43      0.50      0.46         6

   micro avg       0.78      0.78      0.78        32
   macro avg       0.65      0.67      0.66        32
weighted avg       0.80      0.78      0.79        32


Accuracy: 0.78125
Balanced Accuracy: 0.6730769230769231
Precision: 0.42857142857142855
Recall: 0.5
F1: 0.4615384615384615
AUROC: 0.673076923076923
Confusion Matrix: [[22  4]
 [ 3  3]]

# =========================== Tuning hyper-parameters for recall

Fitting 4 folds for each of 81 candidates, totalling 324 fits
Best parameters set found on development set:

{'clf__C': 0.001, 'clf__gamma': 0.001, 'clf__kernel': 'rbf'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.42      0.59        26
           1       0.29      1.00      0.44         6

   micro avg       0.53      0.53      0.53        32
   macro avg       0.64      0.71      0.52        32
weighted avg       0.87      0.53      0.57        32


Accuracy: 0.53125
Balanced Accuracy: 0.7115384615384616
Precision: 0.2857142857142857
Recall: 1.0
F1: 0.4444444444444445
AUROC: 0.7115384615384616
Confusion Matrix: [[11 15]
 [ 0  6]]

# =========================== Tuning hyper-parameters for f1

Fitting 4 folds for each of 81 candidates, totalling 324 fits
Best parameters set found on development set:

{'clf__C': 1, 'clf__kernel': 'linear'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.77      0.87        26
           1       0.50      1.00      0.67         6

   micro avg       0.81      0.81      0.81        32
   macro avg       0.75      0.88      0.77        32
weighted avg       0.91      0.81      0.83        32


Accuracy: 0.8125
Balanced Accuracy: 0.8846153846153846
Precision: 0.5
Recall: 1.0
F1: 0.6666666666666666
AUROC: 0.8846153846153846
Confusion Matrix: [[20  6]
 [ 0  6]]

# =========================== Tuning hyper-parameters for balanced_accuracy

Fitting 4 folds for each of 81 candidates, totalling 324 fits
Best parameters set found on development set:

{'clf__C': 0.1, 'clf__gamma': 0.1, 'clf__kernel': 'rbf'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.65      0.79        26
           1       0.40      1.00      0.57         6

   micro avg       0.72      0.72      0.72        32
   macro avg       0.70      0.83      0.68        32
weighted avg       0.89      0.72      0.75        32


Accuracy: 0.71875
Balanced Accuracy: 0.8269230769230769
Precision: 0.4
Recall: 1.0
F1: 0.5714285714285715
AUROC: 0.8269230769230769
Confusion Matrix: [[17  9]
 [ 0  6]]

# =========================== Tuning hyper-parameters for roc_auc

Fitting 4 folds for each of 81 candidates, totalling 324 fits
Best parameters set found on development set:

{'clf__C': 0.001, 'clf__gamma': 1, 'clf__kernel': 'rbf'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.92      0.92      0.92        26
           1       0.67      0.67      0.67         6

   micro avg       0.88      0.88      0.88        32
   macro avg       0.79      0.79      0.79        32
weighted avg       0.88      0.88      0.88        32


Accuracy: 0.875
Balanced Accuracy: 0.7948717948717949
Precision: 0.6666666666666666
Recall: 0.6666666666666666
F1: 0.6666666666666666
AUROC: 0.7948717948717948
Confusion Matrix: [[24  2]
 [ 2  4]]

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
==============================
 decision_tree 
==============================
# =========================== Tuning hyper-parameters for precision

Fitting 4 folds for each of 1200 candidates, totalling 4800 fits
Best parameters set found on development set:

{'clf__criterion': 'entropy', 'clf__max_depth': 10, 'clf__max_features': 'auto', 'clf__min_samples_leaf': 5, 'clf__min_samples_split': 4, 'clf__splitter': 'best'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.96      0.85      0.90        26
           1       0.56      0.83      0.67         6

   micro avg       0.84      0.84      0.84        32
   macro avg       0.76      0.84      0.78        32
weighted avg       0.88      0.84      0.85        32


Accuracy: 0.84375
Balanced Accuracy: 0.8397435897435898
Precision: 0.5555555555555556
Recall: 0.8333333333333334
F1: 0.6666666666666667
AUROC: 0.8397435897435898
Confusion Matrix: [[22  4]
 [ 1  5]]

# =========================== Tuning hyper-parameters for recall

Fitting 4 folds for each of 1200 candidates, totalling 4800 fits
Best parameters set found on development set:

{'clf__criterion': 'entropy', 'clf__max_depth': 2, 'clf__max_features': 'auto', 'clf__min_samples_leaf': 2, 'clf__min_samples_split': 4, 'clf__splitter': 'best'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.95      0.81      0.88        26
           1       0.50      0.83      0.62         6

   micro avg       0.81      0.81      0.81        32
   macro avg       0.73      0.82      0.75        32
weighted avg       0.87      0.81      0.83        32


Accuracy: 0.8125
Balanced Accuracy: 0.8205128205128205
Precision: 0.5
Recall: 0.8333333333333334
F1: 0.625
AUROC: 0.8205128205128206
Confusion Matrix: [[21  5]
 [ 1  5]]

# =========================== Tuning hyper-parameters for f1

Fitting 4 folds for each of 1200 candidates, totalling 4800 fits
Best parameters set found on development set:

{'clf__criterion': 'gini', 'clf__max_depth': 20, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 5, 'clf__splitter': 'random'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.91      0.81      0.86        26
           1       0.44      0.67      0.53         6

   micro avg       0.78      0.78      0.78        32
   macro avg       0.68      0.74      0.70        32
weighted avg       0.83      0.78      0.80        32


Accuracy: 0.78125
Balanced Accuracy: 0.7371794871794872
Precision: 0.4444444444444444
Recall: 0.6666666666666666
F1: 0.5333333333333333
AUROC: 0.7371794871794871
Confusion Matrix: [[21  5]
 [ 2  4]]

# =========================== Tuning hyper-parameters for balanced_accuracy

Fitting 4 folds for each of 1200 candidates, totalling 4800 fits
Best parameters set found on development set:

{'clf__criterion': 'gini', 'clf__max_depth': 10, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 5, 'clf__min_samples_split': 2, 'clf__splitter': 'best'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.95      0.73      0.83        26
           1       0.42      0.83      0.56         6

   micro avg       0.75      0.75      0.75        32
   macro avg       0.68      0.78      0.69        32
weighted avg       0.85      0.75      0.78        32


Accuracy: 0.75
Balanced Accuracy: 0.782051282051282
Precision: 0.4166666666666667
Recall: 0.8333333333333334
F1: 0.5555555555555556
AUROC: 0.7820512820512822
Confusion Matrix: [[19  7]
 [ 1  5]]

# =========================== Tuning hyper-parameters for roc_auc

Fitting 4 folds for each of 1200 candidates, totalling 4800 fits
Best parameters set found on development set:

{'clf__criterion': 'entropy', 'clf__max_depth': 2, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 3, 'clf__min_samples_split': 5, 'clf__splitter': 'best'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.92      0.85      0.88        26
           1       0.50      0.67      0.57         6

   micro avg       0.81      0.81      0.81        32
   macro avg       0.71      0.76      0.73        32
weighted avg       0.84      0.81      0.82        32


Accuracy: 0.8125
Balanced Accuracy: 0.7564102564102564
Precision: 0.5
Recall: 0.6666666666666666
F1: 0.5714285714285715
AUROC: 0.7564102564102564
Confusion Matrix: [[22  4]
 [ 2  4]]

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
==============================
 random_forest 
==============================
# =========================== Tuning hyper-parameters for precision

Fitting 4 folds for each of 540 candidates, totalling 2160 fits
Best parameters set found on development set:

{'clf__bootstrap': False, 'clf__max_depth': 20, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 6, 'clf__n_estimators': 10}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.95      0.81      0.88        26
           1       0.50      0.83      0.62         6

   micro avg       0.81      0.81      0.81        32
   macro avg       0.73      0.82      0.75        32
weighted avg       0.87      0.81      0.83        32


Accuracy: 0.8125
Balanced Accuracy: 0.8205128205128205
Precision: 0.5
Recall: 0.8333333333333334
F1: 0.625
AUROC: 0.8205128205128206
Confusion Matrix: [[21  5]
 [ 1  5]]

# =========================== Tuning hyper-parameters for recall

Fitting 4 folds for each of 540 candidates, totalling 2160 fits
Best parameters set found on development set:

{'clf__bootstrap': True, 'clf__max_depth': 2, 'clf__max_features': 'auto', 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 4, 'clf__n_estimators': 10}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.85      0.92        26
           1       0.60      1.00      0.75         6

   micro avg       0.88      0.88      0.88        32
   macro avg       0.80      0.92      0.83        32
weighted avg       0.93      0.88      0.89        32


Accuracy: 0.875
Balanced Accuracy: 0.9230769230769231
Precision: 0.6
Recall: 1.0
F1: 0.7499999999999999
AUROC: 0.9230769230769231
Confusion Matrix: [[22  4]
 [ 0  6]]

# =========================== Tuning hyper-parameters for f1

Fitting 4 folds for each of 540 candidates, totalling 2160 fits
Best parameters set found on development set:

{'clf__bootstrap': True, 'clf__max_depth': 10, 'clf__max_features': 'auto', 'clf__min_samples_leaf': 5, 'clf__min_samples_split': 4, 'clf__n_estimators': 100}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.85      0.92        26
           1       0.60      1.00      0.75         6

   micro avg       0.88      0.88      0.88        32
   macro avg       0.80      0.92      0.83        32
weighted avg       0.93      0.88      0.89        32


Accuracy: 0.875
Balanced Accuracy: 0.9230769230769231
Precision: 0.6
Recall: 1.0
F1: 0.7499999999999999
AUROC: 0.9230769230769231
Confusion Matrix: [[22  4]
 [ 0  6]]

# =========================== Tuning hyper-parameters for balanced_accuracy

Fitting 4 folds for each of 540 candidates, totalling 2160 fits
Best parameters set found on development set:

{'clf__bootstrap': False, 'clf__max_depth': 2, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 5, 'clf__min_samples_split': 2, 'clf__n_estimators': 10}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.96      0.85      0.90        26
           1       0.56      0.83      0.67         6

   micro avg       0.84      0.84      0.84        32
   macro avg       0.76      0.84      0.78        32
weighted avg       0.88      0.84      0.85        32


Accuracy: 0.84375
Balanced Accuracy: 0.8397435897435898
Precision: 0.5555555555555556
Recall: 0.8333333333333334
F1: 0.6666666666666667
AUROC: 0.8397435897435898
Confusion Matrix: [[22  4]
 [ 1  5]]

# =========================== Tuning hyper-parameters for roc_auc

Fitting 4 folds for each of 540 candidates, totalling 2160 fits
Best parameters set found on development set:

{'clf__bootstrap': True, 'clf__max_depth': 20, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 5, 'clf__min_samples_split': 4, 'clf__n_estimators': 10}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.95      0.81      0.88        26
           1       0.50      0.83      0.62         6

   micro avg       0.81      0.81      0.81        32
   macro avg       0.73      0.82      0.75        32
weighted avg       0.87      0.81      0.83        32


Accuracy: 0.8125
Balanced Accuracy: 0.8205128205128205
Precision: 0.5
Recall: 0.8333333333333334
F1: 0.625
AUROC: 0.8205128205128206
Confusion Matrix: [[21  5]
 [ 1  5]]

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
==============================
 mlp 
==============================
# =========================== Tuning hyper-parameters for precision

Fitting 4 folds for each of 36 candidates, totalling 144 fits
Best parameters set found on development set:

{'clf__activation': 'relu', 'clf__alpha': 0.0001, 'clf__hidden_layer_sizes': (100,), 'clf__solver': 'sgd'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.81      0.89        26
           1       0.55      1.00      0.71         6

   micro avg       0.84      0.84      0.84        32
   macro avg       0.77      0.90      0.80        32
weighted avg       0.91      0.84      0.86        32


Accuracy: 0.84375
Balanced Accuracy: 0.9038461538461539
Precision: 0.5454545454545454
Recall: 1.0
F1: 0.7058823529411764
AUROC: 0.9038461538461539
Confusion Matrix: [[21  5]
 [ 0  6]]

# =========================== Tuning hyper-parameters for recall

Fitting 4 folds for each of 36 candidates, totalling 144 fits
Best parameters set found on development set:

{'clf__activation': 'tanh', 'clf__alpha': 0.05, 'clf__hidden_layer_sizes': (32, 8, 32), 'clf__solver': 'sgd'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.85      0.92        26
           1       0.60      1.00      0.75         6

   micro avg       0.88      0.88      0.88        32
   macro avg       0.80      0.92      0.83        32
weighted avg       0.93      0.88      0.89        32


Accuracy: 0.875
Balanced Accuracy: 0.9230769230769231
Precision: 0.6
Recall: 1.0
F1: 0.7499999999999999
AUROC: 0.9230769230769231
Confusion Matrix: [[22  4]
 [ 0  6]]

# =========================== Tuning hyper-parameters for f1

Fitting 4 folds for each of 36 candidates, totalling 144 fits
Best parameters set found on development set:

{'clf__activation': 'tanh', 'clf__alpha': 0.0001, 'clf__hidden_layer_sizes': (32, 8, 32), 'clf__solver': 'sgd'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.81      0.89        26
           1       0.55      1.00      0.71         6

   micro avg       0.84      0.84      0.84        32
   macro avg       0.77      0.90      0.80        32
weighted avg       0.91      0.84      0.86        32


Accuracy: 0.84375
Balanced Accuracy: 0.9038461538461539
Precision: 0.5454545454545454
Recall: 1.0
F1: 0.7058823529411764
AUROC: 0.9038461538461539
Confusion Matrix: [[21  5]
 [ 0  6]]

# =========================== Tuning hyper-parameters for balanced_accuracy

Fitting 4 folds for each of 36 candidates, totalling 144 fits
Best parameters set found on development set:

{'clf__activation': 'tanh', 'clf__alpha': 0.005, 'clf__hidden_layer_sizes': (100,), 'clf__solver': 'sgd'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.77      0.87        26
           1       0.50      1.00      0.67         6

   micro avg       0.81      0.81      0.81        32
   macro avg       0.75      0.88      0.77        32
weighted avg       0.91      0.81      0.83        32


Accuracy: 0.8125
Balanced Accuracy: 0.8846153846153846
Precision: 0.5
Recall: 1.0
F1: 0.6666666666666666
AUROC: 0.8846153846153846
Confusion Matrix: [[20  6]
 [ 0  6]]

# =========================== Tuning hyper-parameters for roc_auc

Fitting 4 folds for each of 36 candidates, totalling 144 fits
Best parameters set found on development set:

{'clf__activation': 'relu', 'clf__alpha': 0.005, 'clf__hidden_layer_sizes': (100,), 'clf__solver': 'sgd'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.85      0.92        26
           1       0.60      1.00      0.75         6

   micro avg       0.88      0.88      0.88        32
   macro avg       0.80      0.92      0.83        32
weighted avg       0.93      0.88      0.89        32


Accuracy: 0.875
Balanced Accuracy: 0.9230769230769231
Precision: 0.6
Recall: 1.0
F1: 0.7499999999999999
AUROC: 0.9230769230769231
Confusion Matrix: [[22  4]
 [ 0  6]]

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
 Multiple Grid Search 
==============================
columns ['descr_right_mean', 'descr_right_std', 'descr_right_min', 'descr_right_max', 'descr_left_mean', 'descr_left_std', 'descr_left_min', 'descr_left_max', 'descr_mean_pupil', 'react_right_mean', 'react_right_std', 'react_right_min', 'react_right_max', 'react_left_mean', 'react_left_std', 'react_left_min', 'react_left_max', 'react_mean_pupil']
number of datapoint: 126
Normalize: True
Oversample: True
Oversample Mode: minmax
Drop NaN: True
==============================
==============================
Train Set Datapoints 94
Test Set Datapoints 32
==============================
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
==============================
 naive_bayes 
==============================
# =========================== Tuning hyper-parameters for precision

Fitting 4 folds for each of 5 candidates, totalling 20 fits
Best parameters set found on development set:

{'clf__var_smoothing': 2e-09}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.95      0.77      0.85        26
           1       0.45      0.83      0.59         6

   micro avg       0.78      0.78      0.78        32
   macro avg       0.70      0.80      0.72        32
weighted avg       0.86      0.78      0.80        32


Accuracy: 0.78125
Balanced Accuracy: 0.8012820512820513
Precision: 0.45454545454545453
Recall: 0.8333333333333334
F1: 0.5882352941176471
AUROC: 0.8012820512820513
Confusion Matrix: [[20  6]
 [ 1  5]]

# =========================== Tuning hyper-parameters for recall

Fitting 4 folds for each of 5 candidates, totalling 20 fits
Best parameters set found on development set:

{'clf__var_smoothing': 2e-09}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.95      0.81      0.88        26
           1       0.50      0.83      0.62         6

   micro avg       0.81      0.81      0.81        32
   macro avg       0.73      0.82      0.75        32
weighted avg       0.87      0.81      0.83        32


Accuracy: 0.8125
Balanced Accuracy: 0.8205128205128205
Precision: 0.5
Recall: 0.8333333333333334
F1: 0.625
AUROC: 0.8205128205128206
Confusion Matrix: [[21  5]
 [ 1  5]]

# =========================== Tuning hyper-parameters for f1

Fitting 4 folds for each of 5 candidates, totalling 20 fits
Best parameters set found on development set:

{'clf__var_smoothing': 2e-09}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.95      0.81      0.88        26
           1       0.50      0.83      0.62         6

   micro avg       0.81      0.81      0.81        32
   macro avg       0.73      0.82      0.75        32
weighted avg       0.87      0.81      0.83        32


Accuracy: 0.8125
Balanced Accuracy: 0.8205128205128205
Precision: 0.5
Recall: 0.8333333333333334
F1: 0.625
AUROC: 0.8205128205128206
Confusion Matrix: [[21  5]
 [ 1  5]]

# =========================== Tuning hyper-parameters for balanced_accuracy

Fitting 4 folds for each of 5 candidates, totalling 20 fits
Best parameters set found on development set:

{'clf__var_smoothing': 1e-09}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.95      0.81      0.88        26
           1       0.50      0.83      0.62         6

   micro avg       0.81      0.81      0.81        32
   macro avg       0.73      0.82      0.75        32
weighted avg       0.87      0.81      0.83        32


Accuracy: 0.8125
Balanced Accuracy: 0.8205128205128205
Precision: 0.5
Recall: 0.8333333333333334
F1: 0.625
AUROC: 0.8205128205128206
Confusion Matrix: [[21  5]
 [ 1  5]]

# =========================== Tuning hyper-parameters for roc_auc

Fitting 4 folds for each of 5 candidates, totalling 20 fits
Best parameters set found on development set:

{'clf__var_smoothing': 2e-08}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.95      0.77      0.85        26
           1       0.45      0.83      0.59         6

   micro avg       0.78      0.78      0.78        32
   macro avg       0.70      0.80      0.72        32
weighted avg       0.86      0.78      0.80        32


Accuracy: 0.78125
Balanced Accuracy: 0.8012820512820513
Precision: 0.45454545454545453
Recall: 0.8333333333333334
F1: 0.5882352941176471
AUROC: 0.8012820512820513
Confusion Matrix: [[20  6]
 [ 1  5]]

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
==============================
 knn 
==============================
# =========================== Tuning hyper-parameters for precision

Fitting 4 folds for each of 96 candidates, totalling 384 fits
Best parameters set found on development set:

{'clf__algorithm': 'auto', 'clf__n_neighbors': 7, 'clf__p': 3, 'clf__weights': 'uniform'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.88      0.58      0.70        26
           1       0.27      0.67      0.38         6

   micro avg       0.59      0.59      0.59        32
   macro avg       0.57      0.62      0.54        32
weighted avg       0.77      0.59      0.64        32


Accuracy: 0.59375
Balanced Accuracy: 0.6217948717948718
Precision: 0.26666666666666666
Recall: 0.6666666666666666
F1: 0.3809523809523809
AUROC: 0.6217948717948717
Confusion Matrix: [[15 11]
 [ 2  4]]

# =========================== Tuning hyper-parameters for recall

Fitting 4 folds for each of 96 candidates, totalling 384 fits
Best parameters set found on development set:

{'clf__algorithm': 'auto', 'clf__n_neighbors': 7, 'clf__p': 1, 'clf__weights': 'uniform'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.89      0.65      0.76        26
           1       0.31      0.67      0.42         6

   micro avg       0.66      0.66      0.66        32
   macro avg       0.60      0.66      0.59        32
weighted avg       0.78      0.66      0.69        32


Accuracy: 0.65625
Balanced Accuracy: 0.6602564102564102
Precision: 0.3076923076923077
Recall: 0.6666666666666666
F1: 0.42105263157894735
AUROC: 0.6602564102564102
Confusion Matrix: [[17  9]
 [ 2  4]]

# =========================== Tuning hyper-parameters for f1

Fitting 4 folds for each of 96 candidates, totalling 384 fits
Best parameters set found on development set:

{'clf__algorithm': 'kd_tree', 'clf__n_neighbors': 9, 'clf__p': 1, 'clf__weights': 'uniform'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.93      0.50      0.65        26
           1       0.28      0.83      0.42         6

   micro avg       0.56      0.56      0.56        32
   macro avg       0.60      0.67      0.53        32
weighted avg       0.81      0.56      0.61        32


Accuracy: 0.5625
Balanced Accuracy: 0.6666666666666667
Precision: 0.2777777777777778
Recall: 0.8333333333333334
F1: 0.4166666666666667
AUROC: 0.6666666666666667
Confusion Matrix: [[13 13]
 [ 1  5]]

# =========================== Tuning hyper-parameters for balanced_accuracy

Fitting 4 folds for each of 96 candidates, totalling 384 fits
Best parameters set found on development set:

{'clf__algorithm': 'kd_tree', 'clf__n_neighbors': 9, 'clf__p': 2, 'clf__weights': 'distance'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.94      0.62      0.74        26
           1       0.33      0.83      0.48         6

   micro avg       0.66      0.66      0.66        32
   macro avg       0.64      0.72      0.61        32
weighted avg       0.83      0.66      0.69        32


Accuracy: 0.65625
Balanced Accuracy: 0.7243589743589745
Precision: 0.3333333333333333
Recall: 0.8333333333333334
F1: 0.47619047619047616
AUROC: 0.7243589743589745
Confusion Matrix: [[16 10]
 [ 1  5]]

# =========================== Tuning hyper-parameters for roc_auc

Fitting 4 folds for each of 96 candidates, totalling 384 fits
Best parameters set found on development set:

{'clf__algorithm': 'ball_tree', 'clf__n_neighbors': 9, 'clf__p': 3, 'clf__weights': 'uniform'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.94      0.62      0.74        26
           1       0.33      0.83      0.48         6

   micro avg       0.66      0.66      0.66        32
   macro avg       0.64      0.72      0.61        32
weighted avg       0.83      0.66      0.69        32


Accuracy: 0.65625
Balanced Accuracy: 0.7243589743589745
Precision: 0.3333333333333333
Recall: 0.8333333333333334
F1: 0.47619047619047616
AUROC: 0.7243589743589745
Confusion Matrix: [[16 10]
 [ 1  5]]

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
==============================
 ada 
==============================
# =========================== Tuning hyper-parameters for precision

Fitting 4 folds for each of 40 candidates, totalling 160 fits
Best parameters set found on development set:

{'clf__algorithm': 'SAMME.R', 'clf__learning_rate': 0.01, 'clf__n_estimators': 100}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.95      0.81      0.88        26
           1       0.50      0.83      0.62         6

   micro avg       0.81      0.81      0.81        32
   macro avg       0.73      0.82      0.75        32
weighted avg       0.87      0.81      0.83        32


Accuracy: 0.8125
Balanced Accuracy: 0.8205128205128205
Precision: 0.5
Recall: 0.8333333333333334
F1: 0.625
AUROC: 0.8205128205128206
Confusion Matrix: [[21  5]
 [ 1  5]]

# =========================== Tuning hyper-parameters for recall

Fitting 4 folds for each of 40 candidates, totalling 160 fits
Best parameters set found on development set:

{'clf__algorithm': 'SAMME', 'clf__learning_rate': 0.05, 'clf__n_estimators': 10}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.95      0.81      0.88        26
           1       0.50      0.83      0.62         6

   micro avg       0.81      0.81      0.81        32
   macro avg       0.73      0.82      0.75        32
weighted avg       0.87      0.81      0.83        32


Accuracy: 0.8125
Balanced Accuracy: 0.8205128205128205
Precision: 0.5
Recall: 0.8333333333333334
F1: 0.625
AUROC: 0.8205128205128206
Confusion Matrix: [[21  5]
 [ 1  5]]

# =========================== Tuning hyper-parameters for f1

Fitting 4 folds for each of 40 candidates, totalling 160 fits
Best parameters set found on development set:

{'clf__algorithm': 'SAMME.R', 'clf__learning_rate': 0.01, 'clf__n_estimators': 100}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.95      0.81      0.88        26
           1       0.50      0.83      0.62         6

   micro avg       0.81      0.81      0.81        32
   macro avg       0.73      0.82      0.75        32
weighted avg       0.87      0.81      0.83        32


Accuracy: 0.8125
Balanced Accuracy: 0.8205128205128205
Precision: 0.5
Recall: 0.8333333333333334
F1: 0.625
AUROC: 0.8205128205128206
Confusion Matrix: [[21  5]
 [ 1  5]]

# =========================== Tuning hyper-parameters for balanced_accuracy

Fitting 4 folds for each of 40 candidates, totalling 160 fits
Best parameters set found on development set:

{'clf__algorithm': 'SAMME', 'clf__learning_rate': 0.01, 'clf__n_estimators': 50}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.95      0.77      0.85        26
           1       0.45      0.83      0.59         6

   micro avg       0.78      0.78      0.78        32
   macro avg       0.70      0.80      0.72        32
weighted avg       0.86      0.78      0.80        32


Accuracy: 0.78125
Balanced Accuracy: 0.8012820512820513
Precision: 0.45454545454545453
Recall: 0.8333333333333334
F1: 0.5882352941176471
AUROC: 0.8012820512820513
Confusion Matrix: [[20  6]
 [ 1  5]]

# =========================== Tuning hyper-parameters for roc_auc

Fitting 4 folds for each of 40 candidates, totalling 160 fits
Best parameters set found on development set:

{'clf__algorithm': 'SAMME.R', 'clf__learning_rate': 0.01, 'clf__n_estimators': 50}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.95      0.81      0.88        26
           1       0.50      0.83      0.62         6

   micro avg       0.81      0.81      0.81        32
   macro avg       0.73      0.82      0.75        32
weighted avg       0.87      0.81      0.83        32


Accuracy: 0.8125
Balanced Accuracy: 0.8205128205128205
Precision: 0.5
Recall: 0.8333333333333334
F1: 0.625
AUROC: 0.8205128205128206
Confusion Matrix: [[21  5]
 [ 1  5]]

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
==============================
 svm 
==============================
# =========================== Tuning hyper-parameters for precision

Fitting 4 folds for each of 81 candidates, totalling 324 fits
Best parameters set found on development set:

{'clf__C': 0.001, 'clf__gamma': 1, 'clf__kernel': 'rbf'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.86      0.92      0.89        26
           1       0.50      0.33      0.40         6

   micro avg       0.81      0.81      0.81        32
   macro avg       0.68      0.63      0.64        32
weighted avg       0.79      0.81      0.80        32


Accuracy: 0.8125
Balanced Accuracy: 0.6282051282051282
Precision: 0.5
Recall: 0.3333333333333333
F1: 0.4
AUROC: 0.6282051282051282
Confusion Matrix: [[24  2]
 [ 4  2]]

# =========================== Tuning hyper-parameters for recall

Fitting 4 folds for each of 81 candidates, totalling 324 fits
Best parameters set found on development set:

{'clf__C': 0.001, 'clf__gamma': 0.001, 'clf__kernel': 'rbf'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.54      0.70        26
           1       0.33      1.00      0.50         6

   micro avg       0.62      0.62      0.62        32
   macro avg       0.67      0.77      0.60        32
weighted avg       0.88      0.62      0.66        32


Accuracy: 0.625
Balanced Accuracy: 0.7692307692307692
Precision: 0.3333333333333333
Recall: 1.0
F1: 0.5
AUROC: 0.7692307692307692
Confusion Matrix: [[14 12]
 [ 0  6]]

# =========================== Tuning hyper-parameters for f1

Fitting 4 folds for each of 81 candidates, totalling 324 fits
Best parameters set found on development set:

{'clf__C': 1000, 'clf__gamma': 0.0001, 'clf__kernel': 'sigmoid'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.73      0.84        26
           1       0.46      1.00      0.63         6

   micro avg       0.78      0.78      0.78        32
   macro avg       0.73      0.87      0.74        32
weighted avg       0.90      0.78      0.80        32


Accuracy: 0.78125
Balanced Accuracy: 0.8653846153846154
Precision: 0.46153846153846156
Recall: 1.0
F1: 0.631578947368421
AUROC: 0.8653846153846154
Confusion Matrix: [[19  7]
 [ 0  6]]

# =========================== Tuning hyper-parameters for balanced_accuracy

Fitting 4 folds for each of 81 candidates, totalling 324 fits
Best parameters set found on development set:

{'clf__C': 100, 'clf__gamma': 0.001, 'clf__kernel': 'sigmoid'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.77      0.87        26
           1       0.50      1.00      0.67         6

   micro avg       0.81      0.81      0.81        32
   macro avg       0.75      0.88      0.77        32
weighted avg       0.91      0.81      0.83        32


Accuracy: 0.8125
Balanced Accuracy: 0.8846153846153846
Precision: 0.5
Recall: 1.0
F1: 0.6666666666666666
AUROC: 0.8846153846153846
Confusion Matrix: [[20  6]
 [ 0  6]]

# =========================== Tuning hyper-parameters for roc_auc

Fitting 4 folds for each of 81 candidates, totalling 324 fits
Best parameters set found on development set:

{'clf__C': 100, 'clf__gamma': 0.0001, 'clf__kernel': 'rbf'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.58      0.73        26
           1       0.35      1.00      0.52         6

   micro avg       0.66      0.66      0.66        32
   macro avg       0.68      0.79      0.63        32
weighted avg       0.88      0.66      0.69        32


Accuracy: 0.65625
Balanced Accuracy: 0.7884615384615384
Precision: 0.35294117647058826
Recall: 1.0
F1: 0.5217391304347826
AUROC: 0.7884615384615384
Confusion Matrix: [[15 11]
 [ 0  6]]

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
==============================
 decision_tree 
==============================
# =========================== Tuning hyper-parameters for precision

Fitting 4 folds for each of 1200 candidates, totalling 4800 fits
Best parameters set found on development set:

{'clf__criterion': 'gini', 'clf__max_depth': 2, 'clf__max_features': 'auto', 'clf__min_samples_leaf': 3, 'clf__min_samples_split': 4, 'clf__splitter': 'best'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.96      0.85      0.90        26
           1       0.56      0.83      0.67         6

   micro avg       0.84      0.84      0.84        32
   macro avg       0.76      0.84      0.78        32
weighted avg       0.88      0.84      0.85        32


Accuracy: 0.84375
Balanced Accuracy: 0.8397435897435898
Precision: 0.5555555555555556
Recall: 0.8333333333333334
F1: 0.6666666666666667
AUROC: 0.8397435897435898
Confusion Matrix: [[22  4]
 [ 1  5]]

# =========================== Tuning hyper-parameters for recall

Fitting 4 folds for each of 1200 candidates, totalling 4800 fits
Best parameters set found on development set:

{'clf__criterion': 'gini', 'clf__max_depth': 2, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 6, 'clf__splitter': 'random'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.88      0.27      0.41        26
           1       0.21      0.83      0.33         6

   micro avg       0.38      0.38      0.38        32
   macro avg       0.54      0.55      0.37        32
weighted avg       0.75      0.38      0.40        32


Accuracy: 0.375
Balanced Accuracy: 0.5512820512820513
Precision: 0.20833333333333334
Recall: 0.8333333333333334
F1: 0.33333333333333337
AUROC: 0.5512820512820513
Confusion Matrix: [[ 7 19]
 [ 1  5]]

# =========================== Tuning hyper-parameters for f1

Fitting 4 folds for each of 1200 candidates, totalling 4800 fits
Best parameters set found on development set:

{'clf__criterion': 'gini', 'clf__max_depth': 2, 'clf__max_features': 'auto', 'clf__min_samples_leaf': 5, 'clf__min_samples_split': 3, 'clf__splitter': 'best'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.88      0.85      0.86        26
           1       0.43      0.50      0.46         6

   micro avg       0.78      0.78      0.78        32
   macro avg       0.65      0.67      0.66        32
weighted avg       0.80      0.78      0.79        32


Accuracy: 0.78125
Balanced Accuracy: 0.6730769230769231
Precision: 0.42857142857142855
Recall: 0.5
F1: 0.4615384615384615
AUROC: 0.673076923076923
Confusion Matrix: [[22  4]
 [ 3  3]]

# =========================== Tuning hyper-parameters for balanced_accuracy

Fitting 4 folds for each of 1200 candidates, totalling 4800 fits
Best parameters set found on development set:

{'clf__criterion': 'gini', 'clf__max_depth': 2, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 2, 'clf__min_samples_split': 5, 'clf__splitter': 'best'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.96      0.85      0.90        26
           1       0.56      0.83      0.67         6

   micro avg       0.84      0.84      0.84        32
   macro avg       0.76      0.84      0.78        32
weighted avg       0.88      0.84      0.85        32


Accuracy: 0.84375
Balanced Accuracy: 0.8397435897435898
Precision: 0.5555555555555556
Recall: 0.8333333333333334
F1: 0.6666666666666667
AUROC: 0.8397435897435898
Confusion Matrix: [[22  4]
 [ 1  5]]

# =========================== Tuning hyper-parameters for roc_auc

Fitting 4 folds for each of 1200 candidates, totalling 4800 fits
Best parameters set found on development set:

{'clf__criterion': 'entropy', 'clf__max_depth': 2, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 6, 'clf__splitter': 'best'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.88      0.88      0.88        26
           1       0.50      0.50      0.50         6

   micro avg       0.81      0.81      0.81        32
   macro avg       0.69      0.69      0.69        32
weighted avg       0.81      0.81      0.81        32


Accuracy: 0.8125
Balanced Accuracy: 0.6923076923076923
Precision: 0.5
Recall: 0.5
F1: 0.5
AUROC: 0.6923076923076923
Confusion Matrix: [[23  3]
 [ 3  3]]

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
==============================
 random_forest 
==============================
# =========================== Tuning hyper-parameters for precision

Fitting 4 folds for each of 540 candidates, totalling 2160 fits
Best parameters set found on development set:

{'clf__bootstrap': True, 'clf__max_depth': 50, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 4, 'clf__n_estimators': 10}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.92      0.92      0.92        26
           1       0.67      0.67      0.67         6

   micro avg       0.88      0.88      0.88        32
   macro avg       0.79      0.79      0.79        32
weighted avg       0.88      0.88      0.88        32


Accuracy: 0.875
Balanced Accuracy: 0.7948717948717949
Precision: 0.6666666666666666
Recall: 0.6666666666666666
F1: 0.6666666666666666
AUROC: 0.7948717948717948
Confusion Matrix: [[24  2]
 [ 2  4]]

# =========================== Tuning hyper-parameters for recall

Fitting 4 folds for each of 540 candidates, totalling 2160 fits
Best parameters set found on development set:

{'clf__bootstrap': True, 'clf__max_depth': 2, 'clf__max_features': 'auto', 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 2, 'clf__n_estimators': 80}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.85      0.92        26
           1       0.60      1.00      0.75         6

   micro avg       0.88      0.88      0.88        32
   macro avg       0.80      0.92      0.83        32
weighted avg       0.93      0.88      0.89        32


Accuracy: 0.875
Balanced Accuracy: 0.9230769230769231
Precision: 0.6
Recall: 1.0
F1: 0.7499999999999999
AUROC: 0.9230769230769231
Confusion Matrix: [[22  4]
 [ 0  6]]

# =========================== Tuning hyper-parameters for f1

Fitting 4 folds for each of 540 candidates, totalling 2160 fits
Best parameters set found on development set:

{'clf__bootstrap': True, 'clf__max_depth': 2, 'clf__max_features': 'auto', 'clf__min_samples_leaf': 5, 'clf__min_samples_split': 2, 'clf__n_estimators': 80}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.81      0.89        26
           1       0.55      1.00      0.71         6

   micro avg       0.84      0.84      0.84        32
   macro avg       0.77      0.90      0.80        32
weighted avg       0.91      0.84      0.86        32


Accuracy: 0.84375
Balanced Accuracy: 0.9038461538461539
Precision: 0.5454545454545454
Recall: 1.0
F1: 0.7058823529411764
AUROC: 0.9038461538461539
Confusion Matrix: [[21  5]
 [ 0  6]]

# =========================== Tuning hyper-parameters for balanced_accuracy

Fitting 4 folds for each of 540 candidates, totalling 2160 fits
Best parameters set found on development set:

{'clf__bootstrap': False, 'clf__max_depth': 2, 'clf__max_features': 'auto', 'clf__min_samples_leaf': 5, 'clf__min_samples_split': 6, 'clf__n_estimators': 80}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.85      0.92        26
           1       0.60      1.00      0.75         6

   micro avg       0.88      0.88      0.88        32
   macro avg       0.80      0.92      0.83        32
weighted avg       0.93      0.88      0.89        32


Accuracy: 0.875
Balanced Accuracy: 0.9230769230769231
Precision: 0.6
Recall: 1.0
F1: 0.7499999999999999
AUROC: 0.9230769230769231
Confusion Matrix: [[22  4]
 [ 0  6]]

# =========================== Tuning hyper-parameters for roc_auc

Fitting 4 folds for each of 540 candidates, totalling 2160 fits
Best parameters set found on development set:

{'clf__bootstrap': False, 'clf__max_depth': 2, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 5, 'clf__min_samples_split': 6, 'clf__n_estimators': 10}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.85      0.92        26
           1       0.60      1.00      0.75         6

   micro avg       0.88      0.88      0.88        32
   macro avg       0.80      0.92      0.83        32
weighted avg       0.93      0.88      0.89        32


Accuracy: 0.875
Balanced Accuracy: 0.9230769230769231
Precision: 0.6
Recall: 1.0
F1: 0.7499999999999999
AUROC: 0.9230769230769231
Confusion Matrix: [[22  4]
 [ 0  6]]

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
==============================
 mlp 
==============================
# =========================== Tuning hyper-parameters for precision

Fitting 4 folds for each of 36 candidates, totalling 144 fits
Best parameters set found on development set:

{'clf__activation': 'relu', 'clf__alpha': 0.005, 'clf__hidden_layer_sizes': (100,), 'clf__solver': 'sgd'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.95      0.81      0.88        26
           1       0.50      0.83      0.62         6

   micro avg       0.81      0.81      0.81        32
   macro avg       0.73      0.82      0.75        32
weighted avg       0.87      0.81      0.83        32


Accuracy: 0.8125
Balanced Accuracy: 0.8205128205128205
Precision: 0.5
Recall: 0.8333333333333334
F1: 0.625
AUROC: 0.8205128205128206
Confusion Matrix: [[21  5]
 [ 1  5]]

# =========================== Tuning hyper-parameters for recall

Fitting 4 folds for each of 36 candidates, totalling 144 fits
Best parameters set found on development set:

{'clf__activation': 'tanh', 'clf__alpha': 0.0001, 'clf__hidden_layer_sizes': (100,), 'clf__solver': 'sgd'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.77      0.87        26
           1       0.50      1.00      0.67         6

   micro avg       0.81      0.81      0.81        32
   macro avg       0.75      0.88      0.77        32
weighted avg       0.91      0.81      0.83        32


Accuracy: 0.8125
Balanced Accuracy: 0.8846153846153846
Precision: 0.5
Recall: 1.0
F1: 0.6666666666666666
AUROC: 0.8846153846153846
Confusion Matrix: [[20  6]
 [ 0  6]]

# =========================== Tuning hyper-parameters for f1

Fitting 4 folds for each of 36 candidates, totalling 144 fits
Best parameters set found on development set:

{'clf__activation': 'tanh', 'clf__alpha': 0.005, 'clf__hidden_layer_sizes': (300,), 'clf__solver': 'sgd'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.73      0.84        26
           1       0.46      1.00      0.63         6

   micro avg       0.78      0.78      0.78        32
   macro avg       0.73      0.87      0.74        32
weighted avg       0.90      0.78      0.80        32


Accuracy: 0.78125
Balanced Accuracy: 0.8653846153846154
Precision: 0.46153846153846156
Recall: 1.0
F1: 0.631578947368421
AUROC: 0.8653846153846154
Confusion Matrix: [[19  7]
 [ 0  6]]

# =========================== Tuning hyper-parameters for balanced_accuracy

Fitting 4 folds for each of 36 candidates, totalling 144 fits
Best parameters set found on development set:

{'clf__activation': 'relu', 'clf__alpha': 0.005, 'clf__hidden_layer_sizes': (300,), 'clf__solver': 'sgd'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.77      0.87        26
           1       0.50      1.00      0.67         6

   micro avg       0.81      0.81      0.81        32
   macro avg       0.75      0.88      0.77        32
weighted avg       0.91      0.81      0.83        32


Accuracy: 0.8125
Balanced Accuracy: 0.8846153846153846
Precision: 0.5
Recall: 1.0
F1: 0.6666666666666666
AUROC: 0.8846153846153846
Confusion Matrix: [[20  6]
 [ 0  6]]

# =========================== Tuning hyper-parameters for roc_auc

Fitting 4 folds for each of 36 candidates, totalling 144 fits
Best parameters set found on development set:

{'clf__activation': 'relu', 'clf__alpha': 0.0001, 'clf__hidden_layer_sizes': (32, 8, 32), 'clf__solver': 'sgd'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.96      0.88      0.92        26
           1       0.62      0.83      0.71         6

   micro avg       0.88      0.88      0.88        32
   macro avg       0.79      0.86      0.82        32
weighted avg       0.90      0.88      0.88        32


Accuracy: 0.875
Balanced Accuracy: 0.858974358974359
Precision: 0.625
Recall: 0.8333333333333334
F1: 0.7142857142857143
AUROC: 0.858974358974359
Confusion Matrix: [[23  3]
 [ 1  5]]

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
