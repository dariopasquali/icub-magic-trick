drop NaN
normalize whithin subject
Split in Train and Test set, equal for all the models and column set
 Multiple Grid Search 
==============================
columns ['descr_right_mean', 'descr_left_mean', 'react_right_mean', 'react_left_mean']
number of datapoint: 144
Normalize: True
Oversample: True
Oversample Mode: minmax
Drop NaN: True
==============================
==============================
Train Set Datapoints 108
Test Set Datapoints 36
==============================
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
==============================
 Support Vector Machine 
==============================
# =========================== Tuning hyper-parameters for precision

Fitting 4 folds for each of 81 candidates, totalling 324 fits
Best parameters set found on development set:

{'clf__C': 1000, 'clf__gamma': 0.1, 'clf__kernel': 'rbf'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.96      0.87      0.91        30
           1       0.56      0.83      0.67         6

   micro avg       0.86      0.86      0.86        36
   macro avg       0.76      0.85      0.79        36
weighted avg       0.90      0.86      0.87        36


Accuracy: 0.8611111111111112
Balanced Accuracy: 0.8500000000000001
Precision: 0.5555555555555556
Recall: 0.8333333333333334
F1: 0.6666666666666667
AUROC: 0.8500000000000001

# =========================== Tuning hyper-parameters for recall

Fitting 4 folds for each of 81 candidates, totalling 324 fits
Best parameters set found on development set:

{'clf__C': 0.001, 'clf__gamma': 0.001, 'clf__kernel': 'rbf'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.57      0.72        30
           1       0.32      1.00      0.48         6

   micro avg       0.64      0.64      0.64        36
   macro avg       0.66      0.78      0.60        36
weighted avg       0.89      0.64      0.68        36


Accuracy: 0.6388888888888888
Balanced Accuracy: 0.7833333333333333
Precision: 0.3157894736842105
Recall: 1.0
F1: 0.4799999999999999
AUROC: 0.7833333333333333

# =========================== Tuning hyper-parameters for f1

Fitting 4 folds for each of 81 candidates, totalling 324 fits
Best parameters set found on development set:

{'clf__C': 10, 'clf__gamma': 1, 'clf__kernel': 'rbf'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.87      0.93        30
           1       0.60      1.00      0.75         6

   micro avg       0.89      0.89      0.89        36
   macro avg       0.80      0.93      0.84        36
weighted avg       0.93      0.89      0.90        36


Accuracy: 0.8888888888888888
Balanced Accuracy: 0.9333333333333333
Precision: 0.6
Recall: 1.0
F1: 0.7499999999999999
AUROC: 0.9333333333333333

# =========================== Tuning hyper-parameters for balanced_accuracy

Fitting 4 folds for each of 81 candidates, totalling 324 fits
Best parameters set found on development set:

{'clf__C': 0.1, 'clf__gamma': 1, 'clf__kernel': 'rbf'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.77      0.87        30
           1       0.46      1.00      0.63         6

   micro avg       0.81      0.81      0.81        36
   macro avg       0.73      0.88      0.75        36
weighted avg       0.91      0.81      0.83        36


Accuracy: 0.8055555555555556
Balanced Accuracy: 0.8833333333333333
Precision: 0.46153846153846156
Recall: 1.0
F1: 0.631578947368421
AUROC: 0.8833333333333333

# =========================== Tuning hyper-parameters for roc_auc

Fitting 4 folds for each of 81 candidates, totalling 324 fits
Best parameters set found on development set:

{'clf__C': 10, 'clf__gamma': 0.1, 'clf__kernel': 'rbf'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.80      0.89        30
           1       0.50      1.00      0.67         6

   micro avg       0.83      0.83      0.83        36
   macro avg       0.75      0.90      0.78        36
weighted avg       0.92      0.83      0.85        36


Accuracy: 0.8333333333333334
Balanced Accuracy: 0.9
Precision: 0.5
Recall: 1.0
F1: 0.6666666666666666
AUROC: 0.9

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
==============================
 Decision Tree 
==============================
# =========================== Tuning hyper-parameters for precision

Fitting 4 folds for each of 1200 candidates, totalling 4800 fits
Best parameters set found on development set:

{'clf__criterion': 'gini', 'clf__max_depth': 10, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 3, 'clf__splitter': 'random'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.96      0.83      0.89        30
           1       0.50      0.83      0.62         6

   micro avg       0.83      0.83      0.83        36
   macro avg       0.73      0.83      0.76        36
weighted avg       0.88      0.83      0.85        36


Accuracy: 0.8333333333333334
Balanced Accuracy: 0.8333333333333334
Precision: 0.5
Recall: 0.8333333333333334
F1: 0.625
AUROC: 0.8333333333333334

# =========================== Tuning hyper-parameters for recall

Fitting 4 folds for each of 1200 candidates, totalling 4800 fits
Best parameters set found on development set:

{'clf__criterion': 'entropy', 'clf__max_depth': 2, 'clf__max_features': 'auto', 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 3, 'clf__splitter': 'random'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.57      0.72        30
           1       0.32      1.00      0.48         6

   micro avg       0.64      0.64      0.64        36
   macro avg       0.66      0.78      0.60        36
weighted avg       0.89      0.64      0.68        36


Accuracy: 0.6388888888888888
Balanced Accuracy: 0.7833333333333333
Precision: 0.3157894736842105
Recall: 1.0
F1: 0.4799999999999999
AUROC: 0.7833333333333333

# =========================== Tuning hyper-parameters for f1

Fitting 4 folds for each of 1200 candidates, totalling 4800 fits
Best parameters set found on development set:

{'clf__criterion': 'entropy', 'clf__max_depth': 2, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 4, 'clf__min_samples_split': 3, 'clf__splitter': 'best'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.96      0.83      0.89        30
           1       0.50      0.83      0.62         6

   micro avg       0.83      0.83      0.83        36
   macro avg       0.73      0.83      0.76        36
weighted avg       0.88      0.83      0.85        36


Accuracy: 0.8333333333333334
Balanced Accuracy: 0.8333333333333334
Precision: 0.5
Recall: 0.8333333333333334
F1: 0.625
AUROC: 0.8333333333333334

# =========================== Tuning hyper-parameters for balanced_accuracy

Fitting 4 folds for each of 1200 candidates, totalling 4800 fits
Best parameters set found on development set:

{'clf__criterion': 'entropy', 'clf__max_depth': 20, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 5, 'clf__min_samples_split': 4, 'clf__splitter': 'best'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.96      0.87      0.91        30
           1       0.56      0.83      0.67         6

   micro avg       0.86      0.86      0.86        36
   macro avg       0.76      0.85      0.79        36
weighted avg       0.90      0.86      0.87        36


Accuracy: 0.8611111111111112
Balanced Accuracy: 0.8500000000000001
Precision: 0.5555555555555556
Recall: 0.8333333333333334
F1: 0.6666666666666667
AUROC: 0.8500000000000001

# =========================== Tuning hyper-parameters for roc_auc

Fitting 4 folds for each of 1200 candidates, totalling 4800 fits
Best parameters set found on development set:

{'clf__criterion': 'gini', 'clf__max_depth': 10, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 3, 'clf__min_samples_split': 6, 'clf__splitter': 'random'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.96      0.83      0.89        30
           1       0.50      0.83      0.62         6

   micro avg       0.83      0.83      0.83        36
   macro avg       0.73      0.83      0.76        36
weighted avg       0.88      0.83      0.85        36


Accuracy: 0.8333333333333334
Balanced Accuracy: 0.8333333333333334
Precision: 0.5
Recall: 0.8333333333333334
F1: 0.625
AUROC: 0.8333333333333334

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
==============================
 Adaptive Boosting 
==============================
# =========================== Tuning hyper-parameters for precision

Fitting 4 folds for each of 40 candidates, totalling 160 fits
Best parameters set found on development set:

{'clf__algorithm': 'SAMME', 'clf__learning_rate': 0.01, 'clf__n_estimators': 50}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.96      0.83      0.89        30
           1       0.50      0.83      0.62         6

   micro avg       0.83      0.83      0.83        36
   macro avg       0.73      0.83      0.76        36
weighted avg       0.88      0.83      0.85        36


Accuracy: 0.8333333333333334
Balanced Accuracy: 0.8333333333333334
Precision: 0.5
Recall: 0.8333333333333334
F1: 0.625
AUROC: 0.8333333333333334

# =========================== Tuning hyper-parameters for recall

Fitting 4 folds for each of 40 candidates, totalling 160 fits
Best parameters set found on development set:

{'clf__algorithm': 'SAMME', 'clf__learning_rate': 0.01, 'clf__n_estimators': 50}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.96      0.83      0.89        30
           1       0.50      0.83      0.62         6

   micro avg       0.83      0.83      0.83        36
   macro avg       0.73      0.83      0.76        36
weighted avg       0.88      0.83      0.85        36


Accuracy: 0.8333333333333334
Balanced Accuracy: 0.8333333333333334
Precision: 0.5
Recall: 0.8333333333333334
F1: 0.625
AUROC: 0.8333333333333334

# =========================== Tuning hyper-parameters for f1

Fitting 4 folds for each of 40 candidates, totalling 160 fits
Best parameters set found on development set:

{'clf__algorithm': 'SAMME', 'clf__learning_rate': 0.01, 'clf__n_estimators': 100}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.96      0.83      0.89        30
           1       0.50      0.83      0.62         6

   micro avg       0.83      0.83      0.83        36
   macro avg       0.73      0.83      0.76        36
weighted avg       0.88      0.83      0.85        36


Accuracy: 0.8333333333333334
Balanced Accuracy: 0.8333333333333334
Precision: 0.5
Recall: 0.8333333333333334
F1: 0.625
AUROC: 0.8333333333333334

# =========================== Tuning hyper-parameters for balanced_accuracy

Fitting 4 folds for each of 40 candidates, totalling 160 fits
Best parameters set found on development set:

{'clf__algorithm': 'SAMME', 'clf__learning_rate': 0.01, 'clf__n_estimators': 10}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.96      0.83      0.89        30
           1       0.50      0.83      0.62         6

   micro avg       0.83      0.83      0.83        36
   macro avg       0.73      0.83      0.76        36
weighted avg       0.88      0.83      0.85        36


Accuracy: 0.8333333333333334
Balanced Accuracy: 0.8333333333333334
Precision: 0.5
Recall: 0.8333333333333334
F1: 0.625
AUROC: 0.8333333333333334

# =========================== Tuning hyper-parameters for roc_auc

Fitting 4 folds for each of 40 candidates, totalling 160 fits
Best parameters set found on development set:

{'clf__algorithm': 'SAMME', 'clf__learning_rate': 0.05, 'clf__n_estimators': 100}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.96      0.83      0.89        30
           1       0.50      0.83      0.62         6

   micro avg       0.83      0.83      0.83        36
   macro avg       0.73      0.83      0.76        36
weighted avg       0.88      0.83      0.85        36


Accuracy: 0.8333333333333334
Balanced Accuracy: 0.8333333333333334
Precision: 0.5
Recall: 0.8333333333333334
F1: 0.625
AUROC: 0.8333333333333334

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
==============================
 Random Forest 
==============================
# =========================== Tuning hyper-parameters for precision

Fitting 4 folds for each of 540 candidates, totalling 2160 fits
Best parameters set found on development set:

{'clf__bootstrap': True, 'clf__max_depth': 10, 'clf__max_features': 'auto', 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 2, 'clf__n_estimators': 10}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.96      0.83      0.89        30
           1       0.50      0.83      0.62         6

   micro avg       0.83      0.83      0.83        36
   macro avg       0.73      0.83      0.76        36
weighted avg       0.88      0.83      0.85        36


Accuracy: 0.8333333333333334
Balanced Accuracy: 0.8333333333333334
Precision: 0.5
Recall: 0.8333333333333334
F1: 0.625
AUROC: 0.8333333333333334

# =========================== Tuning hyper-parameters for recall

Fitting 4 folds for each of 540 candidates, totalling 2160 fits
Best parameters set found on development set:

{'clf__bootstrap': True, 'clf__max_depth': 2, 'clf__max_features': 'auto', 'clf__min_samples_leaf': 3, 'clf__min_samples_split': 6, 'clf__n_estimators': 80}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.96      0.83      0.89        30
           1       0.50      0.83      0.62         6

   micro avg       0.83      0.83      0.83        36
   macro avg       0.73      0.83      0.76        36
weighted avg       0.88      0.83      0.85        36


Accuracy: 0.8333333333333334
Balanced Accuracy: 0.8333333333333334
Precision: 0.5
Recall: 0.8333333333333334
F1: 0.625
AUROC: 0.8333333333333334

# =========================== Tuning hyper-parameters for f1

Fitting 4 folds for each of 540 candidates, totalling 2160 fits
Best parameters set found on development set:

{'clf__bootstrap': False, 'clf__max_depth': 20, 'clf__max_features': 'auto', 'clf__min_samples_leaf': 5, 'clf__min_samples_split': 4, 'clf__n_estimators': 10}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.96      0.83      0.89        30
           1       0.50      0.83      0.62         6

   micro avg       0.83      0.83      0.83        36
   macro avg       0.73      0.83      0.76        36
weighted avg       0.88      0.83      0.85        36


Accuracy: 0.8333333333333334
Balanced Accuracy: 0.8333333333333334
Precision: 0.5
Recall: 0.8333333333333334
F1: 0.625
AUROC: 0.8333333333333334

# =========================== Tuning hyper-parameters for balanced_accuracy

Fitting 4 folds for each of 540 candidates, totalling 2160 fits
Best parameters set found on development set:

{'clf__bootstrap': True, 'clf__max_depth': 2, 'clf__max_features': 'auto', 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 2, 'clf__n_estimators': 10}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.96      0.83      0.89        30
           1       0.50      0.83      0.62         6

   micro avg       0.83      0.83      0.83        36
   macro avg       0.73      0.83      0.76        36
weighted avg       0.88      0.83      0.85        36


Accuracy: 0.8333333333333334
Balanced Accuracy: 0.8333333333333334
Precision: 0.5
Recall: 0.8333333333333334
F1: 0.625
AUROC: 0.8333333333333334

# =========================== Tuning hyper-parameters for roc_auc

Fitting 4 folds for each of 540 candidates, totalling 2160 fits
Best parameters set found on development set:

{'clf__bootstrap': False, 'clf__max_depth': 20, 'clf__max_features': 'auto', 'clf__min_samples_leaf': 3, 'clf__min_samples_split': 2, 'clf__n_estimators': 100}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.96      0.87      0.91        30
           1       0.56      0.83      0.67         6

   micro avg       0.86      0.86      0.86        36
   macro avg       0.76      0.85      0.79        36
weighted avg       0.90      0.86      0.87        36


Accuracy: 0.8611111111111112
Balanced Accuracy: 0.8500000000000001
Precision: 0.5555555555555556
Recall: 0.8333333333333334
F1: 0.6666666666666667
AUROC: 0.8500000000000001

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
 Multiple Grid Search 
==============================
columns ['duration', 'react_dur', 'point_dur', 'descr_dur', 'right_mean', 'right_std', 'right_min', 'right_max', 'left_mean', 'left_std', 'left_min', 'left_max', 'react_right_mean', 'react_right_std', 'react_right_min', 'react_right_max', 'react_left_mean', 'react_left_std', 'react_left_min', 'react_left_max', 'point_right_mean', 'point_right_std', 'point_right_min', 'point_right_max', 'point_left_mean', 'point_left_std', 'point_left_min', 'point_left_max', 'descr_right_mean', 'descr_right_std', 'descr_right_min', 'descr_right_max', 'descr_left_mean', 'descr_left_std', 'descr_left_min', 'descr_left_max', 'descr_mean_pupil', 'react_mean_pupil', 'point_mean_pupil']
number of datapoint: 144
Normalize: True
Oversample: True
Oversample Mode: minmax
Drop NaN: True
==============================
==============================
Train Set Datapoints 108
Test Set Datapoints 36
==============================
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
==============================
 Support Vector Machine 
==============================
# =========================== Tuning hyper-parameters for precision

Fitting 4 folds for each of 81 candidates, totalling 324 fits
Best parameters set found on development set:

{'clf__C': 10, 'clf__gamma': 0.1, 'clf__kernel': 'rbf'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.90      0.90      0.90        30
           1       0.50      0.50      0.50         6

   micro avg       0.83      0.83      0.83        36
   macro avg       0.70      0.70      0.70        36
weighted avg       0.83      0.83      0.83        36


Accuracy: 0.8333333333333334
Balanced Accuracy: 0.7
Precision: 0.5
Recall: 0.5
F1: 0.5
AUROC: 0.7000000000000001

# =========================== Tuning hyper-parameters for recall

Fitting 4 folds for each of 81 candidates, totalling 324 fits
Best parameters set found on development set:

{'clf__C': 0.001, 'clf__gamma': 0.001, 'clf__kernel': 'rbf'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.53      0.70        30
           1       0.30      1.00      0.46         6

   micro avg       0.61      0.61      0.61        36
   macro avg       0.65      0.77      0.58        36
weighted avg       0.88      0.61      0.66        36


Accuracy: 0.6111111111111112
Balanced Accuracy: 0.7666666666666666
Precision: 0.3
Recall: 1.0
F1: 0.4615384615384615
AUROC: 0.7666666666666666

# =========================== Tuning hyper-parameters for f1

Fitting 4 folds for each of 81 candidates, totalling 324 fits
Best parameters set found on development set:

{'clf__C': 100, 'clf__gamma': 0.001, 'clf__kernel': 'sigmoid'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.96      0.80      0.87        30
           1       0.45      0.83      0.59         6

   micro avg       0.81      0.81      0.81        36
   macro avg       0.71      0.82      0.73        36
weighted avg       0.88      0.81      0.83        36


Accuracy: 0.8055555555555556
Balanced Accuracy: 0.8166666666666667
Precision: 0.45454545454545453
Recall: 0.8333333333333334
F1: 0.5882352941176471
AUROC: 0.8166666666666668

# =========================== Tuning hyper-parameters for balanced_accuracy

Fitting 4 folds for each of 81 candidates, totalling 324 fits
Best parameters set found on development set:

{'clf__C': 10, 'clf__gamma': 0.001, 'clf__kernel': 'rbf'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.95      0.67      0.78        30
           1       0.33      0.83      0.48         6

   micro avg       0.69      0.69      0.69        36
   macro avg       0.64      0.75      0.63        36
weighted avg       0.85      0.69      0.73        36


Accuracy: 0.6944444444444444
Balanced Accuracy: 0.75
Precision: 0.3333333333333333
Recall: 0.8333333333333334
F1: 0.47619047619047616
AUROC: 0.7500000000000002

# =========================== Tuning hyper-parameters for roc_auc

Fitting 4 folds for each of 81 candidates, totalling 324 fits
Best parameters set found on development set:

{'clf__C': 50, 'clf__gamma': 0.001, 'clf__kernel': 'sigmoid'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.96      0.77      0.85        30
           1       0.42      0.83      0.56         6

   micro avg       0.78      0.78      0.78        36
   macro avg       0.69      0.80      0.70        36
weighted avg       0.87      0.78      0.80        36


Accuracy: 0.7777777777777778
Balanced Accuracy: 0.8
Precision: 0.4166666666666667
Recall: 0.8333333333333334
F1: 0.5555555555555556
AUROC: 0.8

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
==============================
 Decision Tree 
==============================
# =========================== Tuning hyper-parameters for precision

Fitting 4 folds for each of 1200 candidates, totalling 4800 fits
Best parameters set found on development set:

{'clf__criterion': 'gini', 'clf__max_depth': 10, 'clf__max_features': 'auto', 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 4, 'clf__splitter': 'random'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.85      0.77      0.81        30
           1       0.22      0.33      0.27         6

   micro avg       0.69      0.69      0.69        36
   macro avg       0.54      0.55      0.54        36
weighted avg       0.75      0.69      0.72        36


Accuracy: 0.6944444444444444
Balanced Accuracy: 0.55
Precision: 0.2222222222222222
Recall: 0.3333333333333333
F1: 0.26666666666666666
AUROC: 0.5499999999999999

# =========================== Tuning hyper-parameters for recall

Fitting 4 folds for each of 1200 candidates, totalling 4800 fits
Best parameters set found on development set:

{'clf__criterion': 'entropy', 'clf__max_depth': 2, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 3, 'clf__min_samples_split': 6, 'clf__splitter': 'random'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.96      0.73      0.83        30
           1       0.38      0.83      0.53         6

   micro avg       0.75      0.75      0.75        36
   macro avg       0.67      0.78      0.68        36
weighted avg       0.86      0.75      0.78        36


Accuracy: 0.75
Balanced Accuracy: 0.7833333333333333
Precision: 0.38461538461538464
Recall: 0.8333333333333334
F1: 0.5263157894736842
AUROC: 0.7833333333333334

# =========================== Tuning hyper-parameters for f1

Fitting 4 folds for each of 1200 candidates, totalling 4800 fits
Best parameters set found on development set:

{'clf__criterion': 'gini', 'clf__max_depth': 6, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 5, 'clf__min_samples_split': 5, 'clf__splitter': 'random'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.96      0.83      0.89        30
           1       0.50      0.83      0.62         6

   micro avg       0.83      0.83      0.83        36
   macro avg       0.73      0.83      0.76        36
weighted avg       0.88      0.83      0.85        36


Accuracy: 0.8333333333333334
Balanced Accuracy: 0.8333333333333334
Precision: 0.5
Recall: 0.8333333333333334
F1: 0.625
AUROC: 0.8333333333333334

# =========================== Tuning hyper-parameters for balanced_accuracy

Fitting 4 folds for each of 1200 candidates, totalling 4800 fits
Best parameters set found on development set:

{'clf__criterion': 'entropy', 'clf__max_depth': 2, 'clf__max_features': 'auto', 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 5, 'clf__splitter': 'best'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.92      0.73      0.81        30
           1       0.33      0.67      0.44         6

   micro avg       0.72      0.72      0.72        36
   macro avg       0.62      0.70      0.63        36
weighted avg       0.82      0.72      0.75        36


Accuracy: 0.7222222222222222
Balanced Accuracy: 0.7
Precision: 0.3333333333333333
Recall: 0.6666666666666666
F1: 0.4444444444444444
AUROC: 0.7000000000000001

# =========================== Tuning hyper-parameters for roc_auc

Fitting 4 folds for each of 1200 candidates, totalling 4800 fits
Best parameters set found on development set:

{'clf__criterion': 'gini', 'clf__max_depth': 10, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 4, 'clf__min_samples_split': 3, 'clf__splitter': 'best'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.93      0.87      0.90        30
           1       0.50      0.67      0.57         6

   micro avg       0.83      0.83      0.83        36
   macro avg       0.71      0.77      0.73        36
weighted avg       0.86      0.83      0.84        36


Accuracy: 0.8333333333333334
Balanced Accuracy: 0.7666666666666666
Precision: 0.5
Recall: 0.6666666666666666
F1: 0.5714285714285715
AUROC: 0.7666666666666666

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
==============================
 Adaptive Boosting 
==============================
# =========================== Tuning hyper-parameters for precision

Fitting 4 folds for each of 40 candidates, totalling 160 fits
Best parameters set found on development set:

{'clf__algorithm': 'SAMME.R', 'clf__learning_rate': 0.1, 'clf__n_estimators': 100}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.90      0.90      0.90        30
           1       0.50      0.50      0.50         6

   micro avg       0.83      0.83      0.83        36
   macro avg       0.70      0.70      0.70        36
weighted avg       0.83      0.83      0.83        36


Accuracy: 0.8333333333333334
Balanced Accuracy: 0.7
Precision: 0.5
Recall: 0.5
F1: 0.5
AUROC: 0.7000000000000001

# =========================== Tuning hyper-parameters for recall

Fitting 4 folds for each of 40 candidates, totalling 160 fits
Best parameters set found on development set:

{'clf__algorithm': 'SAMME', 'clf__learning_rate': 0.01, 'clf__n_estimators': 10}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.96      0.83      0.89        30
           1       0.50      0.83      0.62         6

   micro avg       0.83      0.83      0.83        36
   macro avg       0.73      0.83      0.76        36
weighted avg       0.88      0.83      0.85        36


Accuracy: 0.8333333333333334
Balanced Accuracy: 0.8333333333333334
Precision: 0.5
Recall: 0.8333333333333334
F1: 0.625
AUROC: 0.8333333333333334

# =========================== Tuning hyper-parameters for f1

Fitting 4 folds for each of 40 candidates, totalling 160 fits
Best parameters set found on development set:

{'clf__algorithm': 'SAMME', 'clf__learning_rate': 0.05, 'clf__n_estimators': 10}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.96      0.83      0.89        30
           1       0.50      0.83      0.62         6

   micro avg       0.83      0.83      0.83        36
   macro avg       0.73      0.83      0.76        36
weighted avg       0.88      0.83      0.85        36


Accuracy: 0.8333333333333334
Balanced Accuracy: 0.8333333333333334
Precision: 0.5
Recall: 0.8333333333333334
F1: 0.625
AUROC: 0.8333333333333334

# =========================== Tuning hyper-parameters for balanced_accuracy

Fitting 4 folds for each of 40 candidates, totalling 160 fits
Best parameters set found on development set:

{'clf__algorithm': 'SAMME', 'clf__learning_rate': 0.01, 'clf__n_estimators': 10}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.96      0.83      0.89        30
           1       0.50      0.83      0.62         6

   micro avg       0.83      0.83      0.83        36
   macro avg       0.73      0.83      0.76        36
weighted avg       0.88      0.83      0.85        36


Accuracy: 0.8333333333333334
Balanced Accuracy: 0.8333333333333334
Precision: 0.5
Recall: 0.8333333333333334
F1: 0.625
AUROC: 0.8333333333333334

# =========================== Tuning hyper-parameters for roc_auc

Fitting 4 folds for each of 40 candidates, totalling 160 fits
Best parameters set found on development set:

{'clf__algorithm': 'SAMME.R', 'clf__learning_rate': 0.05, 'clf__n_estimators': 10}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.96      0.83      0.89        30
           1       0.50      0.83      0.62         6

   micro avg       0.83      0.83      0.83        36
   macro avg       0.73      0.83      0.76        36
weighted avg       0.88      0.83      0.85        36


Accuracy: 0.8333333333333334
Balanced Accuracy: 0.8333333333333334
Precision: 0.5
Recall: 0.8333333333333334
F1: 0.625
AUROC: 0.8333333333333334

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
==============================
 Random Forest 
==============================
# =========================== Tuning hyper-parameters for precision

Fitting 4 folds for each of 540 candidates, totalling 2160 fits
Best parameters set found on development set:

{'clf__bootstrap': True, 'clf__max_depth': 8, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 6, 'clf__n_estimators': 10}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.87      0.90      0.89        30
           1       0.40      0.33      0.36         6

   micro avg       0.81      0.81      0.81        36
   macro avg       0.64      0.62      0.62        36
weighted avg       0.79      0.81      0.80        36


Accuracy: 0.8055555555555556
Balanced Accuracy: 0.6166666666666667
Precision: 0.4
Recall: 0.3333333333333333
F1: 0.3636363636363636
AUROC: 0.6166666666666667

# =========================== Tuning hyper-parameters for recall

Fitting 4 folds for each of 540 candidates, totalling 2160 fits
Best parameters set found on development set:

{'clf__bootstrap': True, 'clf__max_depth': 2, 'clf__max_features': 'auto', 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 2, 'clf__n_estimators': 100}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.96      0.83      0.89        30
           1       0.50      0.83      0.62         6

   micro avg       0.83      0.83      0.83        36
   macro avg       0.73      0.83      0.76        36
weighted avg       0.88      0.83      0.85        36


Accuracy: 0.8333333333333334
Balanced Accuracy: 0.8333333333333334
Precision: 0.5
Recall: 0.8333333333333334
F1: 0.625
AUROC: 0.8333333333333334

# =========================== Tuning hyper-parameters for f1

Fitting 4 folds for each of 540 candidates, totalling 2160 fits
Best parameters set found on development set:

{'clf__bootstrap': True, 'clf__max_depth': 50, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 2, 'clf__n_estimators': 80}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.90      0.87      0.88        30
           1       0.43      0.50      0.46         6

   micro avg       0.81      0.81      0.81        36
   macro avg       0.66      0.68      0.67        36
weighted avg       0.82      0.81      0.81        36


Accuracy: 0.8055555555555556
Balanced Accuracy: 0.6833333333333333
Precision: 0.42857142857142855
Recall: 0.5
F1: 0.4615384615384615
AUROC: 0.6833333333333333

# =========================== Tuning hyper-parameters for balanced_accuracy

Fitting 4 folds for each of 540 candidates, totalling 2160 fits
Best parameters set found on development set:

{'clf__bootstrap': True, 'clf__max_depth': 2, 'clf__max_features': 'auto', 'clf__min_samples_leaf': 5, 'clf__min_samples_split': 4, 'clf__n_estimators': 100}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.96      0.83      0.89        30
           1       0.50      0.83      0.62         6

   micro avg       0.83      0.83      0.83        36
   macro avg       0.73      0.83      0.76        36
weighted avg       0.88      0.83      0.85        36


Accuracy: 0.8333333333333334
Balanced Accuracy: 0.8333333333333334
Precision: 0.5
Recall: 0.8333333333333334
F1: 0.625
AUROC: 0.8333333333333334

# =========================== Tuning hyper-parameters for roc_auc

Fitting 4 folds for each of 540 candidates, totalling 2160 fits
Best parameters set found on development set:

{'clf__bootstrap': False, 'clf__max_depth': 20, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 5, 'clf__min_samples_split': 2, 'clf__n_estimators': 10}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.90      0.90      0.90        30
           1       0.50      0.50      0.50         6

   micro avg       0.83      0.83      0.83        36
   macro avg       0.70      0.70      0.70        36
weighted avg       0.83      0.83      0.83        36


Accuracy: 0.8333333333333334
Balanced Accuracy: 0.7
Precision: 0.5
Recall: 0.5
F1: 0.5
AUROC: 0.7000000000000001

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
 Multiple Grid Search 
==============================
columns ['left_max', 'left_std', 'react_mean_pupil', 'react_left_mean', 'descr_left_max', 'right_mean', 'left_mean', 'descr_right_max', 'descr_left_mean', 'descr_right_mean', 'descr_mean_pupil']
number of datapoint: 144
Normalize: True
Oversample: True
Oversample Mode: minmax
Drop NaN: True
==============================
==============================
Train Set Datapoints 108
Test Set Datapoints 36
==============================
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
==============================
 Support Vector Machine 
==============================
# =========================== Tuning hyper-parameters for precision

Fitting 4 folds for each of 81 candidates, totalling 324 fits
Best parameters set found on development set:

{'clf__C': 1, 'clf__gamma': 1, 'clf__kernel': 'rbf'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.87      0.93        30
           1       0.60      1.00      0.75         6

   micro avg       0.89      0.89      0.89        36
   macro avg       0.80      0.93      0.84        36
weighted avg       0.93      0.89      0.90        36


Accuracy: 0.8888888888888888
Balanced Accuracy: 0.9333333333333333
Precision: 0.6
Recall: 1.0
F1: 0.7499999999999999
AUROC: 0.9333333333333333

# =========================== Tuning hyper-parameters for recall

Fitting 4 folds for each of 81 candidates, totalling 324 fits
Best parameters set found on development set:

{'clf__C': 100, 'clf__gamma': 0.01, 'clf__kernel': 'rbf'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.80      0.89        30
           1       0.50      1.00      0.67         6

   micro avg       0.83      0.83      0.83        36
   macro avg       0.75      0.90      0.78        36
weighted avg       0.92      0.83      0.85        36


Accuracy: 0.8333333333333334
Balanced Accuracy: 0.9
Precision: 0.5
Recall: 1.0
F1: 0.6666666666666666
AUROC: 0.9

# =========================== Tuning hyper-parameters for f1

Fitting 4 folds for each of 81 candidates, totalling 324 fits
Best parameters set found on development set:

{'clf__C': 1, 'clf__kernel': 'linear'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.77      0.87        30
           1       0.46      1.00      0.63         6

   micro avg       0.81      0.81      0.81        36
   macro avg       0.73      0.88      0.75        36
weighted avg       0.91      0.81      0.83        36


Accuracy: 0.8055555555555556
Balanced Accuracy: 0.8833333333333333
Precision: 0.46153846153846156
Recall: 1.0
F1: 0.631578947368421
AUROC: 0.8833333333333333

# =========================== Tuning hyper-parameters for balanced_accuracy

Fitting 4 folds for each of 81 candidates, totalling 324 fits
Best parameters set found on development set:

{'clf__C': 100, 'clf__gamma': 0.01, 'clf__kernel': 'rbf'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.77      0.87        30
           1       0.46      1.00      0.63         6

   micro avg       0.81      0.81      0.81        36
   macro avg       0.73      0.88      0.75        36
weighted avg       0.91      0.81      0.83        36


Accuracy: 0.8055555555555556
Balanced Accuracy: 0.8833333333333333
Precision: 0.46153846153846156
Recall: 1.0
F1: 0.631578947368421
AUROC: 0.8833333333333333

# =========================== Tuning hyper-parameters for roc_auc

Fitting 4 folds for each of 81 candidates, totalling 324 fits
Best parameters set found on development set:

{'clf__C': 1, 'clf__gamma': 1, 'clf__kernel': 'rbf'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.96      0.83      0.89        30
           1       0.50      0.83      0.62         6

   micro avg       0.83      0.83      0.83        36
   macro avg       0.73      0.83      0.76        36
weighted avg       0.88      0.83      0.85        36


Accuracy: 0.8333333333333334
Balanced Accuracy: 0.8333333333333334
Precision: 0.5
Recall: 0.8333333333333334
F1: 0.625
AUROC: 0.8333333333333334

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
==============================
 Decision Tree 
==============================
# =========================== Tuning hyper-parameters for precision

Fitting 4 folds for each of 1200 candidates, totalling 4800 fits
Best parameters set found on development set:

{'clf__criterion': 'gini', 'clf__max_depth': 10, 'clf__max_features': 'auto', 'clf__min_samples_leaf': 2, 'clf__min_samples_split': 3, 'clf__splitter': 'best'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.87      0.87      0.87        30
           1       0.33      0.33      0.33         6

   micro avg       0.78      0.78      0.78        36
   macro avg       0.60      0.60      0.60        36
weighted avg       0.78      0.78      0.78        36


Accuracy: 0.7777777777777778
Balanced Accuracy: 0.6
Precision: 0.3333333333333333
Recall: 0.3333333333333333
F1: 0.3333333333333333
AUROC: 0.6

# =========================== Tuning hyper-parameters for recall

Fitting 4 folds for each of 1200 candidates, totalling 4800 fits
Best parameters set found on development set:

{'clf__criterion': 'entropy', 'clf__max_depth': 2, 'clf__max_features': 'auto', 'clf__min_samples_leaf': 4, 'clf__min_samples_split': 3, 'clf__splitter': 'random'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       1.00      0.47      0.64        30
           1       0.27      1.00      0.43         6

   micro avg       0.56      0.56      0.56        36
   macro avg       0.64      0.73      0.53        36
weighted avg       0.88      0.56      0.60        36


Accuracy: 0.5555555555555556
Balanced Accuracy: 0.7333333333333334
Precision: 0.2727272727272727
Recall: 1.0
F1: 0.42857142857142855
AUROC: 0.7333333333333334

# =========================== Tuning hyper-parameters for f1

Fitting 4 folds for each of 1200 candidates, totalling 4800 fits
Best parameters set found on development set:

{'clf__criterion': 'entropy', 'clf__max_depth': 20, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 2, 'clf__min_samples_split': 5, 'clf__splitter': 'random'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.89      0.83      0.86        30
           1       0.38      0.50      0.43         6

   micro avg       0.78      0.78      0.78        36
   macro avg       0.63      0.67      0.65        36
weighted avg       0.81      0.78      0.79        36


Accuracy: 0.7777777777777778
Balanced Accuracy: 0.6666666666666667
Precision: 0.375
Recall: 0.5
F1: 0.42857142857142855
AUROC: 0.6666666666666666

# =========================== Tuning hyper-parameters for balanced_accuracy

Fitting 4 folds for each of 1200 candidates, totalling 4800 fits
Best parameters set found on development set:

{'clf__criterion': 'entropy', 'clf__max_depth': 4, 'clf__max_features': 'auto', 'clf__min_samples_leaf': 4, 'clf__min_samples_split': 3, 'clf__splitter': 'random'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.96      0.90      0.93        30
           1       0.62      0.83      0.71         6

   micro avg       0.89      0.89      0.89        36
   macro avg       0.79      0.87      0.82        36
weighted avg       0.91      0.89      0.89        36


Accuracy: 0.8888888888888888
Balanced Accuracy: 0.8666666666666667
Precision: 0.625
Recall: 0.8333333333333334
F1: 0.7142857142857143
AUROC: 0.8666666666666667

# =========================== Tuning hyper-parameters for roc_auc

Fitting 4 folds for each of 1200 candidates, totalling 4800 fits
Best parameters set found on development set:

{'clf__criterion': 'entropy', 'clf__max_depth': 4, 'clf__max_features': 'auto', 'clf__min_samples_leaf': 5, 'clf__min_samples_split': 4, 'clf__splitter': 'best'}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.95      0.70      0.81        30
           1       0.36      0.83      0.50         6

   micro avg       0.72      0.72      0.72        36
   macro avg       0.66      0.77      0.65        36
weighted avg       0.85      0.72      0.76        36


Accuracy: 0.7222222222222222
Balanced Accuracy: 0.7666666666666666
Precision: 0.35714285714285715
Recall: 0.8333333333333334
F1: 0.5
AUROC: 0.7666666666666667

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
==============================
 Adaptive Boosting 
==============================
# =========================== Tuning hyper-parameters for precision

Fitting 4 folds for each of 40 candidates, totalling 160 fits
Best parameters set found on development set:

{'clf__algorithm': 'SAMME.R', 'clf__learning_rate': 0.3, 'clf__n_estimators': 200}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.92      0.80      0.86        30
           1       0.40      0.67      0.50         6

   micro avg       0.78      0.78      0.78        36
   macro avg       0.66      0.73      0.68        36
weighted avg       0.84      0.78      0.80        36


Accuracy: 0.7777777777777778
Balanced Accuracy: 0.7333333333333334
Precision: 0.4
Recall: 0.6666666666666666
F1: 0.5
AUROC: 0.7333333333333333

# =========================== Tuning hyper-parameters for recall

Fitting 4 folds for each of 40 candidates, totalling 160 fits
Best parameters set found on development set:

{'clf__algorithm': 'SAMME', 'clf__learning_rate': 0.01, 'clf__n_estimators': 10}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.96      0.83      0.89        30
           1       0.50      0.83      0.62         6

   micro avg       0.83      0.83      0.83        36
   macro avg       0.73      0.83      0.76        36
weighted avg       0.88      0.83      0.85        36


Accuracy: 0.8333333333333334
Balanced Accuracy: 0.8333333333333334
Precision: 0.5
Recall: 0.8333333333333334
F1: 0.625
AUROC: 0.8333333333333334

# =========================== Tuning hyper-parameters for f1

Fitting 4 folds for each of 40 candidates, totalling 160 fits
Best parameters set found on development set:

{'clf__algorithm': 'SAMME', 'clf__learning_rate': 0.05, 'clf__n_estimators': 10}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.96      0.83      0.89        30
           1       0.50      0.83      0.62         6

   micro avg       0.83      0.83      0.83        36
   macro avg       0.73      0.83      0.76        36
weighted avg       0.88      0.83      0.85        36


Accuracy: 0.8333333333333334
Balanced Accuracy: 0.8333333333333334
Precision: 0.5
Recall: 0.8333333333333334
F1: 0.625
AUROC: 0.8333333333333334

# =========================== Tuning hyper-parameters for balanced_accuracy

Fitting 4 folds for each of 40 candidates, totalling 160 fits
Best parameters set found on development set:

{'clf__algorithm': 'SAMME', 'clf__learning_rate': 0.01, 'clf__n_estimators': 50}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.96      0.83      0.89        30
           1       0.50      0.83      0.62         6

   micro avg       0.83      0.83      0.83        36
   macro avg       0.73      0.83      0.76        36
weighted avg       0.88      0.83      0.85        36


Accuracy: 0.8333333333333334
Balanced Accuracy: 0.8333333333333334
Precision: 0.5
Recall: 0.8333333333333334
F1: 0.625
AUROC: 0.8333333333333334

# =========================== Tuning hyper-parameters for roc_auc

Fitting 4 folds for each of 40 candidates, totalling 160 fits
Best parameters set found on development set:

{'clf__algorithm': 'SAMME', 'clf__learning_rate': 1, 'clf__n_estimators': 100}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.93      0.83      0.88        30
           1       0.44      0.67      0.53         6

   micro avg       0.81      0.81      0.81        36
   macro avg       0.69      0.75      0.71        36
weighted avg       0.85      0.81      0.82        36


Accuracy: 0.8055555555555556
Balanced Accuracy: 0.75
Precision: 0.4444444444444444
Recall: 0.6666666666666666
F1: 0.5333333333333333
AUROC: 0.75

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
==============================
 Random Forest 
==============================
# =========================== Tuning hyper-parameters for precision

Fitting 4 folds for each of 540 candidates, totalling 2160 fits
Best parameters set found on development set:

{'clf__bootstrap': False, 'clf__max_depth': 8, 'clf__max_features': 'auto', 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 2, 'clf__n_estimators': 10}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.87      0.87      0.87        30
           1       0.33      0.33      0.33         6

   micro avg       0.78      0.78      0.78        36
   macro avg       0.60      0.60      0.60        36
weighted avg       0.78      0.78      0.78        36


Accuracy: 0.7777777777777778
Balanced Accuracy: 0.6
Precision: 0.3333333333333333
Recall: 0.3333333333333333
F1: 0.3333333333333333
AUROC: 0.6

# =========================== Tuning hyper-parameters for recall

Fitting 4 folds for each of 540 candidates, totalling 2160 fits
Best parameters set found on development set:

{'clf__bootstrap': True, 'clf__max_depth': 2, 'clf__max_features': 'auto', 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 6, 'clf__n_estimators': 10}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.96      0.83      0.89        30
           1       0.50      0.83      0.62         6

   micro avg       0.83      0.83      0.83        36
   macro avg       0.73      0.83      0.76        36
weighted avg       0.88      0.83      0.85        36


Accuracy: 0.8333333333333334
Balanced Accuracy: 0.8333333333333334
Precision: 0.5
Recall: 0.8333333333333334
F1: 0.625
AUROC: 0.8333333333333334

# =========================== Tuning hyper-parameters for f1

Fitting 4 folds for each of 540 candidates, totalling 2160 fits
Best parameters set found on development set:

{'clf__bootstrap': False, 'clf__max_depth': 10, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 3, 'clf__min_samples_split': 6, 'clf__n_estimators': 10}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.90      0.87      0.88        30
           1       0.43      0.50      0.46         6

   micro avg       0.81      0.81      0.81        36
   macro avg       0.66      0.68      0.67        36
weighted avg       0.82      0.81      0.81        36


Accuracy: 0.8055555555555556
Balanced Accuracy: 0.6833333333333333
Precision: 0.42857142857142855
Recall: 0.5
F1: 0.4615384615384615
AUROC: 0.6833333333333333

# =========================== Tuning hyper-parameters for balanced_accuracy

Fitting 4 folds for each of 540 candidates, totalling 2160 fits
Best parameters set found on development set:

{'clf__bootstrap': True, 'clf__max_depth': 50, 'clf__max_features': 'auto', 'clf__min_samples_leaf': 5, 'clf__min_samples_split': 6, 'clf__n_estimators': 80}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.96      0.83      0.89        30
           1       0.50      0.83      0.62         6

   micro avg       0.83      0.83      0.83        36
   macro avg       0.73      0.83      0.76        36
weighted avg       0.88      0.83      0.85        36


Accuracy: 0.8333333333333334
Balanced Accuracy: 0.8333333333333334
Precision: 0.5
Recall: 0.8333333333333334
F1: 0.625
AUROC: 0.8333333333333334

# =========================== Tuning hyper-parameters for roc_auc

Fitting 4 folds for each of 540 candidates, totalling 2160 fits
Best parameters set found on development set:

{'clf__bootstrap': False, 'clf__max_depth': 20, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 4, 'clf__n_estimators': 10}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.93      0.87      0.90        30
           1       0.50      0.67      0.57         6

   micro avg       0.83      0.83      0.83        36
   macro avg       0.71      0.77      0.73        36
weighted avg       0.86      0.83      0.84        36


Accuracy: 0.8333333333333334
Balanced Accuracy: 0.7666666666666666
Precision: 0.5
Recall: 0.6666666666666666
F1: 0.5714285714285715
AUROC: 0.7666666666666666

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
