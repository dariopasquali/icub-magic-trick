drop NaN
normalize whithin subject
Split in Train and Test set, equal for all the models and column set
 Multiple Grid Search 
==============================
columns ['duration', 'react_dur', 'point_dur', 'descr_dur', 'right_mean', 'right_std', 'right_min', 'right_max', 'left_mean', 'left_std', 'left_min', 'left_max', 'react_right_mean', 'react_right_std', 'react_right_min', 'react_right_max', 'react_left_mean', 'react_left_std', 'react_left_min', 'react_left_max', 'point_right_mean', 'point_right_std', 'point_right_min', 'point_right_max', 'point_left_mean', 'point_left_std', 'point_left_min', 'point_left_max', 'descr_right_mean', 'descr_right_std', 'descr_right_min', 'descr_right_max', 'descr_left_mean', 'descr_left_std', 'descr_left_min', 'descr_left_max', 'descr_mean_pupil', 'react_mean_pupil', 'point_mean_pupil']
number of datapoint: 150
Normalize: True
Oversample: True
Oversample Mode: minmax
Drop NaN: True
==============================
==============================
Train Set Datapoints 112
Test Set Datapoints 38
==============================
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
==============================
 Gaussian Naive Bayes 
==============================
# =========================== Tuning hyper-parameters for precision

Fitting 4 folds for each of 5 candidates, totalling 20 fits
Best parameters set found on development set:

{'clf__var_smoothing': 1e-09}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.93      0.78      0.85        32
           1       0.36      0.67      0.47         6

   micro avg       0.76      0.76      0.76        38
   macro avg       0.64      0.72      0.66        38
weighted avg       0.84      0.76      0.79        38


Accuracy: 0.7631578947368421
Balanced Accuracy: 0.7239583333333333
Precision: 0.36363636363636365
Recall: 0.6666666666666666
F1: 0.4705882352941177
AUROC: 0.7239583333333333
Confusion Matrix: [[25  7]
 [ 2  4]]

# =========================== Tuning hyper-parameters for recall

Fitting 4 folds for each of 5 candidates, totalling 20 fits
Best parameters set found on development set:

{'clf__var_smoothing': 1e-09}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.92      0.75      0.83        32
           1       0.33      0.67      0.44         6

   micro avg       0.74      0.74      0.74        38
   macro avg       0.63      0.71      0.64        38
weighted avg       0.83      0.74      0.77        38


Accuracy: 0.7368421052631579
Balanced Accuracy: 0.7083333333333333
Precision: 0.3333333333333333
Recall: 0.6666666666666666
F1: 0.4444444444444444
AUROC: 0.7083333333333334
Confusion Matrix: [[24  8]
 [ 2  4]]

# =========================== Tuning hyper-parameters for f1

Fitting 4 folds for each of 5 candidates, totalling 20 fits
Best parameters set found on development set:

{'clf__var_smoothing': 1e-08}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.92      0.75      0.83        32
           1       0.33      0.67      0.44         6

   micro avg       0.74      0.74      0.74        38
   macro avg       0.63      0.71      0.64        38
weighted avg       0.83      0.74      0.77        38


Accuracy: 0.7368421052631579
Balanced Accuracy: 0.7083333333333333
Precision: 0.3333333333333333
Recall: 0.6666666666666666
F1: 0.4444444444444444
AUROC: 0.7083333333333334
Confusion Matrix: [[24  8]
 [ 2  4]]

# =========================== Tuning hyper-parameters for balanced_accuracy

Fitting 4 folds for each of 5 candidates, totalling 20 fits
Best parameters set found on development set:

{'clf__var_smoothing': 2e-09}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.92      0.75      0.83        32
           1       0.33      0.67      0.44         6

   micro avg       0.74      0.74      0.74        38
   macro avg       0.63      0.71      0.64        38
weighted avg       0.83      0.74      0.77        38


Accuracy: 0.7368421052631579
Balanced Accuracy: 0.7083333333333333
Precision: 0.3333333333333333
Recall: 0.6666666666666666
F1: 0.4444444444444444
AUROC: 0.7083333333333334
Confusion Matrix: [[24  8]
 [ 2  4]]

# =========================== Tuning hyper-parameters for roc_auc

Fitting 4 folds for each of 5 candidates, totalling 20 fits
Best parameters set found on development set:

{'clf__var_smoothing': 1e-08}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.92      0.72      0.81        32
           1       0.31      0.67      0.42         6

   micro avg       0.71      0.71      0.71        38
   macro avg       0.61      0.69      0.61        38
weighted avg       0.82      0.71      0.75        38


Accuracy: 0.7105263157894737
Balanced Accuracy: 0.6927083333333333
Precision: 0.3076923076923077
Recall: 0.6666666666666666
F1: 0.42105263157894735
AUROC: 0.6927083333333333
Confusion Matrix: [[23  9]
 [ 2  4]]

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
 Multiple Grid Search 
==============================
columns ['left_max', 'left_std', 'right_mean', 'left_mean', 'react_right_mean', 'react_left_mean', 'react_mean_pupil', 'descr_left_mean', 'descr_left_max', 'descr_mean_pupil', 'descr_right_max', 'descr_right_mean']
number of datapoint: 150
Normalize: True
Oversample: True
Oversample Mode: minmax
Drop NaN: True
==============================
==============================
Train Set Datapoints 112
Test Set Datapoints 38
==============================
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
==============================
 Gaussian Naive Bayes 
==============================
# =========================== Tuning hyper-parameters for precision

Fitting 4 folds for each of 5 candidates, totalling 20 fits
Best parameters set found on development set:

{'clf__var_smoothing': 2e-09}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.96      0.75      0.84        32
           1       0.38      0.83      0.53         6

   micro avg       0.76      0.76      0.76        38
   macro avg       0.67      0.79      0.68        38
weighted avg       0.87      0.76      0.79        38


Accuracy: 0.7631578947368421
Balanced Accuracy: 0.7916666666666667
Precision: 0.38461538461538464
Recall: 0.8333333333333334
F1: 0.5263157894736842
AUROC: 0.7916666666666666
Confusion Matrix: [[24  8]
 [ 1  5]]

# =========================== Tuning hyper-parameters for recall

Fitting 4 folds for each of 5 candidates, totalling 20 fits
Best parameters set found on development set:

{'clf__var_smoothing': 2e-08}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.96      0.72      0.82        32
           1       0.36      0.83      0.50         6

   micro avg       0.74      0.74      0.74        38
   macro avg       0.66      0.78      0.66        38
weighted avg       0.86      0.74      0.77        38


Accuracy: 0.7368421052631579
Balanced Accuracy: 0.7760416666666667
Precision: 0.35714285714285715
Recall: 0.8333333333333334
F1: 0.5
AUROC: 0.7760416666666667
Confusion Matrix: [[23  9]
 [ 1  5]]

# =========================== Tuning hyper-parameters for f1

Fitting 4 folds for each of 5 candidates, totalling 20 fits
Best parameters set found on development set:

{'clf__var_smoothing': 2e-09}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.96      0.75      0.84        32
           1       0.38      0.83      0.53         6

   micro avg       0.76      0.76      0.76        38
   macro avg       0.67      0.79      0.68        38
weighted avg       0.87      0.76      0.79        38


Accuracy: 0.7631578947368421
Balanced Accuracy: 0.7916666666666667
Precision: 0.38461538461538464
Recall: 0.8333333333333334
F1: 0.5263157894736842
AUROC: 0.7916666666666666
Confusion Matrix: [[24  8]
 [ 1  5]]

# =========================== Tuning hyper-parameters for balanced_accuracy

Fitting 4 folds for each of 5 candidates, totalling 20 fits
Best parameters set found on development set:

{'clf__var_smoothing': 5e-08}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.96      0.75      0.84        32
           1       0.38      0.83      0.53         6

   micro avg       0.76      0.76      0.76        38
   macro avg       0.67      0.79      0.68        38
weighted avg       0.87      0.76      0.79        38


Accuracy: 0.7631578947368421
Balanced Accuracy: 0.7916666666666667
Precision: 0.38461538461538464
Recall: 0.8333333333333334
F1: 0.5263157894736842
AUROC: 0.7916666666666666
Confusion Matrix: [[24  8]
 [ 1  5]]

# =========================== Tuning hyper-parameters for roc_auc

Fitting 4 folds for each of 5 candidates, totalling 20 fits
Best parameters set found on development set:

{'clf__var_smoothing': 1e-08}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.96      0.75      0.84        32
           1       0.38      0.83      0.53         6

   micro avg       0.76      0.76      0.76        38
   macro avg       0.67      0.79      0.68        38
weighted avg       0.87      0.76      0.79        38


Accuracy: 0.7631578947368421
Balanced Accuracy: 0.7916666666666667
Precision: 0.38461538461538464
Recall: 0.8333333333333334
F1: 0.5263157894736842
AUROC: 0.7916666666666666
Confusion Matrix: [[24  8]
 [ 1  5]]

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
 Multiple Grid Search 
==============================
columns ['left_max', 'right_max', 'right_mean', 'left_mean', 'react_right_mean', 'react_left_mean', 'react_mean_pupil', 'react_right_max', 'react_left_max', 'descr_left_mean', 'descr_right_mean', 'descr_mean_pupil', 'descr_right_max', 'descr_left_max']
number of datapoint: 150
Normalize: True
Oversample: True
Oversample Mode: minmax
Drop NaN: True
==============================
==============================
Train Set Datapoints 112
Test Set Datapoints 38
==============================
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
==============================
 Gaussian Naive Bayes 
==============================
# =========================== Tuning hyper-parameters for precision

Fitting 4 folds for each of 5 candidates, totalling 20 fits
Best parameters set found on development set:

{'clf__var_smoothing': 1e-09}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.96      0.78      0.86        32
           1       0.42      0.83      0.56         6

   micro avg       0.79      0.79      0.79        38
   macro avg       0.69      0.81      0.71        38
weighted avg       0.88      0.79      0.81        38


Accuracy: 0.7894736842105263
Balanced Accuracy: 0.8072916666666667
Precision: 0.4166666666666667
Recall: 0.8333333333333334
F1: 0.5555555555555556
AUROC: 0.8072916666666667
Confusion Matrix: [[25  7]
 [ 1  5]]

# =========================== Tuning hyper-parameters for recall

Fitting 4 folds for each of 5 candidates, totalling 20 fits
Best parameters set found on development set:

{'clf__var_smoothing': 5e-08}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.96      0.72      0.82        32
           1       0.36      0.83      0.50         6

   micro avg       0.74      0.74      0.74        38
   macro avg       0.66      0.78      0.66        38
weighted avg       0.86      0.74      0.77        38


Accuracy: 0.7368421052631579
Balanced Accuracy: 0.7760416666666667
Precision: 0.35714285714285715
Recall: 0.8333333333333334
F1: 0.5
AUROC: 0.7760416666666667
Confusion Matrix: [[23  9]
 [ 1  5]]

# =========================== Tuning hyper-parameters for f1

Fitting 4 folds for each of 5 candidates, totalling 20 fits
Best parameters set found on development set:

{'clf__var_smoothing': 1e-08}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.96      0.75      0.84        32
           1       0.38      0.83      0.53         6

   micro avg       0.76      0.76      0.76        38
   macro avg       0.67      0.79      0.68        38
weighted avg       0.87      0.76      0.79        38


Accuracy: 0.7631578947368421
Balanced Accuracy: 0.7916666666666667
Precision: 0.38461538461538464
Recall: 0.8333333333333334
F1: 0.5263157894736842
AUROC: 0.7916666666666666
Confusion Matrix: [[24  8]
 [ 1  5]]

# =========================== Tuning hyper-parameters for balanced_accuracy

Fitting 4 folds for each of 5 candidates, totalling 20 fits
Best parameters set found on development set:

{'clf__var_smoothing': 2e-09}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.96      0.75      0.84        32
           1       0.38      0.83      0.53         6

   micro avg       0.76      0.76      0.76        38
   macro avg       0.67      0.79      0.68        38
weighted avg       0.87      0.76      0.79        38


Accuracy: 0.7631578947368421
Balanced Accuracy: 0.7916666666666667
Precision: 0.38461538461538464
Recall: 0.8333333333333334
F1: 0.5263157894736842
AUROC: 0.7916666666666666
Confusion Matrix: [[24  8]
 [ 1  5]]

# =========================== Tuning hyper-parameters for roc_auc

Fitting 4 folds for each of 5 candidates, totalling 20 fits
Best parameters set found on development set:

{'clf__var_smoothing': 1e-08}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.96      0.75      0.84        32
           1       0.38      0.83      0.53         6

   micro avg       0.76      0.76      0.76        38
   macro avg       0.67      0.79      0.68        38
weighted avg       0.87      0.76      0.79        38


Accuracy: 0.7631578947368421
Balanced Accuracy: 0.7916666666666667
Precision: 0.38461538461538464
Recall: 0.8333333333333334
F1: 0.5263157894736842
AUROC: 0.7916666666666666
Confusion Matrix: [[24  8]
 [ 1  5]]

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
