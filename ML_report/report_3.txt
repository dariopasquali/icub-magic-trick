test sys.stdout
================== MODE SMOOTH sub =====================
 Multiple Grid Search 
==============================
columns ['descr_right_mean', 'descr_left_mean', 'react_right_mean', 'react_left_mean', 'premed_score_right', 'premed_score_left']
number of datapoint: 96
Normalize: False
Oversample: True
Oversample Mode: minmax
Drop NaN: True
==============================
Split in Train and Test set, equal for all the models
==============================
Train Set Datapoints 72
Test Set Datapoints 24
==============================
==============================
 Random Forest 
==============================
# =========================== Tuning hyper-parameters for precision

Fitting 4 folds for each of 540 candidates, totalling 2160 fits
Best parameters set found on development set:

{'clf__bootstrap': False, 'clf__max_depth': 2, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 3, 'clf__min_samples_split': 4, 'clf__n_estimators': 80}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.83      0.75      0.79        20
           1       0.17      0.25      0.20         4

   micro avg       0.67      0.67      0.67        24
   macro avg       0.50      0.50      0.49        24
weighted avg       0.72      0.67      0.69        24


Accuracy: 0.6666666666666666
Balanced Accuracy: 0.5
Precision: 0.16666666666666666
Recall: 0.25
F1: 0.2
AUROC: 0.5

# =========================== Tuning hyper-parameters for recall

Fitting 4 folds for each of 540 candidates, totalling 2160 fits
Best parameters set found on development set:

{'clf__bootstrap': True, 'clf__max_depth': 50, 'clf__max_features': 'auto', 'clf__min_samples_leaf': 5, 'clf__min_samples_split': 2, 'clf__n_estimators': 10}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.83      0.75      0.79        20
           1       0.17      0.25      0.20         4

   micro avg       0.67      0.67      0.67        24
   macro avg       0.50      0.50      0.49        24
weighted avg       0.72      0.67      0.69        24


Accuracy: 0.6666666666666666
Balanced Accuracy: 0.5
Precision: 0.16666666666666666
Recall: 0.25
F1: 0.2
AUROC: 0.5

# =========================== Tuning hyper-parameters for f1

Fitting 4 folds for each of 540 candidates, totalling 2160 fits
Best parameters set found on development set:

{'clf__bootstrap': True, 'clf__max_depth': 2, 'clf__max_features': 'auto', 'clf__min_samples_leaf': 5, 'clf__min_samples_split': 4, 'clf__n_estimators': 10}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.83      0.75      0.79        20
           1       0.17      0.25      0.20         4

   micro avg       0.67      0.67      0.67        24
   macro avg       0.50      0.50      0.49        24
weighted avg       0.72      0.67      0.69        24


Accuracy: 0.6666666666666666
Balanced Accuracy: 0.5
Precision: 0.16666666666666666
Recall: 0.25
F1: 0.2
AUROC: 0.5

# =========================== Tuning hyper-parameters for balanced_accuracy

Fitting 4 folds for each of 540 candidates, totalling 2160 fits
Best parameters set found on development set:

{'clf__bootstrap': False, 'clf__max_depth': 2, 'clf__max_features': 'auto', 'clf__min_samples_leaf': 3, 'clf__min_samples_split': 4, 'clf__n_estimators': 80}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.84      0.80      0.82        20
           1       0.20      0.25      0.22         4

   micro avg       0.71      0.71      0.71        24
   macro avg       0.52      0.53      0.52        24
weighted avg       0.74      0.71      0.72        24


Accuracy: 0.7083333333333334
Balanced Accuracy: 0.525
Precision: 0.2
Recall: 0.25
F1: 0.22222222222222224
AUROC: 0.525

# =========================== Tuning hyper-parameters for roc_auc

Fitting 4 folds for each of 540 candidates, totalling 2160 fits
Best parameters set found on development set:

{'clf__bootstrap': False, 'clf__max_depth': 2, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 4, 'clf__n_estimators': 80}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.85      0.85      0.85        20
           1       0.25      0.25      0.25         4

   micro avg       0.75      0.75      0.75        24
   macro avg       0.55      0.55      0.55        24
weighted avg       0.75      0.75      0.75        24


Accuracy: 0.75
Balanced Accuracy: 0.55
Precision: 0.25
Recall: 0.25
F1: 0.25
AUROC: 0.55

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
 Multiple Grid Search 
==============================
columns ['descr_fix_freq', 'descr_sacc_freq', 'descr_right_mean', 'descr_right_std', 'descr_right_min', 'descr_right_max', 'descr_left_mean', 'descr_left_std', 'descr_left_min', 'descr_left_max', 'react_fix_freq', 'react_sacc_freq', 'react_right_mean', 'react_right_std', 'react_right_min', 'react_right_max', 'react_left_mean', 'react_left_std', 'react_left_min', 'react_left_max', 'react_dur', 'descr_dur', 'premed_score_right', 'premed_score_left']
number of datapoint: 96
Normalize: False
Oversample: True
Oversample Mode: minmax
Drop NaN: True
==============================
Split in Train and Test set, equal for all the models
==============================
Train Set Datapoints 72
Test Set Datapoints 24
==============================
==============================
 Random Forest 
==============================
# =========================== Tuning hyper-parameters for precision

Fitting 4 folds for each of 540 candidates, totalling 2160 fits
Best parameters set found on development set:

{'clf__bootstrap': False, 'clf__max_depth': 50, 'clf__max_features': 'auto', 'clf__min_samples_leaf': 5, 'clf__min_samples_split': 2, 'clf__n_estimators': 100}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.88      0.75      0.81        20
           1       0.29      0.50      0.36         4

   micro avg       0.71      0.71      0.71        24
   macro avg       0.58      0.62      0.59        24
weighted avg       0.78      0.71      0.74        24


Accuracy: 0.7083333333333334
Balanced Accuracy: 0.625
Precision: 0.2857142857142857
Recall: 0.5
F1: 0.36363636363636365
AUROC: 0.625

# =========================== Tuning hyper-parameters for recall

Fitting 4 folds for each of 540 candidates, totalling 2160 fits
Best parameters set found on development set:

{'clf__bootstrap': True, 'clf__max_depth': 2, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 3, 'clf__min_samples_split': 2, 'clf__n_estimators': 10}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.88      0.70      0.78        20
           1       0.25      0.50      0.33         4

   micro avg       0.67      0.67      0.67        24
   macro avg       0.56      0.60      0.56        24
weighted avg       0.77      0.67      0.70        24


Accuracy: 0.6666666666666666
Balanced Accuracy: 0.6
Precision: 0.25
Recall: 0.5
F1: 0.3333333333333333
AUROC: 0.5999999999999999

# =========================== Tuning hyper-parameters for f1

Fitting 4 folds for each of 540 candidates, totalling 2160 fits
Best parameters set found on development set:

{'clf__bootstrap': False, 'clf__max_depth': 2, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 5, 'clf__min_samples_split': 6, 'clf__n_estimators': 100}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.88      0.75      0.81        20
           1       0.29      0.50      0.36         4

   micro avg       0.71      0.71      0.71        24
   macro avg       0.58      0.62      0.59        24
weighted avg       0.78      0.71      0.74        24


Accuracy: 0.7083333333333334
Balanced Accuracy: 0.625
Precision: 0.2857142857142857
Recall: 0.5
F1: 0.36363636363636365
AUROC: 0.625

# =========================== Tuning hyper-parameters for balanced_accuracy

Fitting 4 folds for each of 540 candidates, totalling 2160 fits
Best parameters set found on development set:

{'clf__bootstrap': True, 'clf__max_depth': 8, 'clf__max_features': 'auto', 'clf__min_samples_leaf': 3, 'clf__min_samples_split': 4, 'clf__n_estimators': 80}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.88      0.75      0.81        20
           1       0.29      0.50      0.36         4

   micro avg       0.71      0.71      0.71        24
   macro avg       0.58      0.62      0.59        24
weighted avg       0.78      0.71      0.74        24


Accuracy: 0.7083333333333334
Balanced Accuracy: 0.625
Precision: 0.2857142857142857
Recall: 0.5
F1: 0.36363636363636365
AUROC: 0.625

# =========================== Tuning hyper-parameters for roc_auc

Fitting 4 folds for each of 540 candidates, totalling 2160 fits
Best parameters set found on development set:

{'clf__bootstrap': True, 'clf__max_depth': 2, 'clf__max_features': 'auto', 'clf__min_samples_leaf': 5, 'clf__min_samples_split': 4, 'clf__n_estimators': 10}

Grid scores on development set:


>>>>>>> Test Set Report <<<<<<<<

The model is trained on the full Training set.
The scores are computed on the never revealed Test set.

              precision    recall  f1-score   support

           0       0.82      0.70      0.76        20
           1       0.14      0.25      0.18         4

   micro avg       0.62      0.62      0.62        24
   macro avg       0.48      0.47      0.47        24
weighted avg       0.71      0.62      0.66        24


Accuracy: 0.625
Balanced Accuracy: 0.475
Precision: 0.14285714285714285
Recall: 0.25
F1: 0.18181818181818182
AUROC: 0.475

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
