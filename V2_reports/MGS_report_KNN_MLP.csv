	cols_set	datapoints	normalize	oversample	drop_nan	train_set	test_set	model	tune_for	accuracy	bal_accuracy	precision	recall	f1	AUROC	params
0	all_columns	150	True	minmax	True	112	38	mlp	precision	0.7631578947368421	0.5885416666666666	0.2857142857142857	0.3333333333333333	0.30769230769230765	0.5885416666666666	{'clf__activation': 'relu', 'clf__alpha': 0.05, 'clf__hidden_layer_sizes': (100, 100, 100), 'clf__solver': 'adam'}
1	all_columns	150	True	minmax	True	112	38	mlp	recall	0.7368421052631579	0.640625	0.3	0.5	0.37499999999999994	0.640625	{'clf__activation': 'relu', 'clf__alpha': 0.005, 'clf__hidden_layer_sizes': (100, 100), 'clf__solver': 'sgd'}
2	all_columns	150	True	minmax	True	112	38	mlp	f1	0.8157894736842105	0.7552083333333333	0.4444444444444444	0.6666666666666666	0.5333333333333333	0.7552083333333333	{'clf__activation': 'relu', 'clf__alpha': 0.05, 'clf__hidden_layer_sizes': (100, 100), 'clf__solver': 'sgd'}
3	all_columns	150	True	minmax	True	112	38	mlp	balanced_accuracy	0.7631578947368421	0.65625	0.3333333333333333	0.5	0.4	0.65625	{'clf__activation': 'tanh', 'clf__alpha': 0.0001, 'clf__hidden_layer_sizes': (100, 100, 100), 'clf__solver': 'sgd'}
4	all_columns	150	True	minmax	True	112	38	mlp	roc_auc	0.7631578947368421	0.65625	0.3333333333333333	0.5	0.4	0.65625	{'clf__activation': 'relu', 'clf__alpha': 0.005, 'clf__hidden_layer_sizes': (100, 100), 'clf__solver': 'sgd'}
5	reduced	150	True	minmax	True	112	38	mlp	precision	0.7894736842105263	0.7395833333333333	0.4	0.6666666666666666	0.5	0.7395833333333333	{'clf__activation': 'tanh', 'clf__alpha': 0.005, 'clf__hidden_layer_sizes': (100, 100, 100), 'clf__solver': 'adam'}
6	reduced	150	True	minmax	True	112	38	mlp	recall	0.7368421052631579	0.84375	0.375	1.0	0.5454545454545454	0.84375	{'clf__activation': 'tanh', 'clf__alpha': 0.0001, 'clf__hidden_layer_sizes': (100,), 'clf__solver': 'sgd'}
7	reduced	150	True	minmax	True	112	38	mlp	f1	0.7631578947368421	0.859375	0.4	1.0	0.5714285714285715	0.859375	{'clf__activation': 'relu', 'clf__alpha': 0.05, 'clf__hidden_layer_sizes': (100, 100, 100), 'clf__solver': 'sgd'}
8	reduced	150	True	minmax	True	112	38	mlp	balanced_accuracy	0.7368421052631579	0.84375	0.375	1.0	0.5454545454545454	0.84375	{'clf__activation': 'tanh', 'clf__alpha': 0.005, 'clf__hidden_layer_sizes': (100,), 'clf__solver': 'sgd'}
9	reduced	150	True	minmax	True	112	38	mlp	roc_auc	0.7368421052631579	0.84375	0.375	1.0	0.5454545454545454	0.84375	{'clf__activation': 'relu', 'clf__alpha': 0.0001, 'clf__hidden_layer_sizes': (100,), 'clf__solver': 'sgd'}
10	tt_test	150	True	minmax	True	112	38	mlp	precision	0.7894736842105263	0.7395833333333333	0.4	0.6666666666666666	0.5	0.7395833333333333	{'clf__activation': 'relu', 'clf__alpha': 0.005, 'clf__hidden_layer_sizes': (100, 100), 'clf__solver': 'adam'}
11	tt_test	150	True	minmax	True	112	38	mlp	recall	0.7894736842105263	0.875	0.42857142857142855	1.0	0.6	0.875	{'clf__activation': 'tanh', 'clf__alpha': 0.05, 'clf__hidden_layer_sizes': (100,), 'clf__solver': 'sgd'}
12	tt_test	150	True	minmax	True	112	38	mlp	f1	0.8157894736842105	0.8229166666666667	0.45454545454545453	0.8333333333333334	0.5882352941176471	0.8229166666666667	{'clf__activation': 'tanh', 'clf__alpha': 0.05, 'clf__hidden_layer_sizes': (100,), 'clf__solver': 'adam'}
13	tt_test	150	True	minmax	True	112	38	mlp	balanced_accuracy	0.7368421052631579	0.7760416666666667	0.35714285714285715	0.8333333333333334	0.5	0.7760416666666667	{'clf__activation': 'relu', 'clf__alpha': 0.005, 'clf__hidden_layer_sizes': (100,), 'clf__solver': 'sgd'}
14	tt_test	150	True	minmax	True	112	38	mlp	roc_auc	0.7894736842105263	0.875	0.42857142857142855	1.0	0.6	0.875	{'clf__activation': 'tanh', 'clf__alpha': 0.005, 'clf__hidden_layer_sizes': (100, 100), 'clf__solver': 'sgd'}
15	wtf	150	True	minmax	True	112	38	mlp	precision	0.7631578947368421	0.5208333333333334	0.2	0.16666666666666666	0.1818181818181818	0.5208333333333334	{'clf__activation': 'relu', 'clf__alpha': 0.0001, 'clf__hidden_layer_sizes': (100, 100), 'clf__solver': 'adam'}
16	wtf	150	True	minmax	True	112	38	mlp	recall	0.7894736842105263	0.875	0.42857142857142855	1.0	0.6	0.875	{'clf__activation': 'tanh', 'clf__alpha': 0.0001, 'clf__hidden_layer_sizes': (100,), 'clf__solver': 'sgd'}
17	wtf	150	True	minmax	True	112	38	mlp	f1	0.7368421052631579	0.7760416666666667	0.35714285714285715	0.8333333333333334	0.5	0.7760416666666667	{'clf__activation': 'relu', 'clf__alpha': 0.0001, 'clf__hidden_layer_sizes': (100,), 'clf__solver': 'sgd'}
18	wtf	150	True	minmax	True	112	38	mlp	balanced_accuracy	0.7368421052631579	0.84375	0.375	1.0	0.5454545454545454	0.84375	{'clf__activation': 'relu', 'clf__alpha': 0.05, 'clf__hidden_layer_sizes': (100,), 'clf__solver': 'sgd'}
19	wtf	150	True	minmax	True	112	38	mlp	roc_auc	0.8157894736842105	0.890625	0.46153846153846156	1.0	0.631578947368421	0.890625	{'clf__activation': 'tanh', 'clf__alpha': 0.0001, 'clf__hidden_layer_sizes': (100,), 'clf__solver': 'sgd'}
