	cols_set	datapoints	normalize	oversample	drop_nan	train_set	test_set	model	tune_for	mean	std	accuracy	bal_accuracy	precision	recall	f1	AUROC	params
0	tt_wilcoxon	122	True	minmax	True	91	31	mlp	precision	0.6208791208791209	0.24468206435406206	0.9032258064516129	0.8766666666666667	0.7142857142857143	0.8333333333333334	0.7692307692307692	0.8766666666666668	{'clf__activation': 'relu', 'clf__alpha': 0.0001, 'clf__hidden_layer_sizes': (32, 8, 32), 'clf__solver': 'adam'}
1	tt_wilcoxon	122	True	minmax	True	91	31	mlp	recall	0.8104395604395604	0.20748579767581543	0.8387096774193549	0.9	0.5454545454545454	1.0	0.7058823529411764	0.9	{'clf__activation': 'tanh', 'clf__alpha': 0.0001, 'clf__hidden_layer_sizes': (100,), 'clf__solver': 'sgd'}
2	tt_wilcoxon	122	True	minmax	True	91	31	mlp	f1	0.6293040293040293	0.2097638165321499	0.8709677419354839	0.9199999999999999	0.6	1.0	0.7499999999999999	0.9199999999999999	{'clf__activation': 'tanh', 'clf__alpha': 0.0001, 'clf__hidden_layer_sizes': (32, 8, 32), 'clf__solver': 'sgd'}
3	tt_wilcoxon	122	True	minmax	True	91	31	mlp	balanced_accuracy	0.7987998843262002	0.14127809734566962	0.8709677419354839	0.9199999999999999	0.6	1.0	0.7499999999999999	0.9199999999999999	{'clf__activation': 'relu', 'clf__alpha': 0.005, 'clf__hidden_layer_sizes': (32, 8, 32), 'clf__solver': 'sgd'}
4	tt_wilcoxon	122	True	minmax	True	91	31	mlp	roc_auc	0.8703007518796992	0.17358177645814554	0.8387096774193549	0.9	0.5454545454545454	1.0	0.7058823529411764	0.9	{'clf__activation': 'tanh', 'clf__alpha': 0.05, 'clf__hidden_layer_sizes': (100,), 'clf__solver': 'sgd'}
5	tt_wilcoxon_premed	122	True	minmax	True	91	31	mlp	precision	0.6545787545787546	0.25751306537815005	0.9354838709677419	0.8966666666666667	0.8333333333333334	0.8333333333333334	0.8333333333333334	0.8966666666666667	{'clf__activation': 'relu', 'clf__alpha': 0.0001, 'clf__hidden_layer_sizes': (32, 8, 32), 'clf__solver': 'adam'}
6	tt_wilcoxon_premed	122	True	minmax	True	91	31	mlp	recall	0.8104395604395604	0.3259404384607449	0.8387096774193549	0.9	0.5454545454545454	1.0	0.7058823529411764	0.9	{'clf__activation': 'relu', 'clf__alpha': 0.05, 'clf__hidden_layer_sizes': (100,), 'clf__solver': 'sgd'}
7	tt_wilcoxon_premed	122	True	minmax	True	91	31	mlp	f1	0.698901098901099	0.17383490051239728	0.8064516129032258	0.8166666666666667	0.5	0.8333333333333334	0.625	0.8166666666666668	{'clf__activation': 'tanh', 'clf__alpha': 0.0001, 'clf__hidden_layer_sizes': (300,), 'clf__solver': 'sgd'}
8	tt_wilcoxon_premed	122	True	minmax	True	91	31	mlp	balanced_accuracy	0.8366589550800076	0.11920716851397295	0.7741935483870968	0.7966666666666666	0.45454545454545453	0.8333333333333334	0.5882352941176471	0.7966666666666667	{'clf__activation': 'tanh', 'clf__alpha': 0.05, 'clf__hidden_layer_sizes': (300,), 'clf__solver': 'sgd'}
9	tt_wilcoxon_premed	122	True	minmax	True	91	31	mlp	roc_auc	0.8836032388663968	0.09433843748790284	0.8387096774193549	0.8366666666666667	0.5555555555555556	0.8333333333333334	0.6666666666666667	0.8366666666666667	{'clf__activation': 'relu', 'clf__alpha': 0.0001, 'clf__hidden_layer_sizes': (32, 8, 32), 'clf__solver': 'sgd'}
